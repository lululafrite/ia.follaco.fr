{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a078ff82",
   "metadata": {},
   "source": [
    "# 03 - Entra√Ænement et √©valuation des mod√®les multi-sorties\n",
    "Ce notebook reprend et adapte le script `train_multioutput.py` pour entra√Æner et √©valuer :\n",
    "- Un pipeline scikit-learn avec un `RandomForestRegressor` multi-sorties et une `LogisticRegression` pour la classification du niveau.\n",
    "- Un mod√®le Keras multit√¢che (optionnel) partageant les m√™mes couches de base.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbd1171",
   "metadata": {},
   "source": [
    "## üì¶ Import des biblioth√®ques n√©cessaires\n",
    "- `numpy`, `scipy.sparse` : manipulation des features.\n",
    "- `sklearn.model_selection`, `ensemble`, `multioutput`, `linear_model`, `metrics` : pour le split, l'entra√Ænement et l'√©valuation.\n",
    "- `joblib` : pour la s√©rialisation des mod√®les.\n",
    "- (Optionnel) `tensorflow.keras` pour le mod√®le multit√¢che.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "027a3621",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484471ae",
   "metadata": {},
   "source": [
    "## üóÑÔ∏è Chargement des donn√©es\n",
    "Nous chargeons les matrices de features et les vecteurs cibles g√©n√©r√©s pr√©c√©demment via `prepare_features`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bdb34f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    dir_feat = os.path.join('data', 'fiverr_features')\n",
    "    X = sparse.load_npz(os.path.join(dir_feat, 'X_features.npz'))\n",
    "    y_prix = np.load(os.path.join(dir_feat, 'y_prix.npy'))\n",
    "    y_evaluation = np.load(os.path.join(dir_feat, 'y_evaluation.npy'))\n",
    "    y_niveau = np.load(os.path.join(dir_feat, 'y_niveau.npy'))\n",
    "    # Combiner price et rating pour le multi-output regressor\n",
    "    y_reg = np.vstack([y_prix, y_evaluation]).T\n",
    "    # Supprimer les lignes o√π price ou rating est NaN\n",
    "    mask = ~np.isnan(y_reg).any(axis=1)\n",
    "    X = X[mask]\n",
    "    y_reg = y_reg[mask]\n",
    "    y_niveau = y_niveau[mask]\n",
    "    return X, y_reg, y_niveau\n",
    "\n",
    "# Chargement\n",
    "X, y_reg, y_niveau = load_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bc11cf",
   "metadata": {},
   "source": [
    "## üìà Split train/test\n",
    "On s√©pare 20‚ÄØ% des donn√©es pour le test, avec `random_state=42` pour la reproductibilit√©."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d681042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 1007, Test samples: 252\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_reg_train, y_reg_test, y_niveau_train, y_niveau_test = train_test_split(\n",
    "    X, y_reg, y_niveau, test_size=0.2, random_state=42\n",
    ")\n",
    "print(f\"Train samples: {X_train.shape[0]}, Test samples: {X_test.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a204ca",
   "metadata": {},
   "source": [
    "## ü§ñ Entra√Ænement scikit-learn\n",
    "- **MultiOutputRegressor** avec un `RandomForestRegressor` (100 arbres).\n",
    "- **LogisticRegression** pour classifier le niveau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0863beca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=500, n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=500, n_jobs=-1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=500, n_jobs=-1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "mor = MultiOutputRegressor(rf)\n",
    "mor.fit(X_train, y_reg_train)\n",
    "\n",
    "clf = LogisticRegression(max_iter=500, n_jobs=-1)\n",
    "clf.fit(X_train, y_niveau_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8bd832",
   "metadata": {},
   "source": [
    "## üìä √âvaluation des mod√®les scikit-learn\n",
    "- MAE, RMSE, R¬≤ pour les r√©gressions\n",
    "- Accuracy pour la classification du niveau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "524602a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prix MAE: 3.687877619047631\n",
      "Prix RMSE: 28.741297795221502\n",
      "Prix R2: 0.6502012328686995\n",
      "Note MAE: 0.013188888888892667\n",
      "Note R2: 0.42018711304486656\n",
      "Level accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "y_reg_pred = mor.predict(X_test)\n",
    "y_niveau_pred = clf.predict(X_test)\n",
    "print(\"Prix MAE:\", mean_absolute_error(y_reg_test[:, 0], y_reg_pred[:, 0]))\n",
    "print(\"Prix RMSE:\", np.sqrt(mean_squared_error(y_reg_test[:, 0], y_reg_pred[:, 0])))\n",
    "print(\"Prix R2:\", r2_score(y_reg_test[:, 0], y_reg_pred[:, 0]))\n",
    "print(\"Note MAE:\", mean_absolute_error(y_reg_test[:, 1], y_reg_pred[:, 1]))\n",
    "print(\"Note R2:\", r2_score(y_reg_test[:, 1], y_reg_pred[:, 1]))\n",
    "print(\"Level accuracy:\", accuracy_score(y_niveau_test, y_niveau_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13330ff8",
   "metadata": {},
   "source": [
    "## üíæ Sauvegarde des mod√®les\n",
    "On stocke les mod√®les scikit-learn pour les r√©utiliser dans l‚Äôapplication Gradio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eaf12c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Mod√®les sauvegard√©s dans /models\n"
     ]
    }
   ],
   "source": [
    "os.makedirs('models', exist_ok=True)\n",
    "joblib.dump(mor, 'models/mor_rf.pkl')\n",
    "joblib.dump(clf, 'models/level_clf.pkl')\n",
    "print(\"‚úÖ Mod√®les sauvegard√©s dans /models\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94d8326",
   "metadata": {},
   "source": [
    "## üß† Entra√Ænement Keras multit√¢che (optionnel)\n",
    "Si TensorFlow est install√©, on entra√Æne un MLP multit√¢che partageant la m√™me base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "07ea8394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "114/114 [==============================] - 3s 13ms/step - loss: 5497.0464 - price_loss: 5486.8516 - rating_loss: 9.3134 - level_loss: 0.8819 - price_mae: 14.1754 - rating_mae: 2.1732 - level_accuracy: 0.6336 - val_loss: 2564.7200 - val_price_loss: 2558.6821 - val_rating_loss: 5.2277 - val_level_loss: 0.8104 - val_price_mae: 13.2975 - val_rating_mae: 1.6260 - val_level_accuracy: 0.6535\n",
      "Epoch 2/10\n",
      "114/114 [==============================] - 1s 10ms/step - loss: 4723.5801 - price_loss: 4716.5283 - rating_loss: 6.4368 - level_loss: 0.6148 - price_mae: 11.8137 - rating_mae: 1.3457 - level_accuracy: 0.8488 - val_loss: 1969.1049 - val_price_loss: 1965.2747 - val_rating_loss: 3.2563 - val_level_loss: 0.5740 - val_price_mae: 11.6742 - val_rating_mae: 1.2623 - val_level_accuracy: 0.7624\n",
      "Epoch 3/10\n",
      "114/114 [==============================] - 1s 9ms/step - loss: 3781.6477 - price_loss: 3778.5232 - rating_loss: 2.5373 - level_loss: 0.5870 - price_mae: 9.0103 - rating_mae: 0.9942 - level_accuracy: 0.7594 - val_loss: 1234.0198 - val_price_loss: 1231.6432 - val_rating_loss: 1.9149 - val_level_loss: 0.4617 - val_price_mae: 9.5014 - val_rating_mae: 1.0335 - val_level_accuracy: 0.8218\n",
      "Epoch 4/10\n",
      "114/114 [==============================] - 1s 10ms/step - loss: 2703.2031 - price_loss: 2701.3391 - rating_loss: 1.4481 - level_loss: 0.4159 - price_mae: 6.9578 - rating_mae: 0.8450 - level_accuracy: 0.8896 - val_loss: 663.1816 - val_price_loss: 661.7938 - val_rating_loss: 1.0914 - val_level_loss: 0.2965 - val_price_mae: 6.6949 - val_rating_mae: 0.7662 - val_level_accuracy: 0.8812\n",
      "Epoch 5/10\n",
      "114/114 [==============================] - 1s 10ms/step - loss: 1777.1835 - price_loss: 1775.7329 - rating_loss: 1.1421 - level_loss: 0.3079 - price_mae: 5.5204 - rating_mae: 0.6935 - level_accuracy: 0.9283 - val_loss: 375.5878 - val_price_loss: 374.6843 - val_rating_loss: 0.5867 - val_level_loss: 0.3169 - val_price_mae: 5.3709 - val_rating_mae: 0.5672 - val_level_accuracy: 0.8713\n",
      "Epoch 6/10\n",
      "114/114 [==============================] - 1s 9ms/step - loss: 1175.2500 - price_loss: 1173.7422 - rating_loss: 1.2342 - level_loss: 0.2739 - price_mae: 4.8648 - rating_mae: 0.6421 - level_accuracy: 0.9227 - val_loss: 66.9154 - val_price_loss: 63.9701 - val_rating_loss: 2.6691 - val_level_loss: 0.2763 - val_price_mae: 4.8833 - val_rating_mae: 0.7696 - val_level_accuracy: 0.8911\n",
      "Epoch 7/10\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 438.7297 - price_loss: 435.6772 - rating_loss: 2.8213 - level_loss: 0.2311 - price_mae: 5.3165 - rating_mae: 0.9448 - level_accuracy: 0.9459 - val_loss: 34.2608 - val_price_loss: 33.3177 - val_rating_loss: 0.7568 - val_level_loss: 0.1862 - val_price_mae: 4.2711 - val_rating_mae: 0.6593 - val_level_accuracy: 0.9208\n",
      "Epoch 8/10\n",
      "114/114 [==============================] - 1s 11ms/step - loss: 152.0993 - price_loss: 151.0959 - rating_loss: 0.8272 - level_loss: 0.1763 - price_mae: 3.9103 - rating_mae: 0.5892 - level_accuracy: 0.9614 - val_loss: 28.2232 - val_price_loss: 26.4769 - val_rating_loss: 1.5727 - val_level_loss: 0.1735 - val_price_mae: 4.0052 - val_rating_mae: 0.5830 - val_level_accuracy: 0.9307\n",
      "Epoch 9/10\n",
      "114/114 [==============================] - 1s 9ms/step - loss: 39.2938 - price_loss: 35.7239 - rating_loss: 3.4196 - level_loss: 0.1503 - price_mae: 3.0541 - rating_mae: 0.8923 - level_accuracy: 0.9647 - val_loss: 37.4826 - val_price_loss: 31.2987 - val_rating_loss: 6.0542 - val_level_loss: 0.1297 - val_price_mae: 4.2177 - val_rating_mae: 1.0801 - val_level_accuracy: 0.9406\n",
      "Epoch 10/10\n",
      "114/114 [==============================] - 1s 10ms/step - loss: 20.0998 - price_loss: 12.0261 - rating_loss: 7.9355 - level_loss: 0.1382 - price_mae: 2.5904 - rating_mae: 0.8059 - level_accuracy: 0.9790 - val_loss: 32.8651 - val_price_loss: 26.4845 - val_rating_loss: 6.2309 - val_level_loss: 0.1497 - val_price_mae: 3.9896 - val_rating_mae: 0.7688 - val_level_accuracy: 0.9604\n",
      "Mod√®le Keras multit√¢che sauvegard√©\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from tensorflow import keras\n",
    "    from tensorflow.keras import layers\n",
    "    import tensorflow as tf\n",
    "except ImportError:\n",
    "    print(\"TensorFlow non install√©, passage.\")\n",
    "else:\n",
    "    # Split suppl√©mentaire pour validation\n",
    "    X_tr, X_val, y_reg_tr, y_reg_val, y_niveau_tr, y_niveau_val = train_test_split(\n",
    "        X_train, y_reg_train, y_niveau_train, test_size=0.1, random_state=42\n",
    "    )\n",
    "    X_tr = X_tr.toarray().astype(np.float32)\n",
    "    X_val = X_val.toarray().astype(np.float32)\n",
    "    inp = keras.Input(shape=(X_tr.shape[1],), dtype=tf.float32)\n",
    "    x = layers.Dense(256, activation='relu')(inp)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    price_out = layers.Dense(1, name='price')(x)\n",
    "    rating_out = layers.Dense(1, name='rating')(x)\n",
    "    level_out = layers.Dense(len(np.unique(y_niveau_tr)), activation='softmax', name='level')(x)\n",
    "    model = keras.Model(inputs=inp, outputs=[price_out, rating_out, level_out])\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss={'price':'mse','rating':'mse','level':'sparse_categorical_crossentropy'},\n",
    "        metrics={'price':'mae','rating':'mae','level':'accuracy'}\n",
    "    )\n",
    "    model.fit(\n",
    "        X_tr, [y_reg_tr[:,0], y_reg_tr[:,1], y_niveau_tr],\n",
    "        validation_data=(X_val, [y_reg_val[:,0], y_reg_val[:,1], y_niveau_val]),\n",
    "        epochs=10, batch_size=8,\n",
    "        callbacks=[keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True)]\n",
    "    )\n",
    "    model.save('models/keras_multi_task.h5')\n",
    "    print(\"Mod√®le Keras multit√¢che sauvegard√©\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
