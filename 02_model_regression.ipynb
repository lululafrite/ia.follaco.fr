{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07dc1ac9",
   "metadata": {},
   "source": [
    "# Notebook `02_model_regression.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f909cd",
   "metadata": {},
   "source": [
    "## ğŸ§­ Sommaire\n",
    "\n",
    "1. [ğŸ“˜ Importation des bibliothÃ¨ques](#ğŸ“˜-1-importation-des-bibliothÃ¨ques)\n",
    "2. [ğŸ“¦ Chargement des donnÃ©es transformÃ©es](#ğŸ“¦-2-chargement-des-donnÃ©es-transformÃ©es)\n",
    "3. [ğŸ§  Construction des variables explicatives (`X`) et cibles (`y`)](#ğŸ§ -3-construction-des-variables-explicatives-x-et-cibles-y)\n",
    "4. [ğŸ§ª SÃ©paration des donnÃ©es et dÃ©finition des modÃ¨les](#ğŸ§ª-4-sÃ©paration-des-donnÃ©es-et-dÃ©finition-des-modÃ¨les)\n",
    "5. [ğŸ§  EntraÃ®nement, Ã©valuation et sauvegarde des modÃ¨les de rÃ©gression](#ğŸ§ -5-entraÃ®nement-Ã©valuation-et-sauvegarde-des-modÃ¨les-de-rÃ©gression)\n",
    "6. [ğŸ’¾ Sauvegarde du prÃ©processeur et des colonnes de features](#ğŸ’¾-6-sauvegarde-du-prÃ©processeur-et-des-colonnes-de-features)\n",
    "7. [ğŸ RÃ©sultats comparatifs des modÃ¨les de rÃ©gression](#ğŸ-7-rÃ©sultats-comparatifs-des-modÃ¨les-de-rÃ©gression)\n",
    "8. [ğŸ† SÃ©lection du meilleur modÃ¨le de rÃ©gression](#ğŸ†-8-sÃ©lection-du-meilleur-modÃ¨le-de-rÃ©gression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7ce7f5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120aae6d",
   "metadata": {},
   "source": [
    "## ğŸ“ˆ EntraÃ®nement des modÃ¨les de rÃ©gression\n",
    "\n",
    "Ce notebook a pour objectif de construire et Ã©valuer diffÃ©rents **modÃ¨les de rÃ©gression** pour prÃ©dire le **prix dâ€™un service Fiverr** Ã  partir de ses caractÃ©ristiques (texte, fiabilitÃ©, etc.).\n",
    "\n",
    "Nous comparons ici plusieurs algorithmes supervisÃ©s, avec ou sans transformation logarithmique, pour identifier le modÃ¨le le plus robuste.\n",
    "\n",
    "## ğŸ¯ Objectifs\n",
    "\n",
    "- ğŸ” Charger les features et les cibles prÃ©parÃ©es (`X_scaled`, `y_reg`)\n",
    "- ğŸ§  Tester plusieurs modÃ¨les de rÃ©gression (linÃ©aire, arbres, boosting, etc.)\n",
    "- ğŸ“ Ã‰valuer les performances avec des mÃ©triques comme **MAE**, **RMSE** et **RÂ²**\n",
    "- âœ… SÃ©lectionner le meilleur modÃ¨le pour la prÃ©diction du **prix rÃ©el**\n",
    "- ğŸ’¾ Sauvegarder le modÃ¨le retenu pour les Ã©tapes de prÃ©diction et de mise en production\n",
    "\n",
    "## âœ… CompÃ©tences mobilisÃ©es\n",
    "\n",
    "- **Bloc 3 â€” C1** : Comparer les performances de plusieurs algorithmes de rÃ©gression pour choisir le plus adaptÃ© Ã  la problÃ©matique.\n",
    "- **Bloc 3 â€” C2** : Adapter les donnÃ©es Ã  la forme attendue par les modÃ¨les (notamment via `StandardScaler` et transformation `log`).\n",
    "- **Bloc 3 â€” C3** : EntraÃ®ner un modÃ¨le de rÃ©gression en optimisant ses performances selon des indicateurs clairement dÃ©finis (MAE, RMSE, RÂ²).\n",
    "\n",
    "ğŸš€ *Ce notebook permet de poser les fondations du moteur de prÃ©diction de prix utilisÃ© dans l'application finale.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d647494d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de00436",
   "metadata": {},
   "source": [
    "## ğŸ“˜ 1. Importation des bibliothÃ¨ques\n",
    "\n",
    "### â“ 1.1. Pourquoi cette Ã©tape ?\n",
    "\n",
    "Avant dâ€™entamer le processus de modÃ©lisation, il est indispensable dâ€™importer toutes les bibliothÃ¨ques nÃ©cessaires au traitement des donnÃ©es, Ã  lâ€™entraÃ®nement des modÃ¨les et Ã  leur Ã©valuation.\n",
    "\n",
    "Les modules importÃ©s ici permettent de :\n",
    "\n",
    "- **Charger et manipuler** les donnÃ©es (`pandas`, `numpy`, `os`, `joblib`)\n",
    "- **PrÃ©parer les jeux de donnÃ©es** (`train_test_split`, `StandardScaler`)\n",
    "- **EntraÃ®ner plusieurs types de modÃ¨les de rÃ©gression** :\n",
    "  - `LinearRegression`, `Ridge`\n",
    "  - `DecisionTreeRegressor`, `RandomForestRegressor`\n",
    "  - `GradientBoostingRegressor`, `XGBRegressor`\n",
    "  - `KNeighborsRegressor`\n",
    "- **Ã‰valuer les performances** via des mÃ©triques (`MAE`, `RMSE`, `RÂ²`)\n",
    "- **GÃ©nÃ©rer des embeddings textuels** Ã  partir de la description (`SentenceTransformer`)\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ 1.2. Script dâ€™importation des bibliothÃ¨ques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d48fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“¦ Importation des bibliothÃ¨ques nÃ©cessaires Ã  la modÃ©lisation\n",
    "\n",
    "# Manipulation de donnÃ©es\n",
    "import pandas as pd                                              # Manipulation de DataFrames\n",
    "import numpy as np                                               # Fonctions mathÃ©matiques avancÃ©es\n",
    "import os                                                        # Interaction avec le systÃ¨me de fichiers\n",
    "import joblib                                                    # Sauvegarde et chargement de modÃ¨les\n",
    "\n",
    "# PrÃ©paration des donnÃ©es\n",
    "from sklearn.model_selection import train_test_split             # DÃ©coupe en train/test\n",
    "from sklearn.preprocessing import StandardScaler                 # Normalisation des donnÃ©es numÃ©riques\n",
    "\n",
    "# ModÃ¨les de rÃ©gression standards\n",
    "from sklearn.linear_model import LinearRegression, Ridge         # RÃ©gressions linÃ©aires (classique et rÃ©gularisÃ©e)\n",
    "from sklearn.ensemble import RandomForestRegressor               # ForÃªts alÃ©atoires\n",
    "from sklearn.ensemble import GradientBoostingRegressor           # Boosting\n",
    "from sklearn.tree import DecisionTreeRegressor                   # Arbre de rÃ©gression simple\n",
    "from sklearn.neighbors import KNeighborsRegressor                # RÃ©gression par les k plus proches voisins\n",
    "from xgboost import XGBRegressor                                 # RÃ©gression boostÃ©e performante (XGBoost)\n",
    "\n",
    "# Ã‰valuation des performances\n",
    "from sklearn.metrics import mean_absolute_error                  # - MAE : erreur absolue moyenne\n",
    "from sklearn.metrics import  mean_squared_error                  # - MSE : erreur quadratique moyenne\n",
    "from sklearn.metrics import r2_score                             # - RÂ² : coefficient de dÃ©termination (qualitÃ© d'ajustement)\n",
    "\n",
    "# NLP - Embeddings de texte\n",
    "from sentence_transformers import SentenceTransformer            # GÃ©nÃ©ration de vecteurs Ã  partir de texte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8270230",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bd75e7",
   "metadata": {},
   "source": [
    "## ğŸ“¦ 2. Chargement des donnÃ©es transformÃ©es\n",
    "\n",
    "### â“ 2.1. Pourquoi cette Ã©tape maintenant ?\n",
    "\n",
    "AprÃ¨s le prÃ©traitement complet du jeu de donnÃ©es brut, nous avons sauvegardÃ© une version transformÃ©e et enrichie (`fiverr_cleaned_transformed.csv`).  \n",
    "Cette Ã©tape consiste Ã  **recharger ce fichier prÃ©parÃ©** pour dÃ©marrer la phase de modÃ©lisation.\n",
    "\n",
    "Ce fichier contient :\n",
    "- Des **colonnes nettoyÃ©es et prÃªtes Ã  lâ€™emploi** : `Description`, `Niveau`, `Prix`, `Fiabilite`, etc.\n",
    "- Les **valeurs manquantes imputÃ©es**\n",
    "- Les descriptions textuelles **nettoyÃ©es des stopwords** et formules types\n",
    "- Des formats unifiÃ©s (`float`, `str`, etc.)\n",
    "\n",
    "### ğŸ¯ 2.2. RÃ©sultat attendu\n",
    "\n",
    "- Les donnÃ©es sont chargÃ©es dans un objet `DataFrame` nommÃ© `df`.\n",
    "- Elles sont prÃªtes Ã  Ãªtre utilisÃ©es pour la phase de modÃ©lisation (rÃ©gression et/ou classification).\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ 2.3. Script de chargement des donnÃ©es transformÃ©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d603eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“¥ Chargement du jeu de donnÃ©es transformÃ©\n",
    "\n",
    "# ğŸ”¹ Lecture du fichier CSV contenant les donnÃ©es nettoyÃ©es et enrichies\n",
    "# - Le fichier 'fiverr_cleaned_transformed.csv' est issu des Ã©tapes prÃ©cÃ©dentes de prÃ©processing.\n",
    "# - Il contient dÃ©jÃ  les colonnes prÃªtes Ã  Ãªtre utilisÃ©es pour l'entraÃ®nement des modÃ¨les (ex. : Description nettoyÃ©e, FiabilitÃ©, Niveau, Prix, etc.)\n",
    "\n",
    "df = pd.read_csv(\"data/fiverr_cleaned_transformed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b7c68e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3674825b",
   "metadata": {},
   "source": [
    "## ğŸ§  3. Construction des variables explicatives (`X`) et cibles (`y`)\n",
    "\n",
    "### â“ 3.1. Pourquoi cette Ã©tape maintenant ?\n",
    "\n",
    "Nous allons maintenant prÃ©parer les **donnÃ©es dâ€™entrÃ©e du modÃ¨le** (`X`) et la **variable Ã  prÃ©dire** (`y`), Ã  partir du fichier transformÃ©.  \n",
    "Les colonnes choisies sont prÃªtes Ã  lâ€™emploi grÃ¢ce aux Ã©tapes prÃ©cÃ©dentes (nettoyage, vectorisation, standardisation).\n",
    "\n",
    "### ğŸ”§ 3.2. DÃ©tails des transformations effectuÃ©es\n",
    "\n",
    "| Ã‰tape | Description |\n",
    "|-------|-------------|\n",
    "| ğŸ§© Embedding | Les titres de service (`Description`) sont transformÃ©s en **vecteurs numÃ©riques de 384 dimensions** via un modÃ¨le prÃ©-entraÃ®nÃ© (`all-MiniLM-L6-v2`). |\n",
    "| âš–ï¸ Normalisation | La variable `Fiabilite` est **standardisÃ©e** Ã  lâ€™aide dâ€™un `StandardScaler`. Cela amÃ©liore la performance de nombreux modÃ¨les. |\n",
    "| ğŸ§· Fusion | Les embeddings et la fiabilitÃ© standardisÃ©e sont **fusionnÃ©s horizontalement** dans une matrice `X` utilisÃ©e pour l'entraÃ®nement. |\n",
    "| ğŸ¯ Cibles | Deux cibles sont dÃ©finies : `y_log` (log du prix pour l'entraÃ®nement) et `y_real` (prix rÃ©el pour lâ€™Ã©valuation des performances). |\n",
    "\n",
    "> ğŸ’¡ Remarque : le one-hot encoding de `Niveau` peut Ãªtre rÃ©intÃ©grÃ© ultÃ©rieurement si l'on souhaite inclure cette variable dans les features.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ 3.3. Script de construction des variables explicatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625bcec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfab1a881ae344d29ac73eba4a3515db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ğŸ“ Ã‰tape 1 : GÃ©nÃ©ration des embeddings Ã  partir des descriptions textuelles\n",
    "\n",
    "# ğŸ”¸ ModÃ¨le prÃ©-entraÃ®nÃ© pour transformer le texte en vecteurs numÃ©riques (384 dimensions)\n",
    "embedding_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# ğŸ”¸ Transformation de chaque description textuelle en vecteur dense\n",
    "# - On s'assure que la colonne Description est bien convertie en chaÃ®ne de caractÃ¨res\n",
    "# - Le paramÃ¨tre show_progress_bar=True affiche une barre de progression utile en cas de grand volume\n",
    "embeddings = embedding_model.encode(df[\"Description\"].astype(str).tolist(), show_progress_bar=True)\n",
    "\n",
    "# ğŸ”¸ Conversion en DataFrame avec noms explicites pour chaque dimension\n",
    "embed_df = pd.DataFrame(embeddings, columns=[f\"emb_{i}\" for i in range(384)])\n",
    "\n",
    "# ğŸ“ Ã‰tape 2 : Encodage one-hot du niveau (commentÃ© ici si non utilisÃ©)\n",
    "# - Utile si l'on souhaite intÃ©grer le niveau du vendeur dans le modÃ¨le\n",
    "# niveau_encoded = pd.get_dummies(df[\"Niveau\"], prefix=\"Niveau\")\n",
    "\n",
    "# ğŸ“ Ã‰tape 3 : Standardisation de la variable FiabilitÃ©\n",
    "\n",
    "# - Le StandardScaler transforme la variable pour quâ€™elle ait une moyenne de 0 et un Ã©cart-type de 1\n",
    "# - Cela facilite la convergence des algorithmes sensibles Ã  lâ€™Ã©chelle (ex. : rÃ©gression, KNN...)\n",
    "scaler = StandardScaler()\n",
    "fiabilite_scaled = scaler.fit_transform(df[[\"Fiabilite\"]])\n",
    "\n",
    "# ğŸ”¸ Conversion en DataFrame avec nom de colonne conservÃ©\n",
    "fiabilite_df = pd.DataFrame(fiabilite_scaled, columns=[\"Fiabilite\"])\n",
    "\n",
    "# ğŸ“ Ã‰tape 4 : Fusion des diffÃ©rentes sources de donnÃ©es\n",
    "\n",
    "# - On concatÃ¨ne horizontalement les embeddings textuels et la fiabilitÃ© normalisÃ©e\n",
    "# - Le DataFrame final `X` est lâ€™ensemble des features utilisÃ©es pour lâ€™entraÃ®nement\n",
    "X = pd.concat([embed_df, fiabilite_df], axis=1)\n",
    "\n",
    "# ğŸ“Œ Cibles Ã  prÃ©dire\n",
    "# - y_log : version logarithmique du prix (pour modÃ¨le)\n",
    "# - y_real : prix rÃ©el (pour interprÃ©tation ou Ã©valuation)\n",
    "y_log = df[\"Prix_log\"]\n",
    "y_real = df[\"Prix\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8769b2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb4d5c0",
   "metadata": {},
   "source": [
    "## ğŸ§ª 4. SÃ©paration des donnÃ©es et dÃ©finition des modÃ¨les\n",
    "\n",
    "### â“ 4.1. Pourquoi cette Ã©tape maintenant ?\n",
    "\n",
    "Avant de tester nos modÃ¨les, il est indispensable de :\n",
    "1. **Diviser le jeu de donnÃ©es** en un ensemble d'entraÃ®nement (80 %) et un ensemble de test (20 %) ;\n",
    "2. **DÃ©finir une sÃ©lection de modÃ¨les** Ã  comparer objectivement sur les mÃªmes donnÃ©es.\n",
    "\n",
    "### ğŸ”„ 4.2. DÃ©tails de la division train/test\n",
    "\n",
    "| Variable        | RÃ´le                                      |\n",
    "|----------------|-------------------------------------------|\n",
    "| `X_train`       | DonnÃ©es d'entraÃ®nement (features)         |\n",
    "| `X_test`        | DonnÃ©es de test (features)                |\n",
    "| `y_train`       | Prix log transformÃ© â€” Ã  prÃ©dire (train)   |\n",
    "| `y_test`        | Prix log transformÃ© â€” Ã  prÃ©dire (test)    |\n",
    "| `y_real_train`  | Prix rÃ©el pour comparaison Ã©ventuelle     |\n",
    "| `y_real_test`   | Prix rÃ©el pour lâ€™Ã©valuation des erreurs   |\n",
    "\n",
    "### ğŸ¤– 4.3. ModÃ¨les sÃ©lectionnÃ©s pour la rÃ©gression\n",
    "\n",
    "| ModÃ¨le               | Description rapide                           |\n",
    "|----------------------|----------------------------------------------|\n",
    "| `LinearRegression`   | RÃ©gression linÃ©aire classique                |\n",
    "| `Ridge`              | RÃ©gression linÃ©aire avec rÃ©gularisation L2   |\n",
    "| `RandomForest`       | AgrÃ©gation dâ€™arbres dÃ©cisionnels (bagging)   |\n",
    "| `GradientBoosting`   | EntraÃ®nement sÃ©quentiel dâ€™arbres faibles     |\n",
    "| `XGBoost`            | Boosting optimisÃ© trÃ¨s performant            |\n",
    "| `DecisionTree`       | Arbre de dÃ©cision unique                     |\n",
    "| `KNN Regressor`      | Moyenne des k plus proches voisins           |\n",
    "\n",
    "> âš ï¸ Tous les modÃ¨les seront entraÃ®nÃ©s sur les **mÃªmes donnÃ©es** et Ã©valuÃ©s selon des mÃ©triques identiques pour un comparatif juste.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ 4.4. Script de sÃ©paration des donnÃ©es et dÃ©finition des modÃ¨les"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174cc7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Š Ã‰tape 1 : SÃ©paration des donnÃ©es en ensembles d'entraÃ®nement et de test\n",
    "\n",
    "# â¤ X         : matrice des caractÃ©ristiques (embeddings + fiabilitÃ©)\n",
    "# â¤ y_log     : prix transformÃ© en Ã©chelle logarithmique (cible d'entraÃ®nement)\n",
    "# â¤ y_real    : prix rÃ©el (utilisÃ© uniquement pour l'Ã©valuation, pas pour l'entraÃ®nement)\n",
    "\n",
    "# ParamÃ¨tres :\n",
    "# - test_size=0.2        : 20 % des donnÃ©es seront utilisÃ©es pour les tests\n",
    "# - random_state=42      : graine alÃ©atoire pour garantir la reproductibilitÃ©\n",
    "\n",
    "X_train, X_test, y_train, y_test, y_real_train, y_real_test = train_test_split(\n",
    "    X, y_log, y_real, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# ğŸ¤– Ã‰tape 2 : DÃ©finition des modÃ¨les de rÃ©gression Ã  comparer\n",
    "\n",
    "# â¤ Chaque modÃ¨le est instanciÃ© avec des paramÃ¨tres de base cohÃ©rents\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),                                            # - LinearRegression : modÃ¨le linÃ©aire de base\n",
    "    \"Ridge\": Ridge(alpha=1.0),                                                          # - Ridge : rÃ©gression linÃ©aire avec rÃ©gularisation L2      \n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),          # - Random Forest    : ensemble dâ€™arbres (100 arbres, alÃ©atoire fixÃ©)\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(n_estimators=100, random_state=42),  # - Gradient Boosting: boosting dâ€™arbres (100 itÃ©rations, alÃ©atoire fixÃ©)\n",
    "    \"XGBoost\": XGBRegressor(n_estimators=100, random_state=42, verbosity=0),            # - XGBoost          : gradient boosting trÃ¨s performant (100 arbres, verbositÃ© coupÃ©e)    \n",
    "    \"Decision Tree\": DecisionTreeRegressor(random_state=42),                            # - Decision Tree    : arbre unique, simple Ã  interprÃ©ter\n",
    "    \"KNN Regressor\": KNeighborsRegressor(n_neighbors=5)                                 # - KNN              : rÃ©gression par les k plus proches voisins (ici k=5)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b886b3f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbc81f8",
   "metadata": {},
   "source": [
    "## ğŸ§  5. EntraÃ®nement, Ã©valuation et sauvegarde des modÃ¨les de rÃ©gression\n",
    "\n",
    "### ğŸ¯ 5.1. Objectif\n",
    "\n",
    "Comparer les performances de plusieurs modÃ¨les de rÃ©gression sur la prÃ©diction du **prix rÃ©el**, Ã  partir de la cible log-transformÃ©e (`Prix_log`).  \n",
    "Nous allons :\n",
    "- entraÃ®ner chaque modÃ¨le sur les mÃªmes donnÃ©es (`X_train`, `y_train`),\n",
    "- prÃ©dire sur les mÃªmes donnÃ©es de test (`X_test`),\n",
    "- Ã©valuer les performances selon 3 mÃ©triques principales.\n",
    "\n",
    "### ğŸ“ 5.2. MÃ©triques utilisÃ©es\n",
    "\n",
    "| MÃ©trique | Signification                             |\n",
    "|----------|-------------------------------------------|\n",
    "| MAE      | Erreur absolue moyenne                    |\n",
    "| RMSE     | Erreur quadratique moyenne                |\n",
    "| RÂ²       | Coefficient de dÃ©termination              |\n",
    "\n",
    "> ğŸ” Tous les rÃ©sultats sont **calculÃ©s Ã  partir des prix rÃ©els** (aprÃ¨s transformation inverse du log).\n",
    "\n",
    "### ğŸ’¾ 5.3. Sauvegarde automatique\n",
    "\n",
    "Chaque modÃ¨le est enregistrÃ© automatiquement dans le dossier :\n",
    "\n",
    "\n",
    "### ğŸ¥‡ 5.4. SÃ©lection du meilleur modÃ¨le\n",
    "\n",
    "Le **modÃ¨le ayant le plus petit RMSE** est conservÃ© comme meilleur modÃ¨le (`best_model`), et son nom est stockÃ© pour une utilisation future.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ 5.5. Script de sÃ©lection du meilleur modÃ¨le\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151d60b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ EntraÃ®nement et Ã©valuation de tous les modÃ¨les de rÃ©gression\n",
    "\n",
    "results = []                          # Liste pour stocker les scores de chaque modÃ¨le\n",
    "best_model = None                    # Pour conserver le meilleur modÃ¨le trouvÃ©\n",
    "best_rmse = float('inf')             # Initialisation du plus petit RMSE Ã  lâ€™infini\n",
    "\n",
    "# ğŸ” Boucle sur chaque modÃ¨le du dictionnaire\n",
    "for name, model in models.items():\n",
    "    # â–¶ï¸ EntraÃ®nement du modÃ¨le sur l'ensemble d'entraÃ®nement\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # ğŸ”® PrÃ©diction sur lâ€™ensemble de test (prix en Ã©chelle log)\n",
    "    y_pred_log = model.predict(X_test)\n",
    "\n",
    "    # ğŸ” Transformation inverse pour retrouver les prix rÃ©els\n",
    "    y_pred = np.expm1(y_pred_log)\n",
    "\n",
    "    # ğŸ“Š Calcul des mÃ©triques dâ€™Ã©valuation\n",
    "    mae = mean_absolute_error(y_real_test, y_pred)  # Erreur absolue moyenne\n",
    "    rmse = np.sqrt(mean_squared_error(y_real_test, y_pred))  # Erreur quadratique moyenne\n",
    "    r2 = r2_score(y_real_test, y_pred)  # Coefficient de dÃ©termination\n",
    "\n",
    "    # ğŸ§¾ Stockage des rÃ©sultats arrondis dans une liste de dictionnaires\n",
    "    results.append({\n",
    "        \"ModÃ¨le\": name,\n",
    "        \"MAE\": round(mae, 2),\n",
    "        \"RMSE\": round(rmse, 2),\n",
    "        \"RÂ²\": round(r2, 4)\n",
    "    })\n",
    "\n",
    "    # ğŸ’¾ Sauvegarde du modÃ¨le entraÃ®nÃ© dans le dossier appropriÃ©\n",
    "    model_filename = f\"{name.replace(' ', '_').lower()}.pkl\"\n",
    "    joblib.dump(model, f\"models/regression/{model_filename}\")\n",
    "\n",
    "    # âœ… Suivi du meilleur modÃ¨le (basÃ© sur le plus petit RMSE)\n",
    "    if rmse < best_rmse:\n",
    "        best_rmse = rmse\n",
    "        best_model = model\n",
    "        best_name = name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876bcd05",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614a0d21",
   "metadata": {},
   "source": [
    "## ğŸ’¾ 6. Sauvegarde du prÃ©processeur et des colonnes de features\n",
    "\n",
    "### ğŸ¯ 6.1. Objectif\n",
    "\n",
    "Pour garantir que le pipeline de prÃ©diction future soit **reproductible et cohÃ©rent**, il est indispensable de sauvegarder :\n",
    "- le **scaler** utilisÃ© pour la standardisation de la colonne `Fiabilite` (ici : `StandardScaler`),\n",
    "- la **liste exacte des colonnes** utilisÃ©es comme features (noms et ordre).\n",
    "\n",
    "Cela Ã©vite les erreurs de transformation ou de dimensions lors de l'infÃ©rence en production ou dans lâ€™application Gradio.\n",
    "\n",
    "### ğŸ§± 6.2. Ã‰lÃ©ments sauvegardÃ©s\n",
    "\n",
    "| Ã‰lÃ©ment         | Chemin de sauvegarde                  | Description |\n",
    "|-----------------|----------------------------------------|-------------|\n",
    "| `scaler`        | `models/regression/scaler.pkl`        | Objet `StandardScaler` entraÃ®nÃ© sur la fiabilitÃ© |\n",
    "| `columns_used`  | `models/columns_used.pkl`             | Liste ordonnÃ©e des noms de colonnes de `X` |\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ 6.3. Script de sauvegarde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648dd18c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/columns_used.pkl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ğŸ’¾ Sauvegarde du scaler et des colonnes utilisÃ©es\n",
    "\n",
    "# Le modÃ¨le sÃ©lectionnÃ© (best_model) a dÃ©jÃ  Ã©tÃ© sauvegardÃ© prÃ©cÃ©demment dans la boucle.\n",
    "# Ici, nous sauvegardons le prÃ©processeur utilisÃ© (StandardScaler) et la liste des colonnes du jeu de donnÃ©es final.\n",
    "\n",
    "# ğŸ”§ Sauvegarde du scaler utilisÃ© pour la standardisation de la variable 'Fiabilite'\n",
    "# Cela permettra de reproduire exactement la mÃªme transformation Ã  l'infÃ©rence\n",
    "joblib.dump(scaler, \"models/regression/scaler.pkl\")\n",
    "\n",
    "# ğŸ§¾ Sauvegarde de la liste des colonnes utilisÃ©es dans X (ordre et noms)\n",
    "# Utile pour reconstituer la mÃªme matrice de features Ã  la prÃ©diction\n",
    "joblib.dump(X.columns.tolist(), \"models/columns_used.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc140c03",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79aa1767",
   "metadata": {},
   "source": [
    "## ğŸ 7. RÃ©sultats comparatifs des modÃ¨les de rÃ©gression\n",
    "\n",
    "### ğŸ“Š 7.1. Tableau de synthÃ¨se des performances\n",
    "\n",
    "Une fois les modÃ¨les entraÃ®nÃ©s, nous comparons leurs performances sur lâ€™ensemble de test Ã  lâ€™aide des mÃ©triques suivantes :\n",
    "\n",
    "| ModÃ¨le              | MAE  | RMSE | RÂ²    |\n",
    "|---------------------|------|------|-------|\n",
    "| ... (ex. Ridge, RF) | ...  | ...  | ...   |\n",
    "\n",
    "Le tableau est triÃ© selon la **valeur croissante du RMSE**, afin de visualiser directement les modÃ¨les les plus performants.\n",
    "\n",
    "> â„¹ï¸ Toutes les mÃ©triques sont calculÃ©es **sur les prix rÃ©els**, aprÃ¨s transformation inverse du logarithme.\n",
    "\n",
    "### ğŸ¥‡ 7.2. Meilleur modÃ¨le sÃ©lectionnÃ©\n",
    "\n",
    "Le **modÃ¨le ayant obtenu le plus faible RMSE** est automatiquement sÃ©lectionnÃ© comme modÃ¨le final (`best_model`).  \n",
    "Son nom est affichÃ© Ã  la fin du tableau pour confirmation.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ 7.3. Script dâ€™affichage des performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60311057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š RÃ©sultats comparatifs (Ã©valuÃ©s sur les vrais prix) :\n",
      "\n",
      "| ModÃ¨le            |   MAE |   RMSE |      RÂ² |\n",
      "|:------------------|------:|-------:|--------:|\n",
      "| Gradient Boosting |  3.21 |   4.9  |  0.2566 |\n",
      "| XGBoost           |  3.33 |   5    |  0.2274 |\n",
      "| Random Forest     |  3.32 |   5.03 |  0.2173 |\n",
      "| Ridge             |  3.82 |   5.47 |  0.0748 |\n",
      "| KNN Regressor     |  3.99 |   5.8  | -0.0407 |\n",
      "| Decision Tree     |  4.43 |   7.14 | -0.577  |\n",
      "| Linear Regression |  5.86 |   9.9  | -2.0353 |\n",
      "\n",
      "âœ… Meilleur modÃ¨le : Gradient Boosting (RMSE = 4.9)\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“Š Affichage des rÃ©sultats comparatifs des modÃ¨les de rÃ©gression\n",
    "\n",
    "# âœ… Transformation de la liste des rÃ©sultats en DataFrame et tri par RMSE (croissant)\n",
    "df_results = pd.DataFrame(results).sort_values(\"RMSE\")\n",
    "\n",
    "# ğŸ–¨ï¸ Affichage formatÃ© des rÃ©sultats en tableau Markdown\n",
    "print(\"ğŸ“Š RÃ©sultats comparatifs (Ã©valuÃ©s sur les vrais prix) :\\n\")\n",
    "print(df_results.to_markdown(index=False))  # affichage lisible dans les notebooks / consoles\n",
    "\n",
    "# ğŸ¥‡ Rappel du meilleur modÃ¨le\n",
    "print(f\"\\nâœ… Meilleur modÃ¨le : {best_name} (RMSE = {round(best_rmse, 2)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62ee0e2",
   "metadata": {},
   "source": [
    "## ğŸ† 8. SÃ©lection du meilleur modÃ¨le de rÃ©gression\n",
    "\n",
    "AprÃ¨s avoir entraÃ®nÃ© et comparÃ© **7 modÃ¨les de rÃ©gression**, leurs performances ont Ã©tÃ© Ã©valuÃ©es selon trois mÃ©triques essentielles :  \n",
    "- **MAE** : Erreur absolue moyenne (plus câ€™est bas, mieux câ€™est)  \n",
    "- **RMSE** : Racine de l'erreur quadratique moyenne (plus câ€™est bas, mieux câ€™est)  \n",
    "- **RÂ²** : Coefficient de dÃ©termination (plus câ€™est proche de 1, mieux câ€™est)\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“Š 8.1. RÃ©sultats comparatifs (Ã©valuÃ©s sur les vrais prix)\n",
    "\n",
    "| ModÃ¨le            |   MAE |   RMSE |    RÂ²    |\n",
    "|-------------------|-------|--------|----------|\n",
    "| **Gradient Boosting** |  3.21 |   4.90 | **0.2566** |\n",
    "| XGBoost           |  3.33 |   5.00 | 0.2274   |\n",
    "| Random Forest     |  3.32 |   5.03 | 0.2173   |\n",
    "| Ridge             |  3.82 |   5.47 | 0.0748   |\n",
    "| KNN Regressor     |  3.99 |   5.80 | -0.0407  |\n",
    "| Decision Tree     |  4.43 |   7.14 | -0.5770  |\n",
    "| Linear Regression |  5.86 |   9.90 | -2.0353  |\n",
    "\n",
    "âœ… **Meilleur modÃ¨le : Gradient Boosting (RMSE = 4.90)**\n",
    "\n",
    "---\n",
    "\n",
    "â„¹ï¸ **Remarque sur le choix du modÃ¨le**\n",
    "\n",
    " Le modÃ¨le `Gradient Boosting` sâ€™est imposÃ© comme le plus performant sur les donnÃ©es de test, avec :\n",
    " - la **plus faible erreur quadratique moyenne (RMSE)**,\n",
    " - un **coefficient RÂ² positif**, montrant une bonne capacitÃ© de gÃ©nÃ©ralisation.\n",
    "\n",
    "Ce modÃ¨le sera donc utilisÃ© pour la suite de lâ€™analyse et dans lâ€™application finale."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
