{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81b50826",
   "metadata": {},
   "source": [
    "## üéØ Objectif du notebook `06_predict.ipynb`\n",
    "\n",
    "Ce notebook a pour objectif de **charger les meilleurs mod√®les** s√©lectionn√©s lors des √©tapes pr√©c√©dentes et de **r√©aliser des pr√©dictions** sur de nouvelles donn√©es.\n",
    "\n",
    "### ‚ùì Pourquoi ne teste-t-on pas plusieurs mod√®les ici ?\n",
    "\n",
    "Les mod√®les utilis√©s sont ceux ayant d√©j√† √©t√© **rigoureusement compar√©s et valid√©s** dans les notebooks pr√©c√©dents :\n",
    "\n",
    "- üìò `03_model_regression.ipynb`  \n",
    "  ‚û§ S√©lection du mod√®le **XGBoost** comme meilleur pr√©dicteur de prix, bas√© sur les m√©triques MAE, RMSE, et R¬≤.\n",
    "\n",
    "- üìò `04_model_classification.ipynb`  \n",
    "  ‚û§ S√©lection du mod√®le **Random Forest** pour la classification binaire (tranche de prix), avec un score **Accuracy > 96%**.\n",
    "\n",
    "Il ne s‚Äôagit donc **pas ici de r√©entra√Æner ni de comparer d‚Äôautres mod√®les**, mais de :\n",
    "- charger les mod√®les finalis√©s,\n",
    "- appliquer les transformations n√©cessaires,\n",
    "- produire les pr√©dictions finales.\n",
    "\n",
    "Cette approche garantit :\n",
    "- la **coh√©rence avec l‚Äôensemble du pipeline**,\n",
    "- un **gain de temps** pour les pr√©dictions r√©elles,\n",
    "- une **tra√ßabilit√© claire** des choix m√©thodologiques pour la soutenance.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0166a017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Sauvegard√© : fiverr_predicted_decision_tree__decision_tree.csv\n",
      "‚úÖ Sauvegard√© : fiverr_predicted_decision_tree__knn_classifier.csv\n",
      "‚úÖ Sauvegard√© : fiverr_predicted_decision_tree__logistic_regression.csv\n",
      "‚úÖ Sauvegard√© : fiverr_predicted_decision_tree__random_forest.csv\n",
      "‚úÖ Sauvegard√© : fiverr_predicted_gradient_boosting__decision_tree.csv\n",
      "‚úÖ Sauvegard√© : fiverr_predicted_gradient_boosting__knn_classifier.csv\n",
      "‚úÖ Sauvegard√© : fiverr_predicted_gradient_boosting__logistic_regression.csv\n",
      "‚úÖ Sauvegard√© : fiverr_predicted_gradient_boosting__random_forest.csv\n",
      "‚úÖ Sauvegard√© : fiverr_predicted_knn_regressor__decision_tree.csv\n",
      "‚úÖ Sauvegard√© : fiverr_predicted_knn_regressor__knn_classifier.csv\n",
      "‚úÖ Sauvegard√© : fiverr_predicted_knn_regressor__logistic_regression.csv\n",
      "‚úÖ Sauvegard√© : fiverr_predicted_knn_regressor__random_forest.csv\n",
      "‚úÖ Sauvegard√© : fiverr_predicted_linear_regression__decision_tree.csv\n",
      "‚úÖ Sauvegard√© : fiverr_predicted_linear_regression__knn_classifier.csv\n",
      "‚úÖ Sauvegard√© : fiverr_predicted_linear_regression__logistic_regression.csv\n",
      "‚úÖ Sauvegard√© : fiverr_predicted_linear_regression__random_forest.csv\n",
      "‚úÖ Sauvegard√© : fiverr_predicted_random_forest__decision_tree.csv\n",
      "‚úÖ Sauvegard√© : fiverr_predicted_random_forest__knn_classifier.csv\n",
      "‚úÖ Sauvegard√© : fiverr_predicted_random_forest__logistic_regression.csv\n",
      "‚úÖ Sauvegard√© : fiverr_predicted_random_forest__random_forest.csv\n",
      "‚úÖ Sauvegard√© : fiverr_predicted_ridge__decision_tree.csv\n",
      "‚úÖ Sauvegard√© : fiverr_predicted_ridge__knn_classifier.csv\n",
      "‚úÖ Sauvegard√© : fiverr_predicted_ridge__logistic_regression.csv\n",
      "‚úÖ Sauvegard√© : fiverr_predicted_ridge__random_forest.csv\n",
      "‚úÖ Sauvegard√© : fiverr_predicted_xgboost__decision_tree.csv\n",
      "‚úÖ Sauvegard√© : fiverr_predicted_xgboost__knn_classifier.csv\n",
      "‚úÖ Sauvegard√© : fiverr_predicted_xgboost__logistic_regression.csv\n",
      "‚úÖ Sauvegard√© : fiverr_predicted_xgboost__random_forest.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# üìò 06_predict.ipynb ‚Äî √âvaluation crois√©e de toutes les paires de mod√®les\\n\\nimport os\\nimport pandas as pd\\nimport joblib\\nfrom sentence_transformers import SentenceTransformer\\n\\n# ------------------------------------------------------------\\n# üîß Configuration\\n# ------------------------------------------------------------\\nREGRESSION_MODELS = [\\n    \"decision_tree\",\\n    \"gradient_boosting\",\\n    \"knn_regressor\",\\n    \"linear_regression\",\\n    \"random_forest\",\\n    \"ridge\",\\n    \"xgboost\"\\n]\\n\\nCLASSIFICATION_MODELS = [\\n    \"decision_tree\",\\n    \"knn_classifier\",\\n    \"logistic_regression\",\\n    \"random_forest\"\\n]\\n\\nMODEL_DIR_REG = \"models/regression\"\\nMODEL_DIR_CLF = \"models/classification\"\\nSCALER_PATH = \"models/regression/scaler.pkl\"\\nCOLUMNS_PATH = \"models/columns_used.pkl\"\\nOUTPUT_DIR = \"data/predictions_grid\"\\n\\nos.makedirs(OUTPUT_DIR, exist_ok=True)\\n\\n# ------------------------------------------------------------\\n# üîß Chargement des objets communs\\n# ------------------------------------------------------------\\nscaler = joblib.load(SCALER_PATH)\\ncolumns = joblib.load(COLUMNS_PATH)\\nembedding_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\\n\\n# ------------------------------------------------------------\\n# üß± Fonction de transformation\\n# ------------------------------------------------------------\\ndef preprocess_input(description: str, niveau: str, fiabilite: float) -> pd.DataFrame:\\n    emb = embedding_model.encode([description])\\n    emb_dict = {f\"emb_{i}\": emb[0][i] for i in range(384)}\\n    niveau_dict = {\\n        \"Niveau_Beginner\": niveau.lower() == \"beginner\",\\n        \"Niveau_Intermediate\": niveau.lower() == \"intermediate\",\\n        \"Niveau_Expert\": niveau.lower() == \"expert\"\\n    }\\n    row = {**emb_dict, **niveau_dict, \"Fiabilite\": fiabilite}\\n    df = pd.DataFrame([row])\\n    df = df.reindex(columns=columns, fill_value=0)\\n    df[[\"Fiabilite\"]] = scaler.transform(df[[\"Fiabilite\"]])\\n    return df\\n\\n# ------------------------------------------------------------\\n# üß™ Chargement des donn√©es sources\\n# ------------------------------------------------------------\\ndf_source = pd.read_csv(\"data/fiverr_cleaned.csv\")\\ndf_source[\"Niveau\"] = df_source[\"Niveau\"].str.capitalize().replace({\\n    \"Nouveau\": \"Beginner\",\\n    \"Confirm√©\": \"Intermediate\",\\n    \"Top\": \"Expert\"\\n})\\n\\n# ------------------------------------------------------------\\n# üîÅ Boucle sur toutes les paires de mod√®les\\n# ------------------------------------------------------------\\nfor reg_name in REGRESSION_MODELS:\\n    reg_model = joblib.load(f\"{MODEL_DIR_REG}/{reg_name}.pkl\")\\n\\n    for clf_name in CLASSIFICATION_MODELS:\\n        clf_model = joblib.load(f\"{MODEL_DIR_CLF}/{clf_name}.pkl\")\\n\\n        # üîÆ Pr√©diction pour cette paire\\n        df = df_source.copy()\\n        df[\"Prix_pr√©dit\"] = df.apply(\\n            lambda row: round(reg_model.predict(preprocess_input(row[\"Description\"], row[\"Niveau\"], row[\"Fiabilite\"]))[0], 2),\\n            axis=1\\n        )\\n        df[\"Tranche_pr√©vue\"] = df.apply(\\n            lambda row: clf_model.predict(preprocess_input(row[\"Description\"], row[\"Niveau\"], row[\"Fiabilite\"]))[0],\\n            axis=1\\n        )\\n\\n        # üíæ Sauvegarde du fichier de sortie\\n        filename = f\"fiverr_predicted_{reg_name}__{clf_name}.csv\"\\n        df.to_csv(os.path.join(OUTPUT_DIR, filename), index=False)\\n        print(f\"‚úÖ Sauvegard√© : {filename}\")\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# üìò 06_predict.ipynb ‚Äî √âvaluation crois√©e de toutes les paires de mod√®les\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# üîß Configuration\n",
    "REGRESSION_MODELS = [\n",
    "    \"decision_tree\", \"gradient_boosting\", \"knn_regressor\",\n",
    "    \"linear_regression\", \"random_forest\", \"ridge\", \"xgboost\"\n",
    "]\n",
    "\n",
    "CLASSIFICATION_MODELS = [\n",
    "    \"decision_tree\", \"knn_classifier\", \"logistic_regression\", \"random_forest\"\n",
    "]\n",
    "\n",
    "MODEL_DIR_REG = \"models/regression\"\n",
    "MODEL_DIR_CLF = \"models/classification\"\n",
    "SCALER_PATH = \"models/regression/scaler.pkl\"\n",
    "COLUMNS_PATH = \"models/columns_used.pkl\"\n",
    "OUTPUT_DIR = \"data/predictions_grid\"\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# üîß Chargement des objets communs\n",
    "scaler = joblib.load(SCALER_PATH)\n",
    "columns = joblib.load(COLUMNS_PATH)\n",
    "embedding_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# üß± Fonction de pr√©traitement\n",
    "def preprocess_input(description: str, fiabilite: float) -> pd.DataFrame:\n",
    "    emb = embedding_model.encode([description])\n",
    "    emb_dict = {f\"emb_{i}\": emb[0][i] for i in range(384)}\n",
    "    row = {**emb_dict, \"Fiabilite\": fiabilite}\n",
    "    df = pd.DataFrame([row])\n",
    "    df = df.reindex(columns=columns, fill_value=0)\n",
    "    df[[\"Fiabilite\"]] = scaler.transform(df[[\"Fiabilite\"]])\n",
    "    return df\n",
    "\n",
    "# üß™ Chargement des donn√©es sources\n",
    "df_source = pd.read_csv(\"data/fiverr_cleaned_transformed.csv\")\n",
    "\n",
    "# üîÅ Boucle sur toutes les paires de mod√®les\n",
    "for reg_name in REGRESSION_MODELS:\n",
    "    reg_model = joblib.load(f\"{MODEL_DIR_REG}/{reg_name}.pkl\")\n",
    "\n",
    "    for clf_name in CLASSIFICATION_MODELS:\n",
    "        clf_model = joblib.load(f\"{MODEL_DIR_CLF}/{clf_name}.pkl\")\n",
    "\n",
    "        df = df_source.copy()\n",
    "\n",
    "        # üîÆ Pr√©dictions\n",
    "        df[\"Prix_pr√©dit\"] = df.apply(\n",
    "            lambda row: round(np.expm1(reg_model.predict(preprocess_input(row[\"Description\"], row[\"Fiabilite\"]))[0]) * 10, 2),\n",
    "            axis=1\n",
    "        )\n",
    "        df[\"Tranche_pr√©vue\"] = df.apply(\n",
    "            lambda row: clf_model.predict(preprocess_input(row[\"Description\"], row[\"Fiabilite\"]))[0],\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        # üíæ Sauvegarde du fichier de sortie\n",
    "        filename = f\"fiverr_predicted_{reg_name}__{clf_name}.csv\"\n",
    "        df.to_csv(os.path.join(OUTPUT_DIR, filename), index=False)\n",
    "        print(f\"‚úÖ Sauvegard√© : {filename}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cfe5762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà R√©sultats comparatifs des paires (ordonn√©s par RMSE) :\n",
      "\n",
      "| R√©gression        | Classification      |   MAE |   RMSE |   Accuracy |\n",
      "|:------------------|:--------------------|------:|-------:|-----------:|\n",
      "| ridge             | knn_classifier      | 43.67 |  47.76 |     0.5983 |\n",
      "| ridge             | logistic_regression | 43.67 |  47.76 |     0.5956 |\n",
      "| ridge             | random_forest       | 43.67 |  47.76 |     0.9083 |\n",
      "| ridge             | decision_tree       | 43.67 |  47.76 |     0.924  |\n",
      "| knn_regressor     | random_forest       | 46.48 |  53.35 |     0.9083 |\n",
      "| knn_regressor     | knn_classifier      | 46.48 |  53.35 |     0.5983 |\n",
      "| knn_regressor     | decision_tree       | 46.48 |  53.35 |     0.924  |\n",
      "| knn_regressor     | logistic_regression | 46.48 |  53.35 |     0.5956 |\n",
      "| gradient_boosting | logistic_regression | 47.22 |  54.85 |     0.5956 |\n",
      "| gradient_boosting | knn_classifier      | 47.22 |  54.85 |     0.5983 |\n",
      "| gradient_boosting | decision_tree       | 47.22 |  54.85 |     0.924  |\n",
      "| gradient_boosting | random_forest       | 47.22 |  54.85 |     0.9083 |\n",
      "| random_forest     | decision_tree       | 49.02 |  57.85 |     0.924  |\n",
      "| random_forest     | knn_classifier      | 49.02 |  57.85 |     0.5983 |\n",
      "| random_forest     | logistic_regression | 49.02 |  57.85 |     0.5956 |\n",
      "| random_forest     | random_forest       | 49.02 |  57.85 |     0.9083 |\n",
      "| linear_regression | decision_tree       | 52.41 |  73.16 |     0.924  |\n",
      "| linear_regression | logistic_regression | 52.41 |  73.16 |     0.5956 |\n",
      "| linear_regression | random_forest       | 52.41 |  73.16 |     0.9083 |\n",
      "| linear_regression | knn_classifier      | 52.41 |  73.16 |     0.5983 |\n",
      "| xgboost           | decision_tree       | 56.01 |  74.43 |     0.924  |\n",
      "| xgboost           | knn_classifier      | 56.01 |  74.43 |     0.5983 |\n",
      "| xgboost           | random_forest       | 56.01 |  74.43 |     0.9083 |\n",
      "| xgboost           | logistic_regression | 56.01 |  74.43 |     0.5956 |\n",
      "| decision_tree     | random_forest       | 58.63 |  79.66 |     0.9083 |\n",
      "| decision_tree     | logistic_regression | 58.63 |  79.66 |     0.5956 |\n",
      "| decision_tree     | knn_classifier      | 58.63 |  79.66 |     0.5983 |\n",
      "| decision_tree     | decision_tree       | 58.63 |  79.66 |     0.924  |\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# üìÇ R√©pertoire des fichiers de pr√©diction\n",
    "INPUT_DIR = \"data/predictions_grid\"\n",
    "results = []\n",
    "\n",
    "# üîÅ Boucle sur les fichiers de pr√©diction\n",
    "for filename in os.listdir(INPUT_DIR):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        df = pd.read_csv(os.path.join(INPUT_DIR, filename))\n",
    "\n",
    "        # ‚ö†Ô∏è Ajout de la tranche r√©elle si manquante\n",
    "        if \"Tranche_r√©elle\" not in df.columns:\n",
    "            df[\"Tranche_r√©elle\"] = pd.qcut(df[\"Prix\"], q=3, labels=[\"Basse\", \"Moyenne\", \"Haute\"])\n",
    "\n",
    "        # üè∑Ô∏è Extraction des noms de mod√®les\n",
    "        reg_name, clf_name = filename.replace(\".csv\", \"\").replace(\"fiverr_predicted_\", \"\").split(\"__\")\n",
    "\n",
    "        # üìè Calcul des m√©triques\n",
    "        mae = mean_absolute_error(df[\"Prix\"], df[\"Prix_pr√©dit\"])\n",
    "        rmse = np.sqrt(mean_squared_error(df[\"Prix\"], df[\"Prix_pr√©dit\"]))\n",
    "        acc = accuracy_score(df[\"Tranche_r√©elle\"], df[\"Tranche_pr√©vue\"])\n",
    "\n",
    "        results.append({\n",
    "            \"R√©gression\": reg_name,\n",
    "            \"Classification\": clf_name,\n",
    "            \"MAE\": round(mae, 2),\n",
    "            \"RMSE\": round(rmse, 2),\n",
    "            \"Accuracy\": round(acc, 4)\n",
    "        })\n",
    "\n",
    "# üìä Affichage des r√©sultats\n",
    "df_results = pd.DataFrame(results).sort_values(by=\"RMSE\")\n",
    "print(\"üìà R√©sultats comparatifs des paires (ordonn√©s par RMSE) :\\n\")\n",
    "print(df_results.to_markdown(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68ec53a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importance de la variable Fiabilite : 0.2564\n",
      "\n",
      "Top 10 features :\n",
      "Fiabilite    0.256442\n",
      "emb_78       0.057714\n",
      "emb_374      0.030308\n",
      "emb_121      0.024944\n",
      "emb_25       0.021730\n",
      "emb_363      0.021541\n",
      "emb_187      0.020729\n",
      "emb_60       0.018737\n",
      "emb_188      0.016485\n",
      "emb_260      0.016224\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Chargement du mod√®le entra√Æn√© (doit √™tre un mod√®le √† base d‚Äôarbres)\n",
    "reg_model = joblib.load(\"models/regression/decision_tree.pkl\")\n",
    "columns = joblib.load(\"models/columns_used.pkl\")\n",
    "\n",
    "# Importance des variables\n",
    "importances = reg_model.feature_importances_\n",
    "features = pd.Series(importances, index=columns)\n",
    "\n",
    "# Affichage\n",
    "print(\"Importance de la variable Fiabilite :\", round(features[\"Fiabilite\"], 4))\n",
    "print(\"\\nTop 10 features :\")\n",
    "print(features.sort_values(ascending=False).head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
