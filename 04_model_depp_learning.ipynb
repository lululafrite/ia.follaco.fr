{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38364d87",
   "metadata": {},
   "source": [
    "# Notebook `04_model_deep_learning.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16d423b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb1b615",
   "metadata": {},
   "source": [
    "# ğŸ§  Construction et EntraÃ®nement du ModÃ¨le Deep Learning\n",
    "\n",
    "Ce notebook constitue la **quatriÃ¨me Ã©tape du pipeline IA**.  \n",
    "Il est dÃ©diÃ© Ã  la construction, lâ€™entraÃ®nement, lâ€™Ã©valuation et la sauvegarde dâ€™un **modÃ¨le de deep learning** destinÃ© Ã  prÃ©dire le **prix dâ€™un service Fiverr** Ã  partir de variables numÃ©riques et vectorielles.\n",
    "\n",
    "## ğŸ¯ Objectifs\n",
    "\n",
    "- ğŸ“¦ Charger les donnÃ©es propres et transformÃ©es (`fiverr_cleaned_transformed.csv`)\n",
    "- ğŸ§  GÃ©nÃ©rer les **embeddings vectoriels** Ã  partir des descriptions (modÃ¨le `SentenceTransformer`)\n",
    "- ğŸ” PrÃ©parer les **entrÃ©es combinÃ©es** : texte vectorisÃ©, niveau encodÃ©, fiabilitÃ© numÃ©rique\n",
    "- âš™ï¸ DÃ©finir un **modÃ¨le Keras sÃ©quentiel** adaptÃ© Ã  la rÃ©gression\n",
    "- ğŸ§ª RÃ©aliser une **sÃ©paration train/test** et standardiser les variables\n",
    "- ğŸ“ EntraÃ®ner le modÃ¨le avec **early stopping** pour Ã©viter le surapprentissage\n",
    "- ğŸ“‰ Ã‰valuer ses performances sur les donnÃ©es de test\n",
    "- ğŸ’¾ Sauvegarder le modÃ¨le (`deep_model.h5`) et le scaler (`scaler.pkl`)\n",
    "\n",
    "## âœ… CompÃ©tences mobilisÃ©es\n",
    "\n",
    "- **Bloc 3 â€” C3** : ImplÃ©menter un modÃ¨le de deep learning adaptÃ© Ã  un jeu de donnÃ©es structurÃ©\n",
    "- **Bloc 3 â€” C2** : PrÃ©parer les donnÃ©es et normaliser les vecteurs dâ€™entrÃ©e (embedding + features classiques)\n",
    "- **Bloc 5 â€” C4** : Exporter un modÃ¨le exploitable dans un environnement dÃ©ployÃ© (API, Gradio)\n",
    "\n",
    "ğŸ§  *Ce notebook prÃ©pare un modÃ¨le de prÃ©diction avancÃ© basÃ© sur les rÃ©seaux de neurones, utilisÃ© dans lâ€™application finale.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61762ae",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bafbc79",
   "metadata": {},
   "source": [
    "## ğŸ§­ Sommaire\n",
    "\n",
    "1. [ğŸ§  Importation des bibliothÃ¨ques pour le Deep Learning](#-1-importation-des-bibliothÃ¨ques-pour-le-deep-learning)\n",
    "2. [ğŸ“‚ Chargement des donnÃ©es transformÃ©es dans un DataFrame Pandas](#-2-chargement-des-donnÃ©es-transformÃ©es-dans-un-dataframe-pandas)\n",
    "3. [ğŸ§ª PrÃ©paration des donnÃ©es pour le Deep Learning](#-3-prÃ©paration-des-donnÃ©es-pour-le-deep-learning)\n",
    "4. [ğŸ§  Construction du modÃ¨le MLP (rÃ©gression du prix)](#-4-construction-du-modÃ¨le-mlp-rÃ©gression-du-prix)\n",
    "5. [ğŸ‹ï¸â€â™‚ï¸ EntraÃ®nement du modÃ¨le avec EarlyStopping](#-5-entraÃ®nement-du-modÃ¨le-avec-earlystopping)\n",
    "6. [ğŸ§ª Ã‰valuation du modÃ¨le entraÃ®nÃ©](#-6-Ã©valuation-du-modÃ¨le-entraÃ®nÃ©)\n",
    "7. [ğŸ’¾ Sauvegarde du modÃ¨le Deep Learning entraÃ®nÃ©](#-7-sauvegarde-du-modÃ¨le-deep-learning-entraÃ®nÃ©)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14adee5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46169b50",
   "metadata": {},
   "source": [
    "## ğŸ§  1. Importation des bibliothÃ¨ques pour le Deep Learning\n",
    "\n",
    "### â“ 1.1. Pourquoi cette Ã©tape maintenant ?\n",
    "\n",
    "Avant toute manipulation ou entraÃ®nement, nous devons importer toutes les **bibliothÃ¨ques nÃ©cessaires** Ã  la gestion des donnÃ©es, Ã  la construction du modÃ¨le, et Ã  lâ€™ingÃ©nierie des variables.\n",
    "\n",
    "Cela garantit :\n",
    "- un environnement prÃªt Ã  exÃ©cuter le pipeline complet,\n",
    "- une meilleure lisibilitÃ© du script,\n",
    "- et la centralisation des dÃ©pendances en dÃ©but de fichier.\n",
    "\n",
    "### ğŸ¯ 1.2. RÃ©sultat attendu\n",
    "\n",
    "- Toutes les librairies utiles au traitement et Ã  l'entraÃ®nement dâ€™un modÃ¨le Deep Learning sont importÃ©es.\n",
    "- L'importation est **clairement organisÃ©e** par type de tÃ¢che (donnÃ©es, modÃ¨le, I/O, etc.).\n",
    "- Aucune erreur d'importation ne bloque l'exÃ©cution du notebook.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ 1.3. Script dâ€™importation des bibliothÃ¨ques nÃ©cessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f125f842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“¦ Importation des bibliothÃ¨ques nÃ©cessaires\n",
    "\n",
    "# === ğŸ§® Manipulation de donnÃ©es ===\n",
    "import pandas as pd   # BibliothÃ¨que pour la gestion des tableaux de donnÃ©es (DataFrame)\n",
    "import numpy as np    # BibliothÃ¨que pour le calcul numÃ©rique performant (vecteurs, matrices, etc.)\n",
    "\n",
    "# === ğŸ¤– Deep Learning avec TensorFlow Keras ===\n",
    "import tensorflow as tf  # Backend TensorFlow (nÃ©cessaire mÃªme si Keras est utilisÃ© seul)\n",
    "from tensorflow.keras.models import Sequential       # ModÃ¨le linÃ©aire empilÃ© (sÃ©quentiel)\n",
    "from tensorflow.keras.layers import Dense, Dropout   # Couches dense (fully connected) et dropout (rÃ©gularisation)\n",
    "from tensorflow.keras.callbacks import EarlyStopping # Callback pour arrÃªter l'entraÃ®nement en cas de surapprentissage\n",
    "\n",
    "# === ğŸ”§ PrÃ©paration et Ã©valuation des donnÃ©es ===\n",
    "from sklearn.model_selection import train_test_split  # Fonction de sÃ©paration du dataset en ensembles d'entraÃ®nement/test\n",
    "from sklearn.preprocessing import StandardScaler       # Standardisation (centrage/rÃ©duction) des variables numÃ©riques\n",
    "\n",
    "# === ğŸ—ƒï¸ Gestion des fichiers et modÃ¨les ===\n",
    "import os       # Outils de gestion de fichiers et rÃ©pertoires\n",
    "import joblib   # Sauvegarde et chargement efficace des objets Python (modÃ¨les, scalers, etc.)\n",
    "\n",
    "# === ğŸ§  Embedding de texte via transformers ===\n",
    "from sentence_transformers import SentenceTransformer  # GÃ©nÃ©ration dâ€™embeddings vectoriels Ã  partir de textes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23be1724",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c2cb97",
   "metadata": {},
   "source": [
    "## ğŸ“‚ 2. Chargement des donnÃ©es transformÃ©es dans un DataFrame Pandas\n",
    "\n",
    "### â“ 2.1. Pourquoi cette Ã©tape maintenant ?\n",
    "\n",
    "Le fichier `fiverr_cleaned_transformed.csv` contient les donnÃ©es **nettoyÃ©es et enrichies** suite aux Ã©tapes de prÃ©traitement prÃ©cÃ©dentes.  \n",
    "Câ€™est Ã  partir de ce fichier que nous allons **prÃ©parer les entrÃ©es** du modÃ¨le de deep learning.\n",
    "\n",
    "Cette Ã©tape permet :\n",
    "- de **valider lâ€™accÃ¨s au fichier** et le bon format CSV,\n",
    "- dâ€™initialiser le DataFrame `df` pour les traitements ultÃ©rieurs,\n",
    "- dâ€™obtenir une **confirmation immÃ©diate** sur le nombre de lignes et colonnes disponibles.\n",
    "\n",
    "### ğŸ¯ 2.2. RÃ©sultat attendu\n",
    "\n",
    "- Les donnÃ©es sont correctement lues dans le DataFrame `df`.\n",
    "- Aucune erreur dâ€™accÃ¨s ou de lecture nâ€™est rencontrÃ©e.\n",
    "- Le terminal affiche les dimensions des donnÃ©es (nombre de lignes et de colonnes).\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ 2.3. Script de chargement des donnÃ©es transformÃ©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8395a1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”¹ Chargement des donnÃ©es\n",
    "\n",
    "# DÃ©finition du chemin vers le fichier CSV nettoyÃ© et transformÃ©\n",
    "file_path = \"data/fiverr_cleaned_transformed.csv\"\n",
    "\n",
    "# Chargement du fichier CSV dans un DataFrame Pandas\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Affichage d'un message de confirmation avec les dimensions des donnÃ©es chargÃ©es\n",
    "print(\"âœ”ï¸ DonnÃ©es chargÃ©es :\", df.shape)  # Exemple : (25000, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d675bd90",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96734c6",
   "metadata": {},
   "source": [
    "## ğŸ§ª 3. PrÃ©paration des donnÃ©es pour le Deep Learning\n",
    "\n",
    "### â“ 3.1. Pourquoi cette Ã©tape maintenant ?\n",
    "\n",
    "Cette Ã©tape prÃ©pare les **entrÃ©es du modÃ¨le de deep learning** :\n",
    "- GÃ©nÃ©ration des **embeddings vectoriels** pour les descriptions textuelles,\n",
    "- **Encodage one-hot** de la variable catÃ©gorielle `Niveau`,\n",
    "- SÃ©lection et concatÃ©nation des **variables numÃ©riques** comme `Fiabilite`,\n",
    "- SÃ©paration du jeu de donnÃ©es en ensembles dâ€™entraÃ®nement et de test,\n",
    "- **Normalisation des features** pour stabiliser lâ€™apprentissage,\n",
    "- Sauvegarde du scaler pour reproduire le pipeline dâ€™infÃ©rence plus tard.\n",
    "\n",
    "Câ€™est une Ã©tape centrale avant toute modÃ©lisation supervisÃ©e.\n",
    "\n",
    "### ğŸ¯ 3.2. RÃ©sultat attendu\n",
    "\n",
    "- Le DataFrame `X` contient toutes les variables explicatives correctement formatÃ©es.\n",
    "- Les jeux `X_train_scaled`, `X_test_scaled`, `y_train`, `y_test` sont prÃªts Ã  lâ€™usage.\n",
    "- Le scaler `StandardScaler` est sauvegardÃ© dans `models/deep/scaler.pkl`.\n",
    "- Les dimensions du jeu dâ€™entraÃ®nement sont affichÃ©es Ã  lâ€™Ã©cran pour validation.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ 3.3. Script de prÃ©paration des features d'entrÃ©e pour le deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d002c75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“¥ Chargement des donnÃ©es\n",
    "df = pd.read_csv(\"data/fiverr_cleaned_transformed.csv\")  # Lecture du fichier transformÃ© contenant les features prÃªtes Ã  lâ€™emploi\n",
    "\n",
    "# ğŸ§  Chargement du modÃ¨le d'embedding SentenceTransformer\n",
    "embedding_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")  # ModÃ¨le lÃ©ger et performant pour vectoriser les descriptions textuelles\n",
    "\n",
    "# ğŸ”¹ Embedding de la colonne 'Description'\n",
    "descriptions = df[\"Description\"].astype(str).tolist()\n",
    "embeddings = embedding_model.encode(descriptions)\n",
    "embed_df = pd.DataFrame(embeddings, columns=[f\"emb_{i}\" for i in range(embeddings.shape[1])])  # CrÃ©ation dâ€™un DataFrame pour les vecteurs dâ€™embedding\n",
    "\n",
    "# ğŸ”¹ Encodage one-hot du niveau du vendeur\n",
    "niveau_encoded = pd.get_dummies(df[\"Niveau\"], prefix=\"Niveau\")  # Conversion de la variable catÃ©gorielle en variables binaires\n",
    "\n",
    "# ğŸ”¹ SÃ©lection des variables numÃ©riques restantes\n",
    "autres_features = df[[\"Fiabilite\"]].reset_index(drop=True)  # Ajout de la variable numÃ©rique \"Fiabilite\"\n",
    "\n",
    "# ğŸ”¹ Fusion finale des features dans X\n",
    "X = pd.concat([embed_df, niveau_encoded, autres_features], axis=1)  # Construction du tableau final de variables explicatives\n",
    "y = df[\"Prix\"]  # Variable cible : le prix\n",
    "\n",
    "# ğŸ”¹ DÃ©coupage du jeu de donnÃ©es en train / test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  # 80% entraÃ®nement, 20% test\n",
    "\n",
    "# ğŸ”¹ Standardisation des donnÃ©es (centrage-rÃ©duction)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # Apprentissage des paramÃ¨tres sur X_train\n",
    "X_test_scaled = scaler.transform(X_test)        # Transformation de X_test avec les mÃªmes paramÃ¨tres\n",
    "\n",
    "# ğŸ”¹ Sauvegarde du scaler pour une rÃ©utilisation future\n",
    "os.makedirs(\"models/deep\", exist_ok=True)\n",
    "scaler_path = \"models/deep/scaler.pkl\"\n",
    "joblib.dump(scaler, scaler_path)\n",
    "\n",
    "# ğŸ” Messages de vÃ©rification\n",
    "print(\"ğŸ“¦ Scaler sauvegardÃ© :\", scaler_path)\n",
    "print(\"âœ… DonnÃ©es prÃªtes pour entraÃ®nement deep learning :\", X_train_scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15496d22",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97721ffe",
   "metadata": {},
   "source": [
    "## ğŸ§  4. Construction du modÃ¨le MLP (rÃ©gression du prix)\n",
    "\n",
    "### â“ 4.1. Pourquoi cette Ã©tape maintenant ?\n",
    "\n",
    "Nous allons entraÃ®ner un modÃ¨le de Deep Learning de type **MLP (Multilayer Perceptron)** pour prÃ©dire le prix dâ€™un service.  \n",
    "Il sâ€™agit dâ€™un modÃ¨le dense Ã  plusieurs couches, adaptÃ© aux jeux de donnÃ©es tabulaires enrichis (numÃ©riques + embeddings).\n",
    "\n",
    "Le modÃ¨le est conÃ§u pour apprendre une **fonction de rÃ©gression** sur les variables dâ€™entrÃ©e (dont les embeddings de description) vers une **valeur continue de prix**.\n",
    "\n",
    "### ğŸ¯ 4.2. RÃ©sultat attendu\n",
    "\n",
    "- Un modÃ¨le Keras `Sequential` est initialisÃ© avec 3 couches :\n",
    "  - Deux couches cachÃ©es avec activations ReLU.\n",
    "  - Une couche de sortie sans activation (rÃ©gression directe).\n",
    "- Une couche de rÃ©gularisation `Dropout` est intÃ©grÃ©e pour rÃ©duire le risque de surapprentissage.\n",
    "- Le modÃ¨le est compilÃ© avec :\n",
    "  - Lâ€™optimiseur `adam`\n",
    "  - La fonction de perte `mse`\n",
    "  - Lâ€™indicateur de performance `mae`\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ 4.3. Script de dÃ©finition du modÃ¨le MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cab3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”¹ Construction du modÃ¨le MLP (Multilayer Perceptron)\n",
    "\n",
    "# Initialisation d'un modÃ¨le sÃ©quentiel Keras\n",
    "model = Sequential([\n",
    "\n",
    "    # PremiÃ¨re couche cachÃ©e dense avec 128 neurones et une activation ReLU\n",
    "    Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "\n",
    "    # Couche de dropout pour limiter le surapprentissage (20% des neurones dÃ©sactivÃ©s Ã  chaque itÃ©ration)\n",
    "    Dropout(0.2),\n",
    "\n",
    "    # DeuxiÃ¨me couche cachÃ©e dense avec 64 neurones et une activation ReLU\n",
    "    Dense(64, activation='relu'),\n",
    "\n",
    "    # Couche de sortie : une seule valeur continue (rÃ©gression du prix)\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compilation du modÃ¨le avec :\n",
    "# - l'optimiseur 'adam' (rapide et efficace pour la majoritÃ© des cas)\n",
    "# - la fonction de perte 'mse' (erreur quadratique moyenne, adaptÃ©e Ã  la rÃ©gression)\n",
    "# - l'indicateur de performance 'mae' (erreur absolue moyenne, plus lisible pour l'utilisateur final)\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',\n",
    "    metrics=['mae']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee123e54",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6558e9a5",
   "metadata": {},
   "source": [
    "## ğŸ‹ï¸â€â™‚ï¸ 5. EntraÃ®nement du modÃ¨le avec EarlyStopping\n",
    "\n",
    "### â“ 5.1. Pourquoi cette Ã©tape maintenant ?\n",
    "\n",
    "AprÃ¨s avoir prÃ©parÃ© les donnÃ©es et construit notre modÃ¨le de deep learning, il est temps de lancer lâ€™entraÃ®nement.  \n",
    "Nous utilisons ici un mÃ©canisme de **surveillance automatique** pour Ã©viter le surapprentissage (`EarlyStopping`).\n",
    "\n",
    "Ce mÃ©canisme permet :\n",
    "- d'interrompre l'entraÃ®nement si le modÃ¨le ne s'amÃ©liore plus sur les donnÃ©es de validation,\n",
    "- d'Ã©viter dâ€™apprendre des dÃ©tails trop spÃ©cifiques Ã  lâ€™Ã©chantillon dâ€™entraÃ®nement (overfitting),\n",
    "- de restaurer automatiquement les **meilleurs poids** enregistrÃ©s.\n",
    "\n",
    "### ğŸ¯ 5.2. RÃ©sultat attendu\n",
    "\n",
    "- Le modÃ¨le est entraÃ®nÃ© sur les donnÃ©es normalisÃ©es `X_train_scaled`.\n",
    "- Une **validation croisÃ©e interne** est effectuÃ©e Ã  chaque Ã©poque sur 20% des donnÃ©es.\n",
    "- Le processus sâ€™interrompt automatiquement si aucune amÃ©lioration nâ€™est constatÃ©e pendant 10 Ã©poques consÃ©cutives.\n",
    "- Lâ€™objet `history` contient toutes les informations nÃ©cessaires Ã  la visualisation de la courbe dâ€™apprentissage.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ 5.3. Script dâ€™entraÃ®nement avec arrÃªt anticipÃ©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30b7dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”¹ EntraÃ®nement avec early stopping\n",
    "\n",
    "# ğŸ“Œ CrÃ©ation dâ€™un callback EarlyStopping :\n",
    "# - 'monitor' : indique que l'on surveille la perte sur les donnÃ©es de validation ('val_loss').\n",
    "# - 'patience' : arrÃªte l'entraÃ®nement si la perte ne s'amÃ©liore pas aprÃ¨s 10 epochs consÃ©cutifs.\n",
    "# - 'restore_best_weights' : restaure les poids du modÃ¨le obtenus Ã  l'Ã©poque avec la meilleure val_loss.\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# â–¶ï¸ EntraÃ®nement du modÃ¨le sur les donnÃ©es dâ€™entraÃ®nement\n",
    "# - 'validation_split' : 20% des donnÃ©es d'entraÃ®nement sont utilisÃ©es pour valider le modÃ¨le pendant l'entraÃ®nement.\n",
    "# - 'epochs' : nombre maximum d'itÃ©rations (epochs).\n",
    "# - 'batch_size' : nombre d'exemples traitÃ©s avant la mise Ã  jour des poids.\n",
    "# - 'callbacks' : utilise le mÃ©canisme d'arrÃªt anticipÃ© pour Ã©viter lâ€™overfitting.\n",
    "# - 'verbose' : 1 pour affichage dÃ©taillÃ© de la progression dans le terminal.\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186c27b0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d1cfd4",
   "metadata": {},
   "source": [
    "## ğŸ§ª 6. Ã‰valuation du modÃ¨le entraÃ®nÃ©\n",
    "\n",
    "### â“ 6.1. Pourquoi cette Ã©tape maintenant ?\n",
    "\n",
    "Lâ€™Ã©valuation finale permet de mesurer la **performance rÃ©elle** du modÃ¨le sur des donnÃ©es **inÃ©dites** (non vues pendant lâ€™entraÃ®nement).  \n",
    "Cela permet de dÃ©tecter :\n",
    "- Un Ã©ventuel **surapprentissage** si la performance chute trop par rapport au jeu dâ€™entraÃ®nement,\n",
    "- Lâ€™efficacitÃ© globale du modÃ¨le dans un contexte dâ€™usage rÃ©el.\n",
    "\n",
    "### ğŸ¯ 6.2. RÃ©sultat attendu\n",
    "\n",
    "- Le modÃ¨le retourne deux indicateurs clÃ©s :\n",
    "  - **MAE** (*Mean Absolute Error*) : Ã©cart moyen absolu entre les prix rÃ©els et prÃ©dits,\n",
    "  - **MSE** (*Mean Squared Error*) : utilisÃ© comme fonction de perte pour lâ€™entraÃ®nement.\n",
    "- Ces valeurs sont imprimÃ©es dans la console pour analyse comparative.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ 6.3. Script dâ€™Ã©valuation du modÃ¨le sur le jeu de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6e6722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”¹ Ã‰valuation du modÃ¨le sur les donnÃ©es de test\n",
    "\n",
    "# Ã‰valuation finale du modÃ¨le entraÃ®nÃ© Ã  l'aide des donnÃ©es de test standardisÃ©es.\n",
    "# La mÃ©thode 'evaluate' retourne deux mÃ©triques :\n",
    "# - loss : ici câ€™est le MSE (Mean Squared Error) car le modÃ¨le a Ã©tÃ© compilÃ© avec la perte \"mse\"\n",
    "# - mae : Mean Absolute Error, plus lisible et moins sensible aux grandes erreurs\n",
    "loss, mae = model.evaluate(X_test_scaled, y_test)\n",
    "\n",
    "# Affichage des rÃ©sultats arrondis Ã  deux dÃ©cimales\n",
    "print(f\"\\nğŸ“Š Ã‰valuation finale - MAE : {mae:.2f}, MSE : {loss:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb93841",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2d563f",
   "metadata": {},
   "source": [
    "## ğŸ’¾ 7. Sauvegarde du modÃ¨le Deep Learning entraÃ®nÃ©\n",
    "\n",
    "### â“ 7.1. Pourquoi cette Ã©tape maintenant ?\n",
    "\n",
    "Une fois le modÃ¨le entraÃ®nÃ© et validÃ©, il est crucial de **le sauvegarder** afin de :\n",
    "- RÃ©utiliser le modÃ¨le plus tard sans avoir Ã  le rÃ©entraÃ®ner,\n",
    "- Lâ€™intÃ©grer dans une application (API, Gradio, etc.),\n",
    "- Conserver une version stable du modÃ¨le pour reproductibilitÃ© ou archivage.\n",
    "\n",
    "Le format `.h5` est un format standard de sauvegarde pour les modÃ¨les Keras.\n",
    "\n",
    "### ğŸ¯ 7.2. RÃ©sultat attendu\n",
    "\n",
    "- Le modÃ¨le est sauvegardÃ© dans le fichier `models/deep/deep_model.h5`.\n",
    "- Un message de confirmation sâ€™affiche dans le terminal.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ 7.3. Script de sauvegarde du modÃ¨le Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9086da16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”¹ Sauvegarde du modÃ¨le Keras\n",
    "\n",
    "# DÃ©finition du chemin de sauvegarde du modÃ¨le Deep Learning\n",
    "model_path = \"models/deep/deep_model.h5\"\n",
    "\n",
    "# Sauvegarde du modÃ¨le Keras au format HDF5 (.h5)\n",
    "model.save(model_path)\n",
    "\n",
    "# Confirmation de la sauvegarde\n",
    "print(\"âœ… ModÃ¨le sauvegardÃ© :\", model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
