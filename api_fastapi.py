from fastapi import FastAPI
from pydantic import BaseModel
import joblib
import pandas as pd
import numpy as np
from tensorflow.keras.models import load_model
from sentence_transformers import SentenceTransformer
from fastapi.concurrency import run_in_threadpool

# üåê Cr√©ation de l'application FastAPI
app = FastAPI(title="API Pr√©diction de Prix avec Deep Learning")

# üì¶ Chargement du mod√®le Keras et du scaler utilis√© lors de l'entra√Ænement
MODEL_PATH = "models/deep/deep_model.h5"
SCALER_PATH = "models/deep/scaler.pkl"

model = load_model(MODEL_PATH)
scaler = joblib.load(SCALER_PATH)

# üî§ Chargement du mod√®le d'embedding pour la description
embedding_model = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")

# üîÅ Mapping texte ‚Üí entier pour le niveau vendeur
# üìå Doit correspondre aux valeurs pr√©sentes dans le CSV d'entra√Ænement
niveau_to_int = {
    "Nouveau": 1,
    "Confirm√©": 2,
    "Top": 3
}

# üßæ Sch√©ma d'entr√©e de la requ√™te POST via Pydantic
class InputData(BaseModel):
    Description: str
    Niveau: str
    Fiabilite: float

# üîç Fonction de pr√©traitement : transforme les donn√©es utilisateur en entr√©e mod√®le
def preprocess_input(data: InputData):
    # Embedding de la description
    embedding = embedding_model.encode([data.Description]).flatten()

    # One-hot encoding du niveau (3 colonnes)
    niveau_mapping = ["Nouveau", "Confirm√©", "Top"]
    niveau_ohe = [1 if data.Niveau == niveau else 0 for niveau in niveau_mapping]

    # Fusion finale (384 + 3 + 1 = 388 colonnes)
    features = np.hstack([embedding, niveau_ohe, [data.Fiabilite]])

    print(">> Shape des features brutes :", features.shape)  # Doit √™tre (388,)
    
    features_scaled = scaler.transform([features])
    return features_scaled


# üì® Route principale de pr√©diction
@app.post("/predict")
async def predict_price(input_data: InputData):
    try:
        X = preprocess_input(input_data)

        print(">> Pr√©diction sur X :", X.shape)
        import sys; sys.stdout.flush()

        # ‚ö†Ô∏è Appel du mod√®le dans un thread isol√© pour √©viter les crashs TensorFlow
        y_pred = await run_in_threadpool(lambda: model.predict(X)[0][0])

        return {"prix_predit": round(float(y_pred), 2)}
    except Exception as e:
        import traceback
        print("‚ùå ERREUR PREDICTION :")
        traceback.print_exc()
        return {"error": str(e)}

