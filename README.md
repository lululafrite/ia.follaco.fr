# üîÆ Pr√©diction de prix sur Fiverr ‚Äî Projet IA

Ce projet explore l‚Äôusage de l‚Äôintelligence artificielle pour **pr√©dire le prix d‚Äôune prestation freelance sur la plateforme Fiverr**, en se basant sur :

- la **description textuelle** du service,
- le **niveau du vendeur** (Nouveau, Confirm√©, Top),
- la **fiabilit√© estim√©e** du profil (note composite calcul√©e √† partir des √©valuations).

Il s‚Äôappuie sur un pipeline **modulaire et reproductible**, combinant des techniques de **traitement de texte**, de **vectorisation par embeddings**, de **r√©gression supervis√©e**, de **classification**, et une **application Gradio**.

---

## üéØ Objectifs

1. **Pr√©dire le prix exact** d‚Äôun service √† partir de sa description et des attributs du vendeur.  
2. **Classifier le service dans une tranche de prix** : `Basse`, `Moyenne` ou `Haute`.  
3. **Proposer une interface interactive** pour tester les mod√®les sur des cas r√©els.

<p align="center">
  <img src="./img/app_gradio.png" alt="Illustration de l'application Gradio" width="600"/>
</p>
---

## üì¶ Fonctionnalit√©s cl√©s

- ‚úÖ Nettoyage complet des donn√©es brutes issues de Fiverr.
- üß† Embeddings s√©mantiques via `sentence-transformers` pour les descriptions.
- üìà Mod√©lisation :
  - R√©gression : `GradientBoostingRegressor`
  - Classification : `DecisionTreeClassifier`
- üîç √âvaluation comparative des mod√®les : `MAE`, `RMSE`, `Accuracy`, `F1-score`.
- üíæ Sauvegarde automatique des mod√®les, colonnes, transformateurs et pr√©dictions.
- üåê Application interactive avec `Gradio`.

---

## ‚öôÔ∏è Choix techniques

| Composant            | Choix retenu                                   | Raison                                                                 |
|----------------------|------------------------------------------------|------------------------------------------------------------------------|
| Texte libre          | Embeddings BERT (`all-MiniLM-L6-v2`)           | Repr√©sentation s√©mantique avanc√©e et compacte                          |
| Variables num√©riques | StandardScaler                                 | Meilleure convergence et robustesse des mod√®les                        |
| Algorithmes ML       | Gradient Boosting, Decision Tree               | Performants, interpr√©tables, adapt√©s aux petits jeux tabulaires        |
| Interface            | Gradio                                         | D√©ploiement simple, ergonomie efficace pour la d√©monstration           |
| Organisation         | Notebooks modulaires                           | Ex√©cution claire, maintenance facilit√©e, lisibilit√© p√©dagogique        |

---

## üóÇÔ∏è Structure du projet

| Dossier                              | Contenu du dossier                                                        |
|--------------------------------------|---------------------------------------------------------------------------|
| ia.follaco.fr/                       | Dossier racine du projet                                                  |
| ia.follaco.fr/data/                  | Stockage des fichiers *.csv de donn√©es brutes et nettoy√©es                |
| ia.follaco.fr/data/prediction_grid/  | Stockage des fichiers *.csv de r√©sultats de priction par paires de mod√®le |
| ia.follaco.fr/flagged/               | Stockage du fichiers log.csv , il enregistre les r√©sultats pour analyse   |
| ia.follaco.fr/img/                   | Stockage des images n√©cessaires √† certaines explications                  |
| ia.follaco.fr/models/                | Stockage des mod√®les de regression et de classification entrain√©s         |
| ia.follaco.fr/models/regression/     | Stockage des mod√®les de regression entrain√©s                              |
| ia.follaco.fr/models/classification/ | Stockage des mod√®les de classification entrain√©s                          |

---

## üöÄ Fonctionnement

1. **Pr√©traitement des donn√©es** (`01_pre-processing.ipynb`)  
   Nettoyage du jeu de donn√©es brut : suppression des doublons, traitement des prix aberrants, uniformisation des formats, et export d‚Äôun fichier transform√© pr√™t √† l‚Äôusage.

2. **Mod√©lisation - R√©gression** (`02_model_regression.ipynb`)  
   Construction des features √† partir des variables classiques, entra√Ænement et √©valuation de mod√®les de r√©gression (RandomForest, XGBoost, etc.) pour pr√©dire le **prix exact**.

3. **Mod√©lisation - Classification** (`03_model_classification.ipynb`)  
   Cr√©ation de la variable cible `Tranche` (prix bas / moyen / √©lev√©), puis entra√Ænement de mod√®les de classification pour estimer **la gamme de prix**.

4. **Mod√©lisation - Deep Learning** (`04_model_deep_learning.ipynb`)  
   Entra√Ænement d‚Äôun mod√®le **deep learning** utilisant des **embeddings textuels** (via `SentenceTransformer`) combin√©s √† des variables num√©riques, afin de pr√©dire le prix. Ce mod√®le est export√© au format `.h5`.

5. **Pr√©diction script√©e** (`05_predict.py`)  
   Regroupe les fonctions de pr√©diction pr√™tes √† l‚Äôemploi : chargement des mod√®les, transformation des nouvelles entr√©es, et g√©n√©ration des pr√©dictions (prix et tranche).

6. **API REST avec FastAPI** (`06_api_fastapi.py`)  
   Impl√©mente une API REST permettant de soumettre une requ√™te (description, niveau, fiabilit√©) et de recevoir une pr√©diction de prix via une architecture d√©ployable localement avec `uvicorn`.

7. **Interface utilisateur interactive** (`07_app.ipynb`)  
   Application **Gradio** pour tester dynamiquement les diff√©rents mod√®les (ML, Deep Learning, API REST). L‚Äôutilisateur peut saisir une description, choisir un niveau de fiabilit√©, visualiser les r√©sultats, et **enregistrer** les pr√©dictions dans un fichier `log.csv`.


---

## üìä Exemples de r√©sultats

### üî¢ R√©gression ‚Äî Comparatif des mod√®les

| Mod√®le                | MAE   | RMSE  | R¬≤      |
|------------------------|-------|--------|----------|
| **Gradient Boosting**  | 3.21  | 4.90   | **0.2566** |
| XGBoost                | 3.33  | 5.00   | 0.2274   |
| Random Forest          | 3.32  | 5.03   | 0.2173   |
| Ridge                  | 3.82  | 5.47   | 0.0748   |
| KNN Regressor          | 3.99  | 5.80   | -0.0407  |
| Decision Tree          | 4.43  | 7.14   | -0.5770  |
| Linear Regression      | 5.86  | 9.90   | -2.0353  |

‚úÖ **Mod√®le retenu** : Gradient Boosting Regressor ‚Äî *meilleur compromis entre pr√©cision et stabilit√© (RMSE = 4.90)*.

---

### üè∑Ô∏è Classification ‚Äî Comparatif des mod√®les

| Mod√®le               | Accuracy |
|----------------------|----------|
| **Decision Tree**    | **0.6175** |
| Random Forest        | 0.5339   |
| KNN Classifier       | 0.5179   |
| Logistic Regression  | 0.5100   |

‚úÖ **Mod√®le retenu** : Decision Tree Classifier ‚Äî *meilleur score d‚Äôaccuracy (61.75 %) sur les tranches Basse / Moyenne / Haute.*

---

## ‚úÖ Comp√©tences mobilis√©es

Ce projet couvre des **comp√©tences issues des blocs 3 et 5** de la certification IA :

| Bloc   | Comp√©tence | Description                                                                                          | Notebooks concern√©s                                                                 |
|--------|------------|------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------|
| Bloc_3 | C1         | S√©lection du meilleur algorithme ML selon les performances (MAE, RMSE, Accuracy‚Ä¶)                   | `02_model_regression.ipynb`, `03_model_classification.ipynb`                         |
| Bloc_3 | C2         | Pr√©traitement des donn√©es (scaling, encodage, embeddings) adapt√© √† chaque type de mod√®le            | `01_pre-processing.ipynb`, `02_model_regression.ipynb`, `03_model_classification.ipynb`, `04_model_deep_learning.ipynb`, `05_predict.ipynb` |
| Bloc_3 | C3         | Entra√Ænement et validation de mod√®les ML supervis√©s sur m√©triques d√©finies                          | `02_model_regression.ipynb`, `03_model_classification.ipynb`                         |
| Bloc_5 | C1         | Transformation de textes en vecteurs num√©riques (embeddings BERT via `sentence-transformers`)       | `01_pre-processing.ipynb`, `02_model_regression.ipynb`, `04_model_deep_learning.ipynb`, `05_predict.ipynb` |
| Bloc_5 | C2         | Comparaison de mod√®les hybrides (ML vs Deep Learning) adapt√©s aux contraintes du cas m√©tier         | `02_model_regression.ipynb`, `04_model_deep_learning.ipynb`, `05_predict.ipynb`      |
| Bloc_5 | C3         | Entra√Ænement de mod√®les Deep Learning exploitant les embeddings textuels                            | `04_model_deep_learning.ipynb`                                                      |
| Bloc_5 | C4         | D√©ploiement du pipeline avec une interface Gradio et exposition d‚Äôun mod√®le via une API FastAPI     | `06_app.ipynb`, `06_api_fastapi.ipynb`                                              |

---

## üîß Installation rapide

‚ö†Ô∏è **IMPORTANT**
- L'ensemble du programme fonctionne avec :
    - la version 3.10.11 de python.
    - La liste des packages list√© dans "requirements.txt".

```bash
git clone https://github.com/lululafrite/ia.follaco.fr.git
cd ia.follaco.fr
.venv\Scripts\activate
pip install -r requirements.txt
```

## üë®‚Äçüè´ Remarques p√©dagogiques

- Chaque notebook est autonome, avec une structure claire et des explications guid√©es.
- Le projet est con√ßu pour favoriser la modularit√© et la r√©utilisabilit√© en production.
- L‚Äôinterface utilisateur permet de tester directement la cha√Æne pr√©dictive.
- Le notebook "04_predict.ipynb" n'est pas utilis√© par l'application, il est √† usage p√©dagogique.
- Le fichier "predict.py" est import√© par le notebook "05_app.ipynb" car il contient les fonctione de pr√©diction.

## üë§ Contact

Ludovic FOLLACO  
ludovic.follaco@gmail.com  
https://www.follaco.fr  
https://www.linkedin.com/in/ludovic-follaco-a74b5394/