{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a038f8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\wamp64\\www\\ia.follaco.fr\\.venv\\lib\\site-packages\\gradio_client\\documentation.py:106: UserWarning: Could not get documentation group for <class 'gradio.mix.Parallel'>: No known documentation group for module 'gradio.mix'\n",
      "  warnings.warn(f\"Could not get documentation group for {cls}: {exc}\")\n",
      "c:\\wamp64\\www\\ia.follaco.fr\\.venv\\lib\\site-packages\\gradio_client\\documentation.py:106: UserWarning: Could not get documentation group for <class 'gradio.mix.Series'>: No known documentation group for module 'gradio.mix'\n",
      "  warnings.warn(f\"Could not get documentation group for {cls}: {exc}\")\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "import requests\n",
    "from predict import predict_price, predict_tranche  # ML local\n",
    "from tensorflow.keras.models import load_model\n",
    "from sentence_transformers import SentenceTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf575fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 3.39.0, however version 4.44.1 is available, please upgrade.\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# üìÇ Chemins\n",
    "LOG_PATH = \"flagged/log.csv\"\n",
    "API_URL = \"http://127.0.0.1:8000/predict\"\n",
    "choices = {\n",
    "    \"Acceptable\": 80,\n",
    "    \"Moyenne\": 85,\n",
    "    \"Bonne\": 90,\n",
    "    \"Tr√®s Bonne\": 96,\n",
    "    \"Excellente\": 99\n",
    "}\n",
    "niveau_mapping = [\"Beginner\", \"Intermediate\", \"Expert\"]  # pour DL local\n",
    "\n",
    "# üß† Chargement lazy des mod√®les DL\n",
    "embedding_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "deep_model = None\n",
    "scaler_dl = None\n",
    "\n",
    "def load_deep_models():\n",
    "    global deep_model, scaler_dl\n",
    "    if deep_model is None:\n",
    "        deep_model = load_model(\"models/deep/deep_model.h5\")\n",
    "        scaler_dl = joblib.load(\"models/deep/scaler.pkl\")\n",
    "\n",
    "def faire_une_prediction(description, niveau, use_predefined, fiabilite_percent, fiabilite_choix, modele):\n",
    "    fiabilite = (choices[fiabilite_choix] if use_predefined else fiabilite_percent) / 100\n",
    "\n",
    "    try:\n",
    "        if modele == \"ML - Local\":\n",
    "            prix = predict_price(description, fiabilite)\n",
    "            tranche = predict_tranche(description, fiabilite)\n",
    "\n",
    "        elif modele == \"DL - Local\":\n",
    "            load_deep_models()\n",
    "            emb = embedding_model.encode([description]).flatten()\n",
    "            niveau_ohe = [1 if niveau == n else 0 for n in niveau_mapping]\n",
    "            features = np.hstack([emb, niveau_ohe, [fiabilite]])\n",
    "            features_scaled = scaler_dl.transform([features])\n",
    "            prix = deep_model.predict(features_scaled)[0][0]\n",
    "            tranche = \"Non √©valu√©e\"\n",
    "\n",
    "        elif modele == \"API - FastAPI\":\n",
    "            response = requests.post(API_URL, json={\n",
    "                \"Description\": description,\n",
    "                \"Niveau\": niveau,\n",
    "                \"Fiabilite\": fiabilite\n",
    "            }, timeout=5)\n",
    "            response.raise_for_status()\n",
    "            prix = response.json().get(\"prix_predit\", -1)\n",
    "            tranche = \"Non √©valu√©e\"\n",
    "\n",
    "        else:\n",
    "            return \"‚ùå Mod√®le inconnu\", \"\"\n",
    "\n",
    "        return round(prix, 2), tranche\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Erreur : {str(e)}\", \"\"\n",
    "\n",
    "def enregistrer_log(description, use_predefined, fiabilite_percent, fiabilite_choix, prix, tranche, modele):\n",
    "    fiabilite = choices[fiabilite_choix] if use_predefined else fiabilite_percent\n",
    "    log_data = {\n",
    "        \"Description\": description,\n",
    "        \"Fiabilit√© (%)\": fiabilite,\n",
    "        \"Prix pr√©dit (‚Ç¨)\": prix,\n",
    "        \"Tranche pr√©dite\": tranche,\n",
    "        \"Mod√®le utilis√©\": modele\n",
    "    }\n",
    "\n",
    "    df_log = pd.DataFrame([log_data])\n",
    "    if os.path.exists(LOG_PATH):\n",
    "        df_log.to_csv(LOG_PATH, mode=\"a\", index=False, header=False)\n",
    "    else:\n",
    "        df_log.to_csv(LOG_PATH, index=False)\n",
    "\n",
    "    return \"‚úÖ Signalement enregistr√© avec succ√®s.\"\n",
    "\n",
    "with gr.Blocks() as iface:\n",
    "    gr.Markdown(\"\"\"\n",
    "        ## üéØ Application de pr√©diction de prix Fiverr\n",
    "        Cette application permet d‚Äôestimer automatiquement :\n",
    "        - üí∞ Le **prix probable** d‚Äôun service publi√© sur Fiverr,\n",
    "        - üìä Sa **tranche de prix** parmi trois cat√©gories (Basse / Moyenne / Haute).\n",
    "        Elle s‚Äôappuie sur un pipeline hybride combinant des embeddings de description et des variables num√©riques.\n",
    "        üîÅ Vous pouvez maintenant choisir entre trois mod√®les : ML, Deep Learning, ou appel API REST FastAPI.\n",
    "    \"\"\")\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=1):\n",
    "            description = gr.Textbox(label=\"‚úèÔ∏è Titre du service\", value=\"Je fais le m√©nage\")\n",
    "            niveau = gr.Dropdown(label=\"üî∞ Niveau du vendeur\", choices=niveau_mapping, value=\"Beginner\", visible=False)\n",
    "            use_predefined = gr.Checkbox(label=\"üéõÔ∏è Utiliser les niveaux pr√©d√©finis de fiabilit√©\", value=True)\n",
    "\n",
    "            fiabilite_percent = gr.Slider(label=\"Fiabilit√© (%)\", minimum=0, maximum=100, value=80, step=5, visible=False)\n",
    "            fiabilite_choix = gr.Radio(label=\"üéöÔ∏è Choisissez un niveau de fiabilit√©\", choices=list(choices.keys()), value=\"Acceptable\", visible=True)\n",
    "\n",
    "            modele = gr.Radio(label=\"üß† Choix du mod√®le\", choices=[\"ML - Local\", \"DL - Local\", \"API - FastAPI\"], value=\"ML - Local\")\n",
    "\n",
    "            def sync_slider_with_radio(choix):\n",
    "                return gr.update(value=choices[choix])\n",
    "\n",
    "            fiabilite_choix.change(sync_slider_with_radio, inputs=fiabilite_choix, outputs=fiabilite_percent)\n",
    "\n",
    "            def toggle_inputs(use_predef):\n",
    "                return {\n",
    "                    fiabilite_percent: gr.update(visible=not use_predef),\n",
    "                    fiabilite_choix: gr.update(visible=use_predef)\n",
    "                }\n",
    "\n",
    "            use_predefined.change(toggle_inputs, inputs=use_predefined, outputs=[fiabilite_percent, fiabilite_choix])\n",
    "            bouton_predire = gr.Button(\"üìà Estimer le prix\")\n",
    "\n",
    "        with gr.Column(scale=1):\n",
    "            sortie_prix = gr.Textbox(label=\"üí∞ Prix estim√©\")\n",
    "            sortie_tranche = gr.Textbox(label=\"üìä Tranche estim√©e\")\n",
    "            bouton_signaler = gr.Button(\"üö® Ajouter au fichier log.csv\")\n",
    "            confirmation = gr.Textbox(label=\"‚úÖ Confirmation\", visible=False)\n",
    "\n",
    "            bouton_predire.click(\n",
    "                fn=faire_une_prediction,\n",
    "                inputs=[description, niveau, use_predefined, fiabilite_percent, fiabilite_choix, modele],\n",
    "                outputs=[sortie_prix, sortie_tranche]\n",
    "            )\n",
    "\n",
    "            bouton_signaler.click(\n",
    "                fn=enregistrer_log,\n",
    "                inputs=[description, use_predefined, fiabilite_percent, fiabilite_choix, sortie_prix, sortie_tranche, modele],\n",
    "                outputs=confirmation\n",
    "            )\n",
    "\n",
    "\n",
    "# üöÄ Lancement\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0937224d",
   "metadata": {},
   "source": [
    "## üß† Justification des incoh√©rences apparentes dans les tranches pr√©dictives\n",
    "\n",
    "### ‚ùì Probl√®me observ√©\n",
    "\n",
    "Dans certains cas, il peut sembler incoh√©rent qu‚Äôune **tranche de prix estim√©e** soit plus √©lev√©e pour une **fiabilit√© \"Acceptable\"** que pour une fiabilit√© \"Excellente\". Par exemple :\n",
    "\n",
    "- Pour une **fiabilit√© Acceptable (80%)**, la tranche pr√©dite est **Haute**\n",
    "- Pour une **fiabilit√© Excellente (99%)**, la tranche pr√©dite est **Basse**\n",
    "\n",
    "### üß© Explication technique\n",
    "\n",
    "Cette situation peut √™tre expliqu√©e de fa√ßon coh√©rente par la conception du pipeline :\n",
    "\n",
    "1. **Deux mod√®les ind√©pendants sont utilis√©s** :\n",
    "   - Un mod√®le de **r√©gression** qui pr√©dit un **prix num√©rique**\n",
    "   - Un mod√®le de **classification** qui pr√©dit une **tranche cat√©gorielle** (`Basse`, `Moyenne`, `Haute`)\n",
    "   - Ces deux mod√®les sont **entra√Æn√©s s√©par√©ment**, sur des cibles diff√©rentes\n",
    "\n",
    "2. **La classification ne d√©pend pas du prix pr√©dit** :\n",
    "   - Le mod√®le de classification apprend √† pr√©dire une **cat√©gorie** (la tranche r√©elle observ√©e) en fonction d‚Äôun ensemble de variables, notamment :\n",
    "     - L‚Äôembedding de la description\n",
    "     - La fiabilit√© pond√©r√©e\n",
    "   - Il ne conna√Æt **ni le prix r√©el, ni le prix pr√©dit par le mod√®le de r√©gression**\n",
    "\n",
    "3. **La fiabilit√© pond√©r√©e n‚Äôa pas une influence lin√©aire** :\n",
    "   - Une meilleure fiabilit√© (Excellente) ne garantit pas forc√©ment un prix plus √©lev√© ni une tranche plus haute\n",
    "   - En pratique, **le mod√®le peut estimer qu‚Äôun service g√©n√©rique tr√®s fiable** (par exemple un intitul√© trop large ou basique) appartient aux tranches basses\n",
    "   - Tandis qu‚Äôun **service plus cibl√© ou sp√©cialis√©** avec une fiabilit√© moyenne peut √™tre associ√© aux tranches hautes\n",
    "\n",
    "### üìå Interpr√©tation m√©tier\n",
    "\n",
    "Ce comportement n'est pas une erreur mais une **manifestation de la logique d'apprentissage supervis√©** :\n",
    "\n",
    "> Le mod√®le de classification apprend des **r√®gles implicites** pr√©sentes dans les donn√©es d‚Äôentra√Ænement. Il peut consid√©rer certaines descriptions comme typiquement premium, ind√©pendamment du niveau de fiabilit√©, ce qui entra√Æne une tranche \"Haute\" m√™me avec une fiabilit√© modeste.\n",
    "\n",
    "### ‚úÖ Conclusion\n",
    "\n",
    "Il est important de retenir :\n",
    "\n",
    "- Le syst√®me n‚Äôutilise **pas une simple r√®gle √† seuils** sur le prix pour classer les tranches\n",
    "- Il s‚Äôagit d‚Äôun mod√®le **entra√Æn√© √† partir d‚Äôobservations r√©elles**\n",
    "- Les incoh√©rences apparentes sont souvent dues √† des **corr√©lations non triviales** dans les donn√©es (nature du service, vocabulaire utilis√©, etc.)\n",
    "\n",
    "Cette explication souligne la complexit√© du comportement des mod√®les d‚ÄôIA, et la n√©cessit√© de les √©valuer **sur l‚Äôensemble du pipeline**, pas uniquement sur un cas particulier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fd0fa64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fiabilit√© = 0% ‚Üí Prix pr√©dit = 3.45 ‚Ç¨\n",
      "Fiabilit√© = 10% ‚Üí Prix pr√©dit = 3.45 ‚Ç¨\n",
      "Fiabilit√© = 20% ‚Üí Prix pr√©dit = 3.45 ‚Ç¨\n",
      "Fiabilit√© = 30% ‚Üí Prix pr√©dit = 3.45 ‚Ç¨\n",
      "Fiabilit√© = 40% ‚Üí Prix pr√©dit = 3.45 ‚Ç¨\n",
      "Fiabilit√© = 50% ‚Üí Prix pr√©dit = 3.45 ‚Ç¨\n",
      "Fiabilit√© = 60% ‚Üí Prix pr√©dit = 3.45 ‚Ç¨\n",
      "Fiabilit√© = 70% ‚Üí Prix pr√©dit = 3.45 ‚Ç¨\n",
      "Fiabilit√© = 80% ‚Üí Prix pr√©dit = 3.45 ‚Ç¨\n",
      "Fiabilit√© = 85% ‚Üí Prix pr√©dit = 3.55 ‚Ç¨\n",
      "Fiabilit√© = 90% ‚Üí Prix pr√©dit = 3.72 ‚Ç¨\n",
      "Fiabilit√© = 91% ‚Üí Prix pr√©dit = 3.72 ‚Ç¨\n",
      "Fiabilit√© = 92% ‚Üí Prix pr√©dit = 3.72 ‚Ç¨\n",
      "Fiabilit√© = 93% ‚Üí Prix pr√©dit = 3.72 ‚Ç¨\n",
      "Fiabilit√© = 94% ‚Üí Prix pr√©dit = 3.84 ‚Ç¨\n",
      "Fiabilit√© = 95% ‚Üí Prix pr√©dit = 3.97 ‚Ç¨\n",
      "Fiabilit√© = 96% ‚Üí Prix pr√©dit = 4.04 ‚Ç¨\n",
      "Fiabilit√© = 97% ‚Üí Prix pr√©dit = 4.19 ‚Ç¨\n",
      "Fiabilit√© = 98% ‚Üí Prix pr√©dit = 4.33 ‚Ç¨\n",
      "Fiabilit√© = 99% ‚Üí Prix pr√©dit = 4.33 ‚Ç¨\n",
      "Fiabilit√© = 100% ‚Üí Prix pr√©dit = 4.3 ‚Ç¨\n"
     ]
    }
   ],
   "source": [
    "# Exemple de description et niveau √† tester\n",
    "desc = \"Je fais le m√©nage\"\n",
    "\n",
    "# Test de l‚Äôimpact de la fiabilit√© sur la pr√©diction du prix\n",
    "for f in [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.85, 0.9, 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99, 1.0]:\n",
    "    prix = predict_price(desc, f)\n",
    "    print(f\"Fiabilit√© = {f*100:.0f}% ‚Üí Prix pr√©dit = {prix} ‚Ç¨\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
