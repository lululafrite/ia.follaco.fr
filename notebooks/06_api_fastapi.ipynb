{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af442a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from fastapi.concurrency import run_in_threadpool\n",
    "\n",
    "# Création de l'application FastAPI\n",
    "app = FastAPI(title=\"API Prédiction de Prix avec Deep Learning\")\n",
    "\n",
    "# Chargement du modèle Keras et du scaler utilisé lors de l'entraînement\n",
    "MODEL_PATH = \"models/deep/deep_model.h5\"\n",
    "SCALER_PATH = \"models/deep/scaler.pkl\"\n",
    "\n",
    "model = load_model(MODEL_PATH)\n",
    "scaler = joblib.load(SCALER_PATH)\n",
    "\n",
    "# Chargement du modèle d'embedding pour la description\n",
    "embedding_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Mapping texte → entier pour le niveau vendeur\n",
    "# Doit correspondre aux valeurs présentes dans le CSV d'entraînement\n",
    "niveau_to_int = {\n",
    "    \"Nouveau\": 1,\n",
    "    \"Confirmé\": 2,\n",
    "    \"Top\": 3\n",
    "}\n",
    "\n",
    "# Schéma d'entrée de la requête POST via Pydantic\n",
    "class InputData(BaseModel):\n",
    "    Description: str\n",
    "    Niveau: str\n",
    "    Fiabilite: float\n",
    "\n",
    "# Fonction de prétraitement : transforme les données utilisateur en entrée modèle\n",
    "def preprocess_input(data: InputData):\n",
    "    # Embedding de la description\n",
    "    embedding = embedding_model.encode([data.Description]).flatten()\n",
    "\n",
    "    # One-hot encoding du niveau (3 colonnes)\n",
    "    niveau_mapping = [\"Nouveau\", \"Confirmé\", \"Top\"]\n",
    "    niveau_ohe = [1 if data.Niveau == niveau else 0 for niveau in niveau_mapping]\n",
    "\n",
    "    # Fusion finale (384 + 3 + 1 = 388 colonnes)\n",
    "    features = np.hstack([embedding, niveau_ohe, [data.Fiabilite]])\n",
    "\n",
    "    print(\">> Shape des features brutes :\", features.shape)  # Doit être (388,)\n",
    "    \n",
    "    features_scaled = scaler.transform([features])\n",
    "    return features_scaled\n",
    "\n",
    "\n",
    "# Route principale de prédiction\n",
    "@app.post(\"/predict\")\n",
    "async def predict_price(input_data: InputData):\n",
    "    try:\n",
    "        X = preprocess_input(input_data)\n",
    "\n",
    "        print(\">> Prédiction sur X :\", X.shape)\n",
    "        import sys; sys.stdout.flush()\n",
    "\n",
    "        # Appel du modèle dans un thread isolé pour éviter les crashs TensorFlow\n",
    "        y_pred = await run_in_threadpool(lambda: model.predict(X)[0][0])\n",
    "\n",
    "        return {\"prix_predit\": round(float(y_pred), 2)}\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(\"ERREUR PREDICTION :\")\n",
    "        traceback.print_exc()\n",
    "        return {\"error\": str(e)}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
