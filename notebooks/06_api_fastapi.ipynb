{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af442a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from fastapi.concurrency import run_in_threadpool\n",
    "\n",
    "# üåê Cr√©ation de l'application FastAPI\n",
    "app = FastAPI(title=\"API Pr√©diction de Prix avec Deep Learning\")\n",
    "\n",
    "# üì¶ Chargement du mod√®le Keras et du scaler utilis√© lors de l'entra√Ænement\n",
    "MODEL_PATH = \"models/deep/deep_model.h5\"\n",
    "SCALER_PATH = \"models/deep/scaler.pkl\"\n",
    "\n",
    "model = load_model(MODEL_PATH)\n",
    "scaler = joblib.load(SCALER_PATH)\n",
    "\n",
    "# üî§ Chargement du mod√®le d'embedding pour la description\n",
    "embedding_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# üîÅ Mapping texte ‚Üí entier pour le niveau vendeur\n",
    "# üìå Doit correspondre aux valeurs pr√©sentes dans le CSV d'entra√Ænement\n",
    "niveau_to_int = {\n",
    "    \"Nouveau\": 1,\n",
    "    \"Confirm√©\": 2,\n",
    "    \"Top\": 3\n",
    "}\n",
    "\n",
    "# üßæ Sch√©ma d'entr√©e de la requ√™te POST via Pydantic\n",
    "class InputData(BaseModel):\n",
    "    Description: str\n",
    "    Niveau: str\n",
    "    Fiabilite: float\n",
    "\n",
    "# üîç Fonction de pr√©traitement : transforme les donn√©es utilisateur en entr√©e mod√®le\n",
    "def preprocess_input(data: InputData):\n",
    "    # Embedding de la description\n",
    "    embedding = embedding_model.encode([data.Description]).flatten()\n",
    "\n",
    "    # One-hot encoding du niveau (3 colonnes)\n",
    "    niveau_mapping = [\"Nouveau\", \"Confirm√©\", \"Top\"]\n",
    "    niveau_ohe = [1 if data.Niveau == niveau else 0 for niveau in niveau_mapping]\n",
    "\n",
    "    # Fusion finale (384 + 3 + 1 = 388 colonnes)\n",
    "    features = np.hstack([embedding, niveau_ohe, [data.Fiabilite]])\n",
    "\n",
    "    print(\">> Shape des features brutes :\", features.shape)  # Doit √™tre (388,)\n",
    "    \n",
    "    features_scaled = scaler.transform([features])\n",
    "    return features_scaled\n",
    "\n",
    "\n",
    "# üì® Route principale de pr√©diction\n",
    "@app.post(\"/predict\")\n",
    "async def predict_price(input_data: InputData):\n",
    "    try:\n",
    "        X = preprocess_input(input_data)\n",
    "\n",
    "        print(\">> Pr√©diction sur X :\", X.shape)\n",
    "        import sys; sys.stdout.flush()\n",
    "\n",
    "        # ‚ö†Ô∏è Appel du mod√®le dans un thread isol√© pour √©viter les crashs TensorFlow\n",
    "        y_pred = await run_in_threadpool(lambda: model.predict(X)[0][0])\n",
    "\n",
    "        return {\"prix_predit\": round(float(y_pred), 2)}\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(\"‚ùå ERREUR PREDICTION :\")\n",
    "        traceback.print_exc()\n",
    "        return {\"error\": str(e)}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
