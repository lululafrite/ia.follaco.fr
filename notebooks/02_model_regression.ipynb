{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07dc1ac9",
   "metadata": {},
   "source": [
    "# Notebook `02_model_regression.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7ce7f5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120aae6d",
   "metadata": {},
   "source": [
    "## üìà Entra√Ænement des mod√®les de r√©gression\n",
    "\n",
    "Ce notebook a pour objectif de construire et √©valuer diff√©rents **mod√®les de r√©gression** pour pr√©dire le **prix d‚Äôun service Fiverr** √† partir de ses caract√©ristiques (texte, fiabilit√©, etc.).\n",
    "\n",
    "Nous comparons ici plusieurs algorithmes supervis√©s, avec ou sans transformation logarithmique, pour identifier le mod√®le le plus robuste.\n",
    "\n",
    "## üéØ Objectifs\n",
    "\n",
    "- Charger les features et les cibles pr√©par√©es (`X_scaled`, `y_reg`)\n",
    "- Tester plusieurs mod√®les de r√©gression (lin√©aire, arbres, boosting, etc.)\n",
    "- √âvaluer les performances avec des m√©triques comme **MAE**, **RMSE** et **R¬≤**\n",
    "- S√©lectionner le meilleur mod√®le pour la pr√©diction du **prix r√©el**\n",
    "- Sauvegarder le mod√®le retenu pour les √©tapes de pr√©diction et de mise en production\n",
    "\n",
    "## ‚úÖ Comp√©tences mobilis√©es\n",
    "\n",
    "- **Bloc 3 ‚Äî C1** : Comparer les performances de plusieurs algorithmes de r√©gression pour choisir le plus adapt√© √† la probl√©matique.\n",
    "- **Bloc 3 ‚Äî C2** : Adapter les donn√©es √† la forme attendue par les mod√®les (notamment via `StandardScaler` et transformation `log`).\n",
    "- **Bloc 3 ‚Äî C3** : Entra√Æner un mod√®le de r√©gression en optimisant ses performances selon des indicateurs clairement d√©finis (MAE, RMSE, R¬≤).\n",
    "\n",
    "*Ce notebook permet de poser les fondations du moteur de pr√©diction de prix utilis√© dans l'application finale.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d647494d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5128c02d",
   "metadata": {},
   "source": [
    "## üß≠ Sommaire\n",
    "\n",
    "1. [Importation des biblioth√®ques](#-1-importation-des-biblioth√®ques)\n",
    "2. [Chargement des donn√©es transform√©es](#-2-chargement-des-donn√©es-transform√©es)\n",
    "3. [Construction des variables explicatives (`X`) et cibles (`y`)](#-3-construction-des-variables-explicatives-x-et-cibles-y)\n",
    "4. [S√©paration des donn√©es et d√©finition des mod√®les](#-4-s√©paration-des-donn√©es-et-d√©finition-des-mod√®les)\n",
    "5. [Entra√Ænement, √©valuation et sauvegarde des mod√®les de r√©gression](#-5-entra√Ænement-√©valuation-et-sauvegarde-des-mod√®les-de-r√©gression)\n",
    "6. [Sauvegarde du pr√©processeur et des colonnes de features](#-6-sauvegarde-du-pr√©processeur-et-des-colonnes-de-features)\n",
    "7. [R√©sultats comparatifs des mod√®les de r√©gression](#-7-r√©sultats-comparatifs-des-mod√®les-de-r√©gression)\n",
    "8. [S√©lection du meilleur mod√®le de r√©gression](#-8-s√©lection-du-meilleur-mod√®le-de-r√©gression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c9602a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de00436",
   "metadata": {},
   "source": [
    "## üìò 1. Importation des biblioth√®ques\n",
    "\n",
    "### ‚ùì 1.1. Pourquoi cette √©tape ?\n",
    "\n",
    "Avant d‚Äôentamer le processus de mod√©lisation, il est indispensable d‚Äôimporter toutes les biblioth√®ques n√©cessaires au traitement des donn√©es, √† l‚Äôentra√Ænement des mod√®les et √† leur √©valuation.\n",
    "\n",
    "Les modules import√©s ici permettent de :\n",
    "\n",
    "- **Charger et manipuler** les donn√©es (`pandas`, `numpy`, `os`, `joblib`)\n",
    "- **Pr√©parer les jeux de donn√©es** (`train_test_split`, `StandardScaler`)\n",
    "- **Entra√Æner plusieurs types de mod√®les de r√©gression** :\n",
    "  - `LinearRegression`, `Ridge`\n",
    "  - `DecisionTreeRegressor`, `RandomForestRegressor`\n",
    "  - `GradientBoostingRegressor`, `XGBRegressor`\n",
    "  - `KNeighborsRegressor`\n",
    "- **√âvaluer les performances** via des m√©triques (`MAE`, `RMSE`, `R¬≤`)\n",
    "- **G√©n√©rer des embeddings textuels** √† partir de la description (`SentenceTransformer`)\n",
    "\n",
    "---\n",
    "\n",
    "### üêç 1.2. Script d‚Äôimportation des biblioth√®ques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d48fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des biblioth√®ques n√©cessaires √† la mod√©lisation\n",
    "\n",
    "# Manipulation de donn√©es\n",
    "import pandas as pd                                              # Manipulation de DataFrames\n",
    "import numpy as np                                               # Fonctions math√©matiques avanc√©es\n",
    "import os                                                        # Interaction avec le syst√®me de fichiers\n",
    "import joblib                                                    # Sauvegarde et chargement de mod√®les\n",
    "\n",
    "# Pr√©paration des donn√©es\n",
    "from sklearn.model_selection import train_test_split             # D√©coupe en train/test\n",
    "from sklearn.preprocessing import StandardScaler                 # Normalisation des donn√©es num√©riques\n",
    "\n",
    "# Mod√®les de r√©gression standards\n",
    "from sklearn.linear_model import LinearRegression, Ridge         # R√©gressions lin√©aires (classique et r√©gularis√©e)\n",
    "from sklearn.ensemble import RandomForestRegressor               # For√™ts al√©atoires\n",
    "from sklearn.ensemble import GradientBoostingRegressor           # Boosting\n",
    "from sklearn.tree import DecisionTreeRegressor                   # Arbre de r√©gression simple\n",
    "from sklearn.neighbors import KNeighborsRegressor                # R√©gression par les k plus proches voisins\n",
    "from xgboost import XGBRegressor                                 # R√©gression boost√©e performante (XGBoost)\n",
    "\n",
    "# √âvaluation des performances\n",
    "from sklearn.metrics import mean_absolute_error                  # - MAE : erreur absolue moyenne\n",
    "from sklearn.metrics import  mean_squared_error                  # - MSE : erreur quadratique moyenne\n",
    "from sklearn.metrics import r2_score                             # - R¬≤ : coefficient de d√©termination (qualit√© d'ajustement)\n",
    "\n",
    "# NLP - Embeddings de texte\n",
    "from sentence_transformers import SentenceTransformer            # G√©n√©ration de vecteurs √† partir de texte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8270230",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bd75e7",
   "metadata": {},
   "source": [
    "## üì¶ 2. Chargement des donn√©es transform√©es\n",
    "\n",
    "### ‚ùì 2.1. Pourquoi cette √©tape maintenant ?\n",
    "\n",
    "Apr√®s le pr√©traitement complet du jeu de donn√©es brut, nous avons sauvegard√© une version transform√©e et enrichie (`fiverr_cleaned_transformed.csv`).  \n",
    "Cette √©tape consiste √† **recharger ce fichier pr√©par√©** pour d√©marrer la phase de mod√©lisation.\n",
    "\n",
    "Ce fichier contient :\n",
    "- Des **colonnes nettoy√©es et pr√™tes √† l‚Äôemploi** : `Description`, `Niveau`, `Prix`, `Fiabilite`, etc.\n",
    "- Les **valeurs manquantes imput√©es**\n",
    "- Les descriptions textuelles **nettoy√©es des stopwords** et formules types\n",
    "- Des formats unifi√©s (`float`, `str`, etc.)\n",
    "\n",
    "### üéØ 2.2. R√©sultat attendu\n",
    "\n",
    "- Les donn√©es sont charg√©es dans un objet `DataFrame` nomm√© `df`.\n",
    "- Elles sont pr√™tes √† √™tre utilis√©es pour la phase de mod√©lisation (r√©gression et/ou classification).\n",
    "\n",
    "---\n",
    "\n",
    "### üêç 2.3. Script de chargement des donn√©es transform√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d603eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du jeu de donn√©es transform√©\n",
    "\n",
    "# Lecture du fichier CSV contenant les donn√©es nettoy√©es et enrichies\n",
    "# - Le fichier 'fiverr_cleaned_transformed.csv' est issu des √©tapes pr√©c√©dentes de pr√©processing.\n",
    "# - Il contient d√©j√† les colonnes pr√™tes √† √™tre utilis√©es pour l'entra√Ænement des mod√®les (ex. : Description nettoy√©e, Fiabilit√©, Niveau, Prix, etc.)\n",
    "\n",
    "df = pd.read_csv(\"../data/fiverr_cleaned_dl_notebook.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b7c68e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3674825b",
   "metadata": {},
   "source": [
    "## üß† 3. Construction des variables explicatives (`X`) et cibles (`y`)\n",
    "\n",
    "### ‚ùì 3.1. Pourquoi cette √©tape maintenant ?\n",
    "\n",
    "Nous allons maintenant pr√©parer les **donn√©es d‚Äôentr√©e du mod√®le** (`X`) et la **variable √† pr√©dire** (`y`), √† partir du fichier transform√©.  \n",
    "Les colonnes choisies sont pr√™tes √† l‚Äôemploi gr√¢ce aux √©tapes pr√©c√©dentes (nettoyage, vectorisation, standardisation).\n",
    "\n",
    "### üîß 3.2. D√©tails des transformations effectu√©es\n",
    "\n",
    "| √âtape | Description |\n",
    "|-------|-------------|\n",
    "| üß© Embedding | Les titres de service (`Description`) sont transform√©s en **vecteurs num√©riques de 384 dimensions** via un mod√®le pr√©-entra√Æn√© (`all-MiniLM-L6-v2`). |\n",
    "| ‚öñÔ∏è Normalisation | La variable `Fiabilite` est **standardis√©e** √† l‚Äôaide d‚Äôun `StandardScaler`. Cela am√©liore la performance de nombreux mod√®les. |\n",
    "| üß∑ Fusion | Les embeddings et la fiabilit√© standardis√©e sont **fusionn√©s horizontalement** dans une matrice `X` utilis√©e pour l'entra√Ænement. |\n",
    "| üéØ Cibles | Deux cibles sont d√©finies : `y_log` (log du prix pour l'entra√Ænement) et `y_real` (prix r√©el pour l‚Äô√©valuation des performances). |\n",
    "\n",
    "> üí° Remarque : le one-hot encoding de `Niveau` peut √™tre r√©int√©gr√© ult√©rieurement si l'on souhaite inclure cette variable dans les features.\n",
    "\n",
    "---\n",
    "\n",
    "### üêç 3.3. Script de construction des variables explicatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "625bcec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad8fa897600f4ae38cc6556ca548c56e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# G√©n√©ration des embeddings √† partir des descriptions textuelles\n",
    "\n",
    "# Mod√®le pr√©-entra√Æn√© pour transformer le texte en vecteurs num√©riques (384 dimensions)\n",
    "embedding_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Transformation de chaque description textuelle en vecteur dense\n",
    "# - On s'assure que la colonne Description est bien convertie en cha√Æne de caract√®res\n",
    "# - Le param√®tre show_progress_bar=True affiche une barre de progression utile en cas de grand volume\n",
    "embeddings = embedding_model.encode(df[\"Description\"].astype(str).tolist(), show_progress_bar=True)\n",
    "\n",
    "# Conversion en DataFrame avec noms explicites pour chaque dimension\n",
    "embed_df = pd.DataFrame(embeddings, columns=[f\"emb_{i}\" for i in range(384)])\n",
    "\n",
    "# Encodage one-hot du niveau (comment√© ici si non utilis√©)\n",
    "# - Utile si l'on souhaite int√©grer le niveau du vendeur dans le mod√®le\n",
    "# niveau_encoded = pd.get_dummies(df[\"Niveau\"], prefix=\"Niveau\")\n",
    "\n",
    "# Standardisation de la variable Fiabilit√©\n",
    "\n",
    "# - Le StandardScaler transforme la variable pour qu‚Äôelle ait une moyenne de 0 et un √©cart-type de 1\n",
    "# - Cela facilite la convergence des algorithmes sensibles √† l‚Äô√©chelle (ex. : r√©gression, KNN...)\n",
    "scaler = StandardScaler()\n",
    "fiabilite_scaled = scaler.fit_transform(df[[\"Fiabilite\"]])\n",
    "\n",
    "# Conversion en DataFrame avec nom de colonne conserv√©\n",
    "fiabilite_df = pd.DataFrame(fiabilite_scaled, columns=[\"Fiabilite\"])\n",
    "\n",
    "# Fusion des diff√©rentes sources de donn√©es\n",
    "\n",
    "# - On concat√®ne horizontalement les embeddings textuels et la fiabilit√© normalis√©e\n",
    "# - Le DataFrame final `X` est l‚Äôensemble des features utilis√©es pour l‚Äôentra√Ænement\n",
    "X = pd.concat([embed_df, fiabilite_df], axis=1)\n",
    "\n",
    "# Cibles √† pr√©dire\n",
    "# - y_log : version logarithmique du prix (pour mod√®le)\n",
    "# - y_real : prix r√©el (pour interpr√©tation ou √©valuation)\n",
    "y_log = df[\"Prix_log\"]\n",
    "y_real = df[\"Prix\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8769b2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb4d5c0",
   "metadata": {},
   "source": [
    "## üß™ 4. S√©paration des donn√©es et d√©finition des mod√®les\n",
    "\n",
    "### ‚ùì 4.1. Pourquoi cette √©tape maintenant ?\n",
    "\n",
    "Avant de tester nos mod√®les, il est indispensable de :\n",
    "1. **Diviser le jeu de donn√©es** en un ensemble d'entra√Ænement (80 %) et un ensemble de test (20 %) ;\n",
    "2. **D√©finir une s√©lection de mod√®les** √† comparer objectivement sur les m√™mes donn√©es.\n",
    "\n",
    "### üîÑ 4.2. D√©tails de la division train/test\n",
    "\n",
    "| Variable        | R√¥le                                      |\n",
    "|----------------|-------------------------------------------|\n",
    "| `X_train`       | Donn√©es d'entra√Ænement (features)         |\n",
    "| `X_test`        | Donn√©es de test (features)                |\n",
    "| `y_train`       | Prix log transform√© ‚Äî √† pr√©dire (train)   |\n",
    "| `y_test`        | Prix log transform√© ‚Äî √† pr√©dire (test)    |\n",
    "| `y_real_train`  | Prix r√©el pour comparaison √©ventuelle     |\n",
    "| `y_real_test`   | Prix r√©el pour l‚Äô√©valuation des erreurs   |\n",
    "\n",
    "### ü§ñ 4.3. Mod√®les s√©lectionn√©s pour la r√©gression\n",
    "\n",
    "| Mod√®le               | Description rapide                           |\n",
    "|----------------------|----------------------------------------------|\n",
    "| `LinearRegression`   | R√©gression lin√©aire classique                |\n",
    "| `Ridge`              | R√©gression lin√©aire avec r√©gularisation L2   |\n",
    "| `RandomForest`       | Agr√©gation d‚Äôarbres d√©cisionnels (bagging)   |\n",
    "| `GradientBoosting`   | Entra√Ænement s√©quentiel d‚Äôarbres faibles     |\n",
    "| `XGBoost`            | Boosting optimis√© tr√®s performant            |\n",
    "| `DecisionTree`       | Arbre de d√©cision unique                     |\n",
    "| `KNN Regressor`      | Moyenne des k plus proches voisins           |\n",
    "\n",
    "> ‚ö†Ô∏è Tous les mod√®les seront entra√Æn√©s sur les **m√™mes donn√©es** et √©valu√©s selon des m√©triques identiques pour un comparatif juste.\n",
    "\n",
    "---\n",
    "\n",
    "### üêç 4.4. Script de s√©paration des donn√©es et d√©finition des mod√®les"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174cc7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S√©paration des donn√©es en ensembles d'entra√Ænement et de test\n",
    "\n",
    "# X         : matrice des caract√©ristiques (embeddings + fiabilit√©)\n",
    "# y_log     : prix transform√© en √©chelle logarithmique (cible d'entra√Ænement)\n",
    "# y_real    : prix r√©el (utilis√© uniquement pour l'√©valuation, pas pour l'entra√Ænement)\n",
    "\n",
    "# Param√®tres :\n",
    "# - test_size=0.2        : 20 % des donn√©es seront utilis√©es pour les tests\n",
    "# - random_state=42      : graine al√©atoire pour garantir la reproductibilit√©\n",
    "\n",
    "X_train, X_test, y_train, y_test, y_real_train, y_real_test = train_test_split(\n",
    "    X, y_log, y_real, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# D√©finition des mod√®les de r√©gression √† comparer\n",
    "\n",
    "# Chaque mod√®le est instanci√© avec des param√®tres de base coh√©rents\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),                                            # - LinearRegression : mod√®le lin√©aire de base\n",
    "    \"Ridge\": Ridge(alpha=1.0),                                                          # - Ridge : r√©gression lin√©aire avec r√©gularisation L2      \n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),          # - Random Forest    : ensemble d‚Äôarbres (100 arbres, al√©atoire fix√©)\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(n_estimators=100, random_state=42),  # - Gradient Boosting: boosting d‚Äôarbres (100 it√©rations, al√©atoire fix√©)\n",
    "    \"XGBoost\": XGBRegressor(n_estimators=100, random_state=42, verbosity=0),            # - XGBoost          : gradient boosting tr√®s performant (100 arbres, verbosit√© coup√©e)    \n",
    "    \"Decision Tree\": DecisionTreeRegressor(random_state=42),                            # - Decision Tree    : arbre unique, simple √† interpr√©ter\n",
    "    \"KNN Regressor\": KNeighborsRegressor(n_neighbors=5)                                 # - KNN              : r√©gression par les k plus proches voisins (ici k=5)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b886b3f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbc81f8",
   "metadata": {},
   "source": [
    "## üß† 5. Entra√Ænement, √©valuation et sauvegarde des mod√®les de r√©gression\n",
    "\n",
    "### üéØ 5.1. Objectif\n",
    "\n",
    "Comparer les performances de plusieurs mod√®les de r√©gression sur la pr√©diction du **prix r√©el**, √† partir de la cible log-transform√©e (`Prix_log`).  \n",
    "Nous allons :\n",
    "- entra√Æner chaque mod√®le sur les m√™mes donn√©es (`X_train`, `y_train`),\n",
    "- pr√©dire sur les m√™mes donn√©es de test (`X_test`),\n",
    "- √©valuer les performances selon 3 m√©triques principales.\n",
    "\n",
    "### üìè 5.2. M√©triques utilis√©es\n",
    "\n",
    "| M√©trique | Signification                             |\n",
    "|----------|-------------------------------------------|\n",
    "| MAE      | Erreur absolue moyenne                    |\n",
    "| RMSE     | Erreur quadratique moyenne                |\n",
    "| R¬≤       | Coefficient de d√©termination              |\n",
    "\n",
    "> üîÅ Tous les r√©sultats sont **calcul√©s √† partir des prix r√©els** (apr√®s transformation inverse du log).\n",
    "\n",
    "### üíæ 5.3. Sauvegarde automatique\n",
    "\n",
    "Chaque mod√®le est enregistr√© automatiquement dans le dossier :\n",
    "\n",
    "\n",
    "### ü•á 5.4. S√©lection du meilleur mod√®le\n",
    "\n",
    "Le **mod√®le ayant le plus petit RMSE** est conserv√© comme meilleur mod√®le (`best_model`), et son nom est stock√© pour une utilisation future.\n",
    "\n",
    "---\n",
    "\n",
    "### üêç 5.5. Script de s√©lection du meilleur mod√®le\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151d60b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entra√Ænement et √©valuation de tous les mod√®les de r√©gression\n",
    "\n",
    "results = []                          # Liste pour stocker les scores de chaque mod√®le\n",
    "best_model = None                    # Pour conserver le meilleur mod√®le trouv√©\n",
    "best_rmse = float('inf')             # Initialisation du plus petit RMSE √† l‚Äôinfini\n",
    "\n",
    "# Boucle sur chaque mod√®le du dictionnaire\n",
    "for name, model in models.items():\n",
    "    # Entra√Ænement du mod√®le sur l'ensemble d'entra√Ænement\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Pr√©diction sur l‚Äôensemble de test (prix en √©chelle log)\n",
    "    y_pred_log = model.predict(X_test)\n",
    "\n",
    "    # Transformation inverse pour retrouver les prix r√©els\n",
    "    y_pred = np.expm1(y_pred_log)\n",
    "\n",
    "    # Calcul des m√©triques d‚Äô√©valuation\n",
    "    mae = mean_absolute_error(y_real_test, y_pred)  # Erreur absolue moyenne\n",
    "    rmse = np.sqrt(mean_squared_error(y_real_test, y_pred))  # Erreur quadratique moyenne\n",
    "    r2 = r2_score(y_real_test, y_pred)  # Coefficient de d√©termination\n",
    "\n",
    "    # Stockage des r√©sultats arrondis dans une liste de dictionnaires\n",
    "    results.append({\n",
    "        \"Mod√®le\": name,\n",
    "        \"MAE\": round(mae, 2),\n",
    "        \"RMSE\": round(rmse, 2),\n",
    "        \"R¬≤\": round(r2, 4)\n",
    "    })\n",
    "\n",
    "    # Sauvegarde du mod√®le entra√Æn√© dans le dossier appropri√©\n",
    "    model_filename = f\"{name.replace(' ', '_').lower()}_notebook.pkl\"\n",
    "    joblib.dump(model, f\"../models/regression/{model_filename}\")\n",
    "\n",
    "    # Suivi du meilleur mod√®le (bas√© sur le plus petit RMSE)\n",
    "    if rmse < best_rmse:\n",
    "        best_rmse = rmse\n",
    "        best_model = model\n",
    "        best_name = name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876bcd05",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614a0d21",
   "metadata": {},
   "source": [
    "## üíæ 6. Sauvegarde du pr√©processeur et des colonnes de features\n",
    "\n",
    "### üéØ 6.1. Objectif\n",
    "\n",
    "Pour garantir que le pipeline de pr√©diction future soit **reproductible et coh√©rent**, il est indispensable de sauvegarder :\n",
    "- le **scaler** utilis√© pour la standardisation de la colonne `Fiabilite` (ici : `StandardScaler`),\n",
    "- la **liste exacte des colonnes** utilis√©es comme features (noms et ordre).\n",
    "\n",
    "Cela √©vite les erreurs de transformation ou de dimensions lors de l'inf√©rence en production ou dans l‚Äôapplication Gradio.\n",
    "\n",
    "### üß± 6.2. √âl√©ments sauvegard√©s\n",
    "\n",
    "| √âl√©ment         | Chemin de sauvegarde                  | Description |\n",
    "|-----------------|----------------------------------------|-------------|\n",
    "| `scaler`        | `models/regression/scaler.pkl`        | Objet `StandardScaler` entra√Æn√© sur la fiabilit√© |\n",
    "| `columns_used`  | `models/columns_used.pkl`             | Liste ordonn√©e des noms de colonnes de `X` |\n",
    "\n",
    "---\n",
    "\n",
    "### üêç 6.3. Script de sauvegarde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "648dd18c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/columns_used_notebook.pkl']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sauvegarde du scaler et des colonnes utilis√©es\n",
    "\n",
    "# Le mod√®le s√©lectionn√© (best_model) a d√©j√† √©t√© sauvegard√© pr√©c√©demment dans la boucle.\n",
    "# Ici, nous sauvegardons le pr√©processeur utilis√© (StandardScaler) et la liste des colonnes du jeu de donn√©es final.\n",
    "\n",
    "# Sauvegarde du scaler utilis√© pour la standardisation de la variable 'Fiabilite'\n",
    "# Cela permettra de reproduire exactement la m√™me transformation √† l'inf√©rence\n",
    "joblib.dump(scaler, \"../models/regression/scaler_notebook.pkl\")\n",
    "\n",
    "# Sauvegarde de la liste des colonnes utilis√©es dans X (ordre et noms)\n",
    "# Utile pour reconstituer la m√™me matrice de features √† la pr√©diction\n",
    "joblib.dump(X.columns.tolist(), \"../models/columns_used_notebook.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc140c03",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79aa1767",
   "metadata": {},
   "source": [
    "## üèÅ 7. R√©sultats comparatifs des mod√®les de r√©gression\n",
    "\n",
    "### üìä 7.1. Tableau de synth√®se des performances\n",
    "\n",
    "Une fois les mod√®les entra√Æn√©s, nous comparons leurs performances sur l‚Äôensemble de test √† l‚Äôaide des m√©triques suivantes :\n",
    "\n",
    "| Mod√®le              | MAE  | RMSE | R¬≤    |\n",
    "|---------------------|------|------|-------|\n",
    "| ... (ex. Ridge, RF) | ...  | ...  | ...   |\n",
    "\n",
    "Le tableau est tri√© selon la **valeur croissante du RMSE**, afin de visualiser directement les mod√®les les plus performants.\n",
    "\n",
    "> ‚ÑπÔ∏è Toutes les m√©triques sont calcul√©es **sur les prix r√©els**, apr√®s transformation inverse du logarithme.\n",
    "\n",
    "### ü•á 7.2. Meilleur mod√®le s√©lectionn√©\n",
    "\n",
    "Le **mod√®le ayant obtenu le plus faible RMSE** est automatiquement s√©lectionn√© comme mod√®le final (`best_model`).  \n",
    "Son nom est affich√© √† la fin du tableau pour confirmation.\n",
    "\n",
    "---\n",
    "\n",
    "### üêç 7.3. Script d‚Äôaffichage des performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "60311057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä R√©sultats comparatifs (√©valu√©s sur les vrais prix) :\n",
      "\n",
      "| Mod√®le            |   MAE |   RMSE |      R¬≤ |\n",
      "|:------------------|------:|-------:|--------:|\n",
      "| Gradient Boosting |  3.21 |   4.9  |  0.2566 |\n",
      "| XGBoost           |  3.33 |   5    |  0.2274 |\n",
      "| Random Forest     |  3.32 |   5.03 |  0.2173 |\n",
      "| Ridge             |  3.82 |   5.47 |  0.0748 |\n",
      "| KNN Regressor     |  3.99 |   5.8  | -0.0407 |\n",
      "| Decision Tree     |  4.43 |   7.14 | -0.577  |\n",
      "| Linear Regression |  5.86 |   9.9  | -2.0358 |\n",
      "\n",
      "‚úÖ Meilleur mod√®le : Gradient Boosting (RMSE = 4.9)\n"
     ]
    }
   ],
   "source": [
    "# Affichage des r√©sultats comparatifs des mod√®les de r√©gression\n",
    "\n",
    "# Transformation de la liste des r√©sultats en DataFrame et tri par RMSE (croissant)\n",
    "df_results = pd.DataFrame(results).sort_values(\"RMSE\")\n",
    "\n",
    "# Affichage format√© des r√©sultats en tableau Markdown\n",
    "print(\"R√©sultats comparatifs (√©valu√©s sur les vrais prix) :\\n\")\n",
    "print(df_results.to_markdown(index=False))  # affichage lisible dans les notebooks / consoles\n",
    "\n",
    "# ü•á Rappel du meilleur mod√®le\n",
    "print(f\"\\nMeilleur mod√®le : {best_name} (RMSE = {round(best_rmse, 2)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62ee0e2",
   "metadata": {},
   "source": [
    "## üèÜ 8. S√©lection du meilleur mod√®le de r√©gression\n",
    "\n",
    "Apr√®s avoir entra√Æn√© et compar√© **7 mod√®les de r√©gression**, leurs performances ont √©t√© √©valu√©es selon trois m√©triques essentielles :  \n",
    "- **MAE** : Erreur absolue moyenne (plus c‚Äôest bas, mieux c‚Äôest)  \n",
    "- **RMSE** : Racine de l'erreur quadratique moyenne (plus c‚Äôest bas, mieux c‚Äôest)  \n",
    "- **R¬≤** : Coefficient de d√©termination (plus c‚Äôest proche de 1, mieux c‚Äôest)\n",
    "\n",
    "---\n",
    "\n",
    "### üìä 8.1. R√©sultats comparatifs (√©valu√©s sur les vrais prix)\n",
    "\n",
    "| Mod√®le            |   MAE |   RMSE |    R¬≤    |\n",
    "|-------------------|-------|--------|----------|\n",
    "| **Gradient Boosting** |  3.21 |   4.90 | **0.2566** |\n",
    "| XGBoost           |  3.33 |   5.00 | 0.2274   |\n",
    "| Random Forest     |  3.32 |   5.03 | 0.2173   |\n",
    "| Ridge             |  3.82 |   5.47 | 0.0748   |\n",
    "| KNN Regressor     |  3.99 |   5.80 | -0.0407  |\n",
    "| Decision Tree     |  4.43 |   7.14 | -0.5770  |\n",
    "| Linear Regression |  5.86 |   9.90 | -2.0353  |\n",
    "\n",
    "‚úÖ **Meilleur mod√®le : Gradient Boosting (RMSE = 4.90)**\n",
    "\n",
    "---\n",
    "\n",
    "‚ÑπÔ∏è **Remarque sur le choix du mod√®le**\n",
    "\n",
    " Le mod√®le `Gradient Boosting` s‚Äôest impos√© comme le plus performant sur les donn√©es de test, avec :\n",
    " - la **plus faible erreur quadratique moyenne (RMSE)**,\n",
    " - un **coefficient R¬≤ positif**, montrant une bonne capacit√© de g√©n√©ralisation.\n",
    "\n",
    "Ce mod√®le sera donc utilis√© pour la suite de l‚Äôanalyse et dans l‚Äôapplication finale."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
