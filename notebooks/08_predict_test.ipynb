{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81b50826",
   "metadata": {},
   "source": [
    "## üéØ Objectif du notebook `06_predict.ipynb`\n",
    "\n",
    "Ce notebook a pour objectif de **charger les meilleurs mod√®les** s√©lectionn√©s lors des √©tapes pr√©c√©dentes et de **r√©aliser des pr√©dictions** sur de nouvelles donn√©es.\n",
    "\n",
    "### ‚ùì Pourquoi ne teste-t-on pas plusieurs mod√®les ici ?\n",
    "\n",
    "Les mod√®les utilis√©s sont ceux ayant d√©j√† √©t√© **rigoureusement compar√©s et valid√©s** dans les notebooks pr√©c√©dents :\n",
    "\n",
    "- üìò `03_model_regression.ipynb`  \n",
    "  ‚û§ S√©lection du mod√®le **XGBoost** comme meilleur pr√©dicteur de prix, bas√© sur les m√©triques MAE, RMSE, et R¬≤.\n",
    "\n",
    "- üìò `04_model_classification.ipynb`  \n",
    "  ‚û§ S√©lection du mod√®le **Random Forest** pour la classification binaire (tranche de prix), avec un score **Accuracy > 96%**.\n",
    "\n",
    "Il ne s‚Äôagit donc **pas ici de r√©entra√Æner ni de comparer d‚Äôautres mod√®les**, mais de :\n",
    "- charger les mod√®les finalis√©s,\n",
    "- appliquer les transformations n√©cessaires,\n",
    "- produire les pr√©dictions finales.\n",
    "\n",
    "Cette approche garantit :\n",
    "- la **coh√©rence avec l‚Äôensemble du pipeline**,\n",
    "- un **gain de temps** pour les pr√©dictions r√©elles,\n",
    "- une **tra√ßabilit√© claire** des choix m√©thodologiques pour la soutenance.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0166a017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìò 06_predict.ipynb ‚Äî √âvaluation crois√©e de toutes les paires de mod√®les\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# üîß Configuration\n",
    "REGRESSION_MODELS = [\n",
    "    \"decision_tree\", \"gradient_boosting\", \"knn_regressor\",\n",
    "    \"linear_regression\", \"random_forest\", \"ridge\", \"xgboost\"\n",
    "]\n",
    "\n",
    "CLASSIFICATION_MODELS = [\n",
    "    \"decision_tree\", \"knn_classifier\", \"logistic_regression\", \"random_forest\"\n",
    "]\n",
    "\n",
    "MODEL_DIR_REG = \"../models/regression\"\n",
    "MODEL_DIR_CLF = \"../models/classification\"\n",
    "SCALER_PATH = \"../models/regression/scaler_notebook.pkl\"\n",
    "COLUMNS_PATH = \"../models/columns_used_notebook.pkl\"\n",
    "OUTPUT_DIR = \"../data/predictions_grid\"\n",
    "\n",
    "# üîß Chargement des objets communs\n",
    "scaler = joblib.load(SCALER_PATH)\n",
    "columns = joblib.load(COLUMNS_PATH)\n",
    "embedding_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# üß± Fonction de pr√©traitement\n",
    "def preprocess_input(description: str, fiabilite: float) -> pd.DataFrame:\n",
    "    emb = embedding_model.encode([description])\n",
    "    emb_dict = {f\"emb_{i}\": emb[0][i] for i in range(384)}\n",
    "    row = {**emb_dict, \"Fiabilite\": fiabilite}\n",
    "    df = pd.DataFrame([row])\n",
    "    df = df.reindex(columns=columns, fill_value=0)\n",
    "    df[[\"Fiabilite\"]] = scaler.transform(df[[\"Fiabilite\"]])\n",
    "    return df\n",
    "\n",
    "# üß™ Chargement des donn√©es sources\n",
    "df_source = pd.read_csv(\"../data/fiverr_cleaned_dl_notebook.csv\")\n",
    "\n",
    "# üîÅ Boucle sur toutes les paires de mod√®les\n",
    "for reg_name in REGRESSION_MODELS:\n",
    "    reg_model = joblib.load(f\"{MODEL_DIR_REG}/{reg_name}_notebook.pkl\")\n",
    "\n",
    "    for clf_name in CLASSIFICATION_MODELS:\n",
    "        clf_model = joblib.load(f\"{MODEL_DIR_CLF}/{clf_name}_notebook.pkl\")\n",
    "\n",
    "        df = df_source.copy()\n",
    "\n",
    "        # üîÆ Pr√©dictions\n",
    "        df[\"Prix_pr√©dit\"] = df.apply(\n",
    "            lambda row: round(np.expm1(reg_model.predict(preprocess_input(row[\"Description\"], row[\"Fiabilite\"]))[0]) * 10, 2),\n",
    "            axis=1\n",
    "        )\n",
    "        df[\"Tranche_pr√©vue\"] = df.apply(\n",
    "            lambda row: clf_model.predict(preprocess_input(row[\"Description\"], row[\"Fiabilite\"]))[0],\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        # üíæ Sauvegarde du fichier de sortie\n",
    "        filename = f\"fiverr_predicted_{reg_name}_{clf_name}_notebook.csv\"\n",
    "        df.to_csv(os.path.join(OUTPUT_DIR, filename), index=False)\n",
    "        print(f\"‚úÖ Sauvegard√© : {filename}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfe5762",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# üìÇ R√©pertoire des fichiers de pr√©diction\n",
    "INPUT_DIR = \"../data/predictions_grid\"\n",
    "results = []\n",
    "\n",
    "# üîÅ Boucle sur les fichiers de pr√©diction\n",
    "for filename in os.listdir(INPUT_DIR):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        df = pd.read_csv(os.path.join(INPUT_DIR, filename))\n",
    "\n",
    "        # ‚ö†Ô∏è Ajout de la tranche r√©elle si manquante\n",
    "        if \"Tranche_r√©elle\" not in df.columns:\n",
    "            df[\"Tranche_r√©elle\"] = pd.qcut(df[\"Prix\"], q=3, labels=[\"Basse\", \"Moyenne\", \"Haute\"])\n",
    "\n",
    "        # üè∑Ô∏è Extraction des noms de mod√®les\n",
    "        reg_name, clf_name = filename.replace(\".csv\", \"\").replace(\"fiverr_predicted_\", \"\").split(\"__\")\n",
    "\n",
    "        # üìè Calcul des m√©triques\n",
    "        mae = mean_absolute_error(df[\"Prix\"], df[\"Prix_pr√©dit\"])\n",
    "        rmse = np.sqrt(mean_squared_error(df[\"Prix\"], df[\"Prix_pr√©dit\"]))\n",
    "        acc = accuracy_score(df[\"Tranche_r√©elle\"], df[\"Tranche_pr√©vue\"])\n",
    "\n",
    "        results.append({\n",
    "            \"R√©gression\": reg_name,\n",
    "            \"Classification\": clf_name,\n",
    "            \"MAE\": round(mae, 2),\n",
    "            \"RMSE\": round(rmse, 2),\n",
    "            \"Accuracy\": round(acc, 4)\n",
    "        })\n",
    "\n",
    "# üìä Affichage des r√©sultats\n",
    "df_results = pd.DataFrame(results).sort_values(by=\"RMSE\")\n",
    "print(\"üìà R√©sultats comparatifs des paires (ordonn√©s par RMSE) :\\n\")\n",
    "print(df_results.to_markdown(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ec53a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Chargement du mod√®le entra√Æn√© (doit √™tre un mod√®le √† base d‚Äôarbres)\n",
    "reg_model = joblib.load(\"models/regression/decision_tree.pkl\")\n",
    "columns = joblib.load(\"models/columns_used.pkl\")\n",
    "\n",
    "# Importance des variables\n",
    "importances = reg_model.feature_importances_\n",
    "features = pd.Series(importances, index=columns)\n",
    "\n",
    "# Affichage\n",
    "print(\"Importance de la variable Fiabilite :\", round(features[\"Fiabilite\"], 4))\n",
    "print(\"\\nTop 10 features :\")\n",
    "print(features.sort_values(ascending=False).head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
