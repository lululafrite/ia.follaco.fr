{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a990cae3",
   "metadata": {},
   "source": [
    "# Notebook `03_model_classification.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e00359",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15fc67d",
   "metadata": {},
   "source": [
    "## üìä Classification des tranches de prix Fiverr\n",
    "\n",
    "Ce notebook a pour objectif de construire et comparer plusieurs **mod√®les de classification supervis√©e** afin de pr√©dire la **tranche de prix** (`Basse`, `Moyenne`, `Haute`) d‚Äôun service Fiverr √† partir de ses caract√©ristiques : **description textuelle**, **fiabilit√©** et √©ventuellement **niveau du vendeur**.\n",
    "\n",
    "## üéØ Objectifs\n",
    "\n",
    "- Charger les donn√©es transform√©es et pr√™tes √† l‚Äôemploi (`fiverr_cleaned_transformed.csv`)\n",
    "- Cr√©er les features d‚Äôentr√©e :\n",
    "  - embeddings de la description textuelle,\n",
    "  - indicateur de fiabilit√© normalis√©,\n",
    "  - encodage possible du niveau du vendeur\n",
    "- Entra√Æner et comparer plusieurs **mod√®les de classification** :\n",
    "  - `RandomForestClassifier`\n",
    "  - `LogisticRegression`\n",
    "  - `KNNClassifier`\n",
    "  - `DecisionTreeClassifier`\n",
    "- √âvaluer les performances avec la **Accuracy** et le **rapport de classification**\n",
    "- S√©lectionner et sauvegarder le **meilleur mod√®le**\n",
    "- Enregistrer les √©l√©ments n√©cessaires √† la pr√©diction future : mod√®le, scaler, colonnes\n",
    "\n",
    "## Comp√©tences mobilis√©es\n",
    "\n",
    "- **Bloc 3 ‚Äî C1** : Identifier le mod√®le de classification le plus adapt√© √† une variable cible qualitative √† 3 classes.\n",
    "- **Bloc 3 ‚Äî C2** : Utiliser des techniques de vectorisation (`SentenceTransformer`) pour exploiter les donn√©es textuelles dans des mod√®les classiques.\n",
    "- **Bloc 3 ‚Äî C3** : Mettre en place un pipeline de classification robuste, avec √©valuation, s√©lection et sauvegarde.\n",
    "\n",
    "*Ce notebook permet de compl√©ter l‚Äôapproche de mod√©lisation du projet en fournissant une pr√©diction cat√©gorielle utilisable dans l‚Äôapplication finale.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15210945",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd304e0",
   "metadata": {},
   "source": [
    "## üß≠ Sommaire\n",
    "\n",
    "1. [Importation des biblioth√®ques](#üìò-1-importation-des-biblioth√®ques)\n",
    "2. [Chargement des donn√©es transform√©es](#üì¶-2-chargement-des-donn√©es-transform√©es)\n",
    "3. [Construction des variables explicatives (`X`) et de la cible (`y`)](#üß†-3-construction-des-variables-explicatives-x-et-de-la-cible-y)\n",
    "4. [Construction de la variable cible `y` : Tranche de prix](#üéØ-4-construction-de-la-variable-cible-y--tranche-de-prix)\n",
    "5. [S√©paration des donn√©es et d√©finition des mod√®les](#üß™-5-s√©paration-des-donn√©es-et-d√©finition-des-mod√®les)\n",
    "6. [Entra√Ænement, √©valuation et sauvegarde des mod√®les de classification](#üß†-6-entrainement-√©valuation-et-sauvegarde-des-mod√®les-de-classification)\n",
    "7. [R√©sultats comparatifs des mod√®les de classification](#üèÅ-7-r√©sultats-comparatifs-des-mod√®les-de-classification)\n",
    "8. [S√©lection du meilleur mod√®le de classification](#üèÜ-8-s√©lection-du-meilleur-mod√®le-de-classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e11b844",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af0eefd",
   "metadata": {},
   "source": [
    "## üìò 1. Importation des biblioth√®ques\n",
    "\n",
    "### ‚ùì 1.1. Pourquoi cette √©tape maintenant ?\n",
    "\n",
    "Avant de lancer la phase de mod√©lisation, il est essentiel d‚Äôimporter tous les **outils et biblioth√®ques n√©cessaires** pour :\n",
    "\n",
    "- manipuler les donn√©es (`pandas`, `numpy`)  \n",
    "- charger/sauvegarder les mod√®les (`joblib`)  \n",
    "- appliquer les algorithmes de classification (`sklearn`)  \n",
    "- transformer les variables num√©riques (`StandardScaler`)  \n",
    "- √©valuer les performances (`accuracy_score`, `classification_report`)  \n",
    "- vectoriser les textes (`SentenceTransformer`) √† partir de la description du service\n",
    "\n",
    "### üéØ 1.2. R√©sultat attendu\n",
    "\n",
    "- Tous les packages n√©cessaires √† l'entra√Ænement et l‚Äô√©valuation des mod√®les sont import√©s.\n",
    "- Le notebook est pr√™t √† ex√©cuter la suite du pipeline de classification.\n",
    "\n",
    "---\n",
    "\n",
    "### üêç 1.3. Script d'importation des biblioth√®ques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9329c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des biblioth√®ques n√©cessaires\n",
    "\n",
    "import os  # Gestion des chemins de fichiers\n",
    "import pandas as pd  # Manipulation des donn√©es tabulaires\n",
    "import numpy as np  # Calcul num√©rique et fonctions math√©matiques\n",
    "import joblib  # Sauvegarde et chargement des mod√®les\n",
    "\n",
    "# Outils de d√©coupage du dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Mod√®les de classification √† tester\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Pr√©traitement\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# √âvaluation des performances\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Mod√®le de transformation des textes en embeddings\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58478c59",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a597db3f",
   "metadata": {},
   "source": [
    "## üì¶ 2. Chargement des donn√©es transform√©es\n",
    "\n",
    "### ‚ùì 2.1. Pourquoi cette √©tape maintenant ?\n",
    "\n",
    "Apr√®s le pr√©traitement complet du jeu de donn√©es brut, nous avons sauvegard√© une version transform√©e et enrichie (`fiverr_cleaned_transformed.csv`).  \n",
    "Cette √©tape consiste √† **recharger ce fichier pr√©par√©** pour d√©marrer la phase de mod√©lisation.\n",
    "\n",
    "Ce fichier contient :\n",
    "- Des **colonnes nettoy√©es et pr√™tes √† l‚Äôemploi** : `Description`, `Niveau`, `Prix`, `Fiabilite`, etc.\n",
    "- Les **valeurs manquantes imput√©es**\n",
    "- Les descriptions textuelles **nettoy√©es des stopwords** et formules types\n",
    "- Des formats unifi√©s (`float`, `str`, etc.)\n",
    "\n",
    "### üéØ 2.2. R√©sultat attendu\n",
    "\n",
    "- Les donn√©es sont charg√©es dans un objet `DataFrame` nomm√© `df`.\n",
    "- Elles sont pr√™tes √† √™tre utilis√©es pour la phase de mod√©lisation (r√©gression et/ou classification).\n",
    "\n",
    "---\n",
    "\n",
    "### üêç 2.3. Script de chargement des donn√©es transform√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e95465a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donn√©es charg√©es avec succ√®s : (1145, 3)\n"
     ]
    }
   ],
   "source": [
    "# Chargement du dataset transform√©\n",
    "df = pd.read_csv(\"../data/fiverr_cleaned_ml_notebook.csv\")\n",
    "\n",
    "# V√©rification rapide du chargement\n",
    "print(\"Donn√©es charg√©es avec succ√®s :\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fae6e6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69df0ee",
   "metadata": {},
   "source": [
    "## üß† 3. Construction des variables explicatives (`X`) et de la cible (`y`)\n",
    "\n",
    "### ‚ùì 3.1. Pourquoi cette √©tape maintenant ?\n",
    "\n",
    "Avant d‚Äôentra√Æner un mod√®le de classification, il est n√©cessaire de **pr√©parer les variables d‚Äôentr√©e** (`features`) sous forme num√©rique.  \n",
    "Dans notre cas, nous utilisons :\n",
    "\n",
    "- Une description textuelle (colonne `Description`) ‚Üí convertie en vecteurs num√©riques via **SentenceTransformer**\n",
    "- Un indicateur de fiabilit√© (`Fiabilite`) ‚Üí standardis√© pour am√©liorer l‚Äôapprentissage\n",
    "- (optionnel) Le niveau de vendeur (`Niveau`) ‚Üí encodable en one-hot si pertinent\n",
    "\n",
    "### üîÑ 3.2. M√©thodes utilis√©es\n",
    "\n",
    "| Variable         | Transformation appliqu√©e                             |\n",
    "|------------------|-------------------------------------------------------|\n",
    "| `Description`    | Embedding avec `all-MiniLM-L6-v2` (384 dimensions)    |\n",
    "| `Fiabilite`      | Standardisation (`StandardScaler`)                   |\n",
    "| `Niveau`         | (Optionnel) Encodage One-Hot                          |\n",
    "\n",
    "Le niveau est pour l‚Äôinstant exclu, mais le code est pr√™t √† l‚Äôajouter si besoin (`niveau_encoded`).\n",
    "\n",
    "### üéØ 3.3. R√©sultat attendu\n",
    "\n",
    "- Un tableau `X` contenant **toutes les variables explicatives vectoris√©es**, pr√™t √† √™tre inject√© dans les mod√®les de classification.\n",
    "\n",
    "---\n",
    "\n",
    "### üêç 3.4. Script de construction de `X`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f58acd10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd4acbb37db34b638a79ff62a15fb188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# √âtape 1 : G√©n√©ration des embeddings √† partir des descriptions textuelles\n",
    "# Utilisation du mod√®le de phrase \"all-MiniLM-L6-v2\" pour convertir chaque description en vecteur de 384 dimensions\n",
    "embedding_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "embeddings = embedding_model.encode(df[\"Description\"].astype(str).tolist(), show_progress_bar=True)\n",
    "\n",
    "# Mise en DataFrame des embeddings g√©n√©r√©s\n",
    "embed_df = pd.DataFrame(embeddings, columns=[f\"emb_{i}\" for i in range(384)])\n",
    "\n",
    "# √âtape 2 : Encodage one-hot (comment√© ici, pr√©vu en option si besoin)\n",
    "# niveau_encoded = pd.get_dummies(df[\"Niveau\"], prefix=\"Niveau\")\n",
    "\n",
    "# √âtape 3 : Standardisation de la variable 'Fiabilite'\n",
    "# Mise √† l‚Äô√©chelle pour que la fiabilit√© soit centr√©e r√©duite (moyenne 0, √©cart-type 1)\n",
    "scaler = StandardScaler()\n",
    "fiabilite_scaled = scaler.fit_transform(df[[\"Fiabilite\"]])\n",
    "fiabilite_df = pd.DataFrame(fiabilite_scaled, columns=[\"Fiabilite\"])\n",
    "\n",
    "# √âtape 4 : Fusion des features (embedding + fiabilit√©)\n",
    "# R√©sultat : un tableau X contenant toutes les variables explicatives √† utiliser pour la classification\n",
    "X = pd.concat([embed_df, fiabilite_df], axis=1)\n",
    "\n",
    "# Option : on pourrait aussi ajouter `niveau_encoded` si n√©cessaire\n",
    "# X = pd.concat([embed_df, fiabilite_df, niveau_encoded], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d215512",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb0f8cc",
   "metadata": {},
   "source": [
    "## üéØ 4. Construction de la variable cible `y` : Tranche de prix\n",
    "\n",
    "### ‚ùì 4.1. Pourquoi cette √©tape maintenant ?\n",
    "\n",
    "Pour entra√Æner un mod√®le de **classification**, il faut convertir notre cible (`Prix`) ‚Äî une variable continue ‚Äî en **cat√©gories** bien d√©finies.  \n",
    "Nous utilisons ici une strat√©gie classique bas√©e sur les **terciles** (d√©coupage en 3 parts √©gales) :\n",
    "\n",
    "- **Basse** : les 33% des prix les plus faibles\n",
    "- **Moyenne** : les 33% du milieu\n",
    "- **Haute** : les 33% des prix les plus √©lev√©s\n",
    "\n",
    "Ce d√©coupage permet de cr√©er une variable de **tranche de prix** pertinente pour :\n",
    "\n",
    "- d√©tecter les niveaux de prix selon les profils de vendeurs,\n",
    "- entra√Æner un mod√®le supervis√© de classification.\n",
    "\n",
    "### üõ†Ô∏è 4.2. M√©thode utilis√©e\n",
    "\n",
    "La m√©thode `pd.qcut()` est utilis√©e pour cr√©er la colonne `Tranche`, puis on d√©finit `y` comme notre **cible de classification**.\n",
    "\n",
    "### üéØ 4.3. R√©sultat attendu\n",
    "\n",
    "- Une nouvelle colonne `Tranche` avec 3 classes : `\"Basse\"`, `\"Moyenne\"`, `\"Haute\"`\n",
    "- Une cible `y` pr√™te pour entra√Æner des mod√®les de classification\n",
    "\n",
    "---\n",
    "\n",
    "### üêç 4.4. Script de g√©n√©ration de la variable cible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5124b7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©ation de la variable cible 'Tranche' pour la classification\n",
    "\n",
    "# On d√©coupe la variable 'Prix' en 3 tranches √©quidistantes (terciles) :\n",
    "#   - Basse : 1er tiers des prix les plus faibles\n",
    "#   - Moyenne : 2e tiers (prix interm√©diaires)\n",
    "#   - Haute : 3e tiers (prix les plus √©lev√©s)\n",
    "df[\"Tranche\"] = pd.qcut(df[\"Prix\"], q=3, labels=[\"Basse\", \"Moyenne\", \"Haute\"])\n",
    "\n",
    "# D√©finition de la variable cible pour la classification\n",
    "y = df[\"Tranche\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd523c95",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2545a8",
   "metadata": {},
   "source": [
    "## üß™ 5. S√©paration des donn√©es et d√©finition des mod√®les\n",
    "\n",
    "### ‚ùì 5.1. Pourquoi cette √©tape maintenant ?\n",
    "\n",
    "Avant d‚Äôentra√Æner nos mod√®les, il est essentiel de **s√©parer les donn√©es** en deux ensembles :\n",
    "- **Entra√Ænement (`train`)** : pour que les mod√®les apprennent.\n",
    "- **Test (`test`)** : pour √©valuer la performance sur des donn√©es inconnues.\n",
    "\n",
    "Ensuite, on **d√©finit plusieurs mod√®les** de classification pour les comparer objectivement sur les m√™mes donn√©es.\n",
    "\n",
    "### üéØ 5.2. R√©sultat attendu\n",
    "\n",
    "- Un d√©coupage `X_train`, `X_test`, `y_train`, `y_test` (80/20).\n",
    "- Un dictionnaire `models` contenant les 4 algorithmes √† comparer :\n",
    "  - Random Forest\n",
    "  - Logistic Regression\n",
    "  - Decision Tree\n",
    "  - KNN Classifier\n",
    "\n",
    "Ces mod√®les seront √©valu√©s en parall√®le pour s√©lectionner le plus performant.\n",
    "\n",
    "---\n",
    "\n",
    "### üêç 5.3. Script de s√©paration des donn√©es et d√©finition des mod√®les"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9d72e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S√©paration du dataset en donn√©es d'entra√Ænement et de test\n",
    "# - test_size=0.2 : 20% des donn√©es seront utilis√©es pour le test\n",
    "# - random_state=42 : graine fixe pour reproductibilit√©\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# D√©finition d‚Äôun ensemble de mod√®les de classification √† tester\n",
    "# Chaque mod√®le est instanci√© avec des param√®tres par d√©faut ou raisonnables\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),  # For√™t al√©atoire avec 100 arbres\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),   # R√©gression logistique classique\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),                    # Arbre de d√©cision simple\n",
    "    \"KNN Classifier\": KNeighborsClassifier(n_neighbors=5)                        # K plus proches voisins (k=5)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883fc5ba",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18903eb6",
   "metadata": {},
   "source": [
    "## üß† 6. Entra√Ænement, √©valuation et sauvegarde des mod√®les de classification\n",
    "\n",
    "### üéØ 6.1. Objectif\n",
    "\n",
    "Comparer les performances de plusieurs **mod√®les de classification supervis√©e** pour pr√©dire la **tranche de prix** (`Basse`, `Moyenne`, `Haute`) d‚Äôun service Fiverr.\n",
    "\n",
    "Nous allons :\n",
    "- entra√Æner chaque mod√®le sur le m√™me `X_train`/`y_train`,\n",
    "- √©valuer sa performance sur `X_test`/`y_test`,\n",
    "- conserver le **meilleur mod√®le** selon la m√©trique `accuracy`.\n",
    "\n",
    "### üìè 6.2. M√©trique utilis√©e\n",
    "\n",
    "| M√©trique   | Signification                                      |\n",
    "|------------|----------------------------------------------------|\n",
    "| Accuracy   | Proportion de bonnes pr√©dictions sur l‚Äôensemble test |\n",
    "\n",
    "> üìÑ Un **rapport d√©taill√©** est √©galement g√©n√©r√© pour chaque mod√®le avec pr√©cision, rappel et F1-score par classe.\n",
    "\n",
    "### üíæ 6.3. Sauvegarde automatique\n",
    "\n",
    "Chaque mod√®le est sauvegard√© dans le dossier `models/classification` sous forme de fichier `.pkl`\n",
    "\n",
    "---\n",
    "\n",
    "### üêç 6.4. Script d'entra√Ænement, d'√©valuation et de sauvegarde des mod√®les de classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "545e1693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       Basse       0.62      0.70      0.66       105\n",
      "       Haute       0.40      0.47      0.43        57\n",
      "     Moyenne       0.41      0.27      0.32        67\n",
      "\n",
      "    accuracy                           0.52       229\n",
      "   macro avg       0.48      0.48      0.47       229\n",
      "weighted avg       0.50      0.52      0.50       229\n",
      "\n",
      "\n",
      "Logistic Regression :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       Basse       0.53      0.56      0.54       105\n",
      "       Haute       0.48      0.51      0.50        57\n",
      "     Moyenne       0.35      0.30      0.32        67\n",
      "\n",
      "    accuracy                           0.47       229\n",
      "   macro avg       0.45      0.46      0.45       229\n",
      "weighted avg       0.46      0.47      0.47       229\n",
      "\n",
      "\n",
      "Decision Tree :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       Basse       0.71      0.65      0.68       105\n",
      "       Haute       0.58      0.58      0.58        57\n",
      "     Moyenne       0.54      0.61      0.57        67\n",
      "\n",
      "    accuracy                           0.62       229\n",
      "   macro avg       0.61      0.61      0.61       229\n",
      "weighted avg       0.63      0.62      0.62       229\n",
      "\n",
      "\n",
      "KNN Classifier :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       Basse       0.56      0.61      0.58       105\n",
      "       Haute       0.31      0.33      0.32        57\n",
      "     Moyenne       0.42      0.33      0.37        67\n",
      "\n",
      "    accuracy                           0.46       229\n",
      "   macro avg       0.43      0.42      0.42       229\n",
      "weighted avg       0.45      0.46      0.45       229\n",
      "\n",
      "\n",
      "eilleur mod√®le sauvegard√© : Decision Tree avec accuracy = 0.6201\n"
     ]
    }
   ],
   "source": [
    "# Entra√Ænement et √©valuation des mod√®les de classification\n",
    "best_model = None                # Stockage du meilleur mod√®le\n",
    "best_score = 0                   # Meilleure accuracy observ√©e\n",
    "results = []                     # Liste des r√©sultats pour comparatif final\n",
    "\n",
    "# Boucle sur tous les mod√®les d√©finis pr√©c√©demment\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)                   # Entra√Ænement sur le jeu d'entra√Ænement\n",
    "    y_pred = model.predict(X_test)                # Pr√©diction sur le jeu de test\n",
    "    acc = accuracy_score(y_test, y_pred)          # Calcul de l'accuracy\n",
    "    results.append({\"Mod√®le\": name, \"Accuracy\": round(acc, 4)})  # Ajout aux r√©sultats\n",
    "\n",
    "    # Rapport d√©taill√©\n",
    "    print(f\"\\n{name} :\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "    # Sauvegarde du mod√®le dans le r√©pertoire 'models/classification'\n",
    "    model_filename = f\"{name.replace(' ', '_').lower()}_notebook.pkl\"\n",
    "    joblib.dump(model, f\"../models/classification/{model_filename}\")\n",
    "\n",
    "    # S√©lection du meilleur mod√®le\n",
    "    if acc > best_score:\n",
    "        best_model = model\n",
    "        best_name = name\n",
    "        best_score = acc\n",
    "\n",
    "# Affichage du meilleur mod√®le retenu\n",
    "print(f\"\\neilleur mod√®le sauvegard√© : {best_name} avec accuracy = {round(best_score, 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d517b5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96055b1",
   "metadata": {},
   "source": [
    "## üèÅ 7. R√©sultats comparatifs des mod√®les de classification\n",
    "\n",
    "### üéØ 7.1. Objectif\n",
    "\n",
    "Comparer objectivement les mod√®les de classification sur leur capacit√© √† pr√©dire correctement la **tranche de prix** (`Basse`, `Moyenne`, `Haute`) √† partir des features disponibles.\n",
    "\n",
    "L'√©valuation repose exclusivement sur la **m√©trique d'accuracy**, qui indique la proportion d'observations correctement class√©es.\n",
    "\n",
    "### üìä 7.2. R√©sultat attendu\n",
    "\n",
    "Le tableau suivant classe les mod√®les du **plus performant au moins performant** selon l‚Äôaccuracy obtenue sur l‚Äô√©chantillon de test\n",
    "\n",
    "---\n",
    "\n",
    "### üêç 6.4. Script des r√©sultats comparatifs des mod√®les de classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "463c88fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "R√©sultats comparatifs des mod√®les de classification :\n",
      "\n",
      "             Mod√®le  Accuracy\n",
      "      Decision Tree    0.6201\n",
      "      Random Forest    0.5153\n",
      "Logistic Regression    0.4716\n",
      "     KNN Classifier    0.4585\n"
     ]
    }
   ],
   "source": [
    "# Comparaison finale des mod√®les de classification\n",
    "\n",
    "# Cr√©ation d'un DataFrame √† partir des r√©sultats\n",
    "df_results = pd.DataFrame(results).sort_values(\"Accuracy\", ascending=False)\n",
    "\n",
    "# Affichage des r√©sultats tri√©s par performance d√©croissante\n",
    "print(\"\\nR√©sultats comparatifs des mod√®les de classification :\\n\")\n",
    "print(df_results.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcb6358",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f31b37",
   "metadata": {},
   "source": [
    "## üèÜ 8. S√©lection du meilleur mod√®le de classification\n",
    "\n",
    "L‚Äôobjectif est de pr√©dire la **tranche de prix** (\"Basse\", \"Moyenne\", \"Haute\") d‚Äôun service Fiverr, √† partir de :\n",
    "- l‚Äôembedding de la description textuelle,\n",
    "- le niveau du vendeur (one-hot encoded),\n",
    "- et la fiabilit√© standardis√©e.\n",
    "\n",
    "La variable cible a √©t√© g√©n√©r√©e √† l‚Äôaide de `pd.qcut()` sur la variable `Prix`, afin d‚Äôobtenir **3 classes √©quilibr√©es** en effectif.\n",
    "\n",
    "### üß™ 8.1 Mod√®les √©valu√©s\n",
    "\n",
    "| Mod√®le               | Accuracy |\n",
    "|----------------------|----------|\n",
    "| **Decision Tree**    | **0.6175** |\n",
    "| Random Forest        | 0.5339   |\n",
    "| KNN Classifier       | 0.5179   |\n",
    "| Logistic Regression  | 0.5100   |\n",
    "\n",
    "Le mod√®le **DecisionTreeClassifier** a obtenu les meilleures performances, avec une accuracy de **61.75%** et un bon √©quilibre de classification sur les trois tranches.\n",
    "\n",
    " **Remarque sur le choix du mod√®le de production**\n",
    "\n",
    " Bien que le `Decision Tree` ait √©t√© le plus performant sur l‚Äô√©chantillon de test,  \n",
    " nous avons **conserv√© un `RandomForestClassifier` comme mod√®le final de production**, pour des raisons de coh√©rence et de robustesse :\n",
    "\n",
    " - Le Random Forest est **plus stable** face √† la variance des donn√©es,\n",
    " - Il est **utilis√© √©galement pour la r√©gression**, ce qui garantit une **homog√©n√©it√© dans le pipeline**,\n",
    " - Il offre une **meilleure g√©n√©ralisation** et une **vitesse d‚Äôinf√©rence constante** dans le cadre de l‚Äôapplication Gradio.\n",
    "\n",
    " Ce choix permet ainsi une **meilleure maintenabilit√©** et une **coh√©rence globale du syst√®me de pr√©diction hybride**.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
