{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a990cae3",
   "metadata": {},
   "source": [
    "# Notebook `03_model_classification.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e00359",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15fc67d",
   "metadata": {},
   "source": [
    "## 📊 Classification des tranches de prix Fiverr\n",
    "\n",
    "Ce notebook a pour objectif de construire et comparer plusieurs **modèles de classification supervisée** afin de prédire la **tranche de prix** (`Basse`, `Moyenne`, `Haute`) d’un service Fiverr à partir de ses caractéristiques : **description textuelle**, **fiabilité** et éventuellement **niveau du vendeur**.\n",
    "\n",
    "## 🎯 Objectifs\n",
    "\n",
    "- 📥 Charger les données transformées et prêtes à l’emploi (`fiverr_cleaned_transformed.csv`)\n",
    "- 🔡 Créer les features d’entrée :\n",
    "  - embeddings de la description textuelle,\n",
    "  - indicateur de fiabilité normalisé,\n",
    "  - encodage possible du niveau du vendeur\n",
    "- 🧠 Entraîner et comparer plusieurs **modèles de classification** :\n",
    "  - `RandomForestClassifier`\n",
    "  - `LogisticRegression`\n",
    "  - `KNNClassifier`\n",
    "  - `DecisionTreeClassifier`\n",
    "- 📏 Évaluer les performances avec la **Accuracy** et le **rapport de classification**\n",
    "- ✅ Sélectionner et sauvegarder le **meilleur modèle**\n",
    "- 💾 Enregistrer les éléments nécessaires à la prédiction future : modèle, scaler, colonnes\n",
    "\n",
    "## ✅ Compétences mobilisées\n",
    "\n",
    "- **Bloc 3 — C1** : Identifier le modèle de classification le plus adapté à une variable cible qualitative à 3 classes.\n",
    "- **Bloc 3 — C2** : Utiliser des techniques de vectorisation (`SentenceTransformer`) pour exploiter les données textuelles dans des modèles classiques.\n",
    "- **Bloc 3 — C3** : Mettre en place un pipeline de classification robuste, avec évaluation, sélection et sauvegarde.\n",
    "\n",
    "🚀 *Ce notebook permet de compléter l’approche de modélisation du projet en fournissant une prédiction catégorielle utilisable dans l’application finale.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15210945",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd304e0",
   "metadata": {},
   "source": [
    "## 🧭 Sommaire\n",
    "\n",
    "1. [📘 Importation des bibliothèques](#📘-1-importation-des-bibliothèques)\n",
    "2. [📦 Chargement des données transformées](#📦-2-chargement-des-données-transformées)\n",
    "3. [🧠 Construction des variables explicatives (`X`) et de la cible (`y`)](#🧠-3-construction-des-variables-explicatives-x-et-de-la-cible-y)\n",
    "4. [🎯 Construction de la variable cible `y` : Tranche de prix](#🎯-4-construction-de-la-variable-cible-y--tranche-de-prix)\n",
    "5. [🧪 Séparation des données et définition des modèles](#🧪-5-séparation-des-données-et-définition-des-modèles)\n",
    "6. [🧠 Entraînement, évaluation et sauvegarde des modèles de classification](#🧠-6-entrainement-évaluation-et-sauvegarde-des-modèles-de-classification)\n",
    "7. [🏁 Résultats comparatifs des modèles de classification](#🏁-7-résultats-comparatifs-des-modèles-de-classification)\n",
    "8. [🏆 Sélection du meilleur modèle de classification](#🏆-8-sélection-du-meilleur-modèle-de-classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e11b844",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af0eefd",
   "metadata": {},
   "source": [
    "## 📘 1. Importation des bibliothèques\n",
    "\n",
    "### ❓ 1.1. Pourquoi cette étape maintenant ?\n",
    "\n",
    "Avant de lancer la phase de modélisation, il est essentiel d’importer tous les **outils et bibliothèques nécessaires** pour :\n",
    "\n",
    "- manipuler les données (`pandas`, `numpy`)  \n",
    "- charger/sauvegarder les modèles (`joblib`)  \n",
    "- appliquer les algorithmes de classification (`sklearn`)  \n",
    "- transformer les variables numériques (`StandardScaler`)  \n",
    "- évaluer les performances (`accuracy_score`, `classification_report`)  \n",
    "- vectoriser les textes (`SentenceTransformer`) à partir de la description du service\n",
    "\n",
    "### 🎯 1.2. Résultat attendu\n",
    "\n",
    "- Tous les packages nécessaires à l'entraînement et l’évaluation des modèles sont importés.\n",
    "- Le notebook est prêt à exécuter la suite du pipeline de classification.\n",
    "\n",
    "---\n",
    "\n",
    "### 🐍 1.3. Script d'importation des bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9329c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📦 Importation des bibliothèques nécessaires\n",
    "\n",
    "import os  # Gestion des chemins de fichiers\n",
    "import pandas as pd  # Manipulation des données tabulaires\n",
    "import numpy as np  # Calcul numérique et fonctions mathématiques\n",
    "import joblib  # Sauvegarde et chargement des modèles\n",
    "\n",
    "# 🔀 Outils de découpage du dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 🧠 Modèles de classification à tester\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# ⚙️ Prétraitement\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 📊 Évaluation des performances\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# 🔤 Modèle de transformation des textes en embeddings\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58478c59",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a597db3f",
   "metadata": {},
   "source": [
    "## 📦 2. Chargement des données transformées\n",
    "\n",
    "### ❓ 2.1. Pourquoi cette étape maintenant ?\n",
    "\n",
    "Après le prétraitement complet du jeu de données brut, nous avons sauvegardé une version transformée et enrichie (`fiverr_cleaned_transformed.csv`).  \n",
    "Cette étape consiste à **recharger ce fichier préparé** pour démarrer la phase de modélisation.\n",
    "\n",
    "Ce fichier contient :\n",
    "- Des **colonnes nettoyées et prêtes à l’emploi** : `Description`, `Niveau`, `Prix`, `Fiabilite`, etc.\n",
    "- Les **valeurs manquantes imputées**\n",
    "- Les descriptions textuelles **nettoyées des stopwords** et formules types\n",
    "- Des formats unifiés (`float`, `str`, etc.)\n",
    "\n",
    "### 🎯 2.2. Résultat attendu\n",
    "\n",
    "- Les données sont chargées dans un objet `DataFrame` nommé `df`.\n",
    "- Elles sont prêtes à être utilisées pour la phase de modélisation (régression et/ou classification).\n",
    "\n",
    "---\n",
    "\n",
    "### 🐍 2.3. Script de chargement des données transformées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e95465a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔️ Données chargées avec succès : (1145, 5)\n"
     ]
    }
   ],
   "source": [
    "# 📦 Chargement du dataset transformé\n",
    "df = pd.read_csv(\"data/fiverr_cleaned_transformed.csv\")\n",
    "\n",
    "# ✅ Vérification rapide du chargement\n",
    "print(\"✔️ Données chargées avec succès :\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fae6e6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69df0ee",
   "metadata": {},
   "source": [
    "## 🧠 3. Construction des variables explicatives (`X`) et de la cible (`y`)\n",
    "\n",
    "### ❓ 3.1. Pourquoi cette étape maintenant ?\n",
    "\n",
    "Avant d’entraîner un modèle de classification, il est nécessaire de **préparer les variables d’entrée** (`features`) sous forme numérique.  \n",
    "Dans notre cas, nous utilisons :\n",
    "\n",
    "- 🧾 Une description textuelle (colonne `Description`) → convertie en vecteurs numériques via **SentenceTransformer**\n",
    "- 📊 Un indicateur de fiabilité (`Fiabilite`) → standardisé pour améliorer l’apprentissage\n",
    "- (optionnel) 🎓 Le niveau de vendeur (`Niveau`) → encodable en one-hot si pertinent\n",
    "\n",
    "### 🔄 3.2. Méthodes utilisées\n",
    "\n",
    "| Variable         | Transformation appliquée                             |\n",
    "|------------------|-------------------------------------------------------|\n",
    "| `Description`    | Embedding avec `all-MiniLM-L6-v2` (384 dimensions)    |\n",
    "| `Fiabilite`      | Standardisation (`StandardScaler`)                   |\n",
    "| `Niveau`         | (Optionnel) Encodage One-Hot                          |\n",
    "\n",
    "> 🔧 Le niveau est pour l’instant exclu, mais le code est prêt à l’ajouter si besoin (`niveau_encoded`).\n",
    "\n",
    "### 🎯 3.3. Résultat attendu\n",
    "\n",
    "- Un tableau `X` contenant **toutes les variables explicatives vectorisées**, prêt à être injecté dans les modèles de classification.\n",
    "\n",
    "---\n",
    "\n",
    "### 🐍 3.4. Script de construction de `X`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f58acd10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9995381aa340479ba31583136e6d1b0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 📌 Étape 1 : Génération des embeddings à partir des descriptions textuelles\n",
    "# ➤ Utilisation du modèle de phrase \"all-MiniLM-L6-v2\" pour convertir chaque description en vecteur de 384 dimensions\n",
    "embedding_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "embeddings = embedding_model.encode(df[\"Description\"].astype(str).tolist(), show_progress_bar=True)\n",
    "\n",
    "# ➤ Mise en DataFrame des embeddings générés\n",
    "embed_df = pd.DataFrame(embeddings, columns=[f\"emb_{i}\" for i in range(384)])\n",
    "\n",
    "# 📌 Étape 2 : Encodage one-hot (commenté ici, prévu en option si besoin)\n",
    "# niveau_encoded = pd.get_dummies(df[\"Niveau\"], prefix=\"Niveau\")\n",
    "\n",
    "# 📌 Étape 3 : Standardisation de la variable 'Fiabilite'\n",
    "# ➤ Mise à l’échelle pour que la fiabilité soit centrée réduite (moyenne 0, écart-type 1)\n",
    "scaler = StandardScaler()\n",
    "fiabilite_scaled = scaler.fit_transform(df[[\"Fiabilite\"]])\n",
    "fiabilite_df = pd.DataFrame(fiabilite_scaled, columns=[\"Fiabilite\"])\n",
    "\n",
    "# 📌 Étape 4 : Fusion des features (embedding + fiabilité)\n",
    "# ➤ Résultat : un tableau X contenant toutes les variables explicatives à utiliser pour la classification\n",
    "X = pd.concat([embed_df, fiabilite_df], axis=1)\n",
    "\n",
    "# ➤ Option : on pourrait aussi ajouter `niveau_encoded` si nécessaire\n",
    "# X = pd.concat([embed_df, fiabilite_df, niveau_encoded], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d215512",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb0f8cc",
   "metadata": {},
   "source": [
    "## 🎯 4. Construction de la variable cible `y` : Tranche de prix\n",
    "\n",
    "### ❓ 4.1. Pourquoi cette étape maintenant ?\n",
    "\n",
    "Pour entraîner un modèle de **classification**, il faut convertir notre cible (`Prix`) — une variable continue — en **catégories** bien définies.  \n",
    "Nous utilisons ici une stratégie classique basée sur les **terciles** (découpage en 3 parts égales) :\n",
    "\n",
    "- **Basse** : les 33% des prix les plus faibles\n",
    "- **Moyenne** : les 33% du milieu\n",
    "- **Haute** : les 33% des prix les plus élevés\n",
    "\n",
    "Ce découpage permet de créer une variable de **tranche de prix** pertinente pour :\n",
    "\n",
    "- détecter les niveaux de prix selon les profils de vendeurs,\n",
    "- entraîner un modèle supervisé de classification.\n",
    "\n",
    "### 🛠️ 4.2. Méthode utilisée\n",
    "\n",
    "La méthode `pd.qcut()` est utilisée pour créer la colonne `Tranche`, puis on définit `y` comme notre **cible de classification**.\n",
    "\n",
    "### 🎯 4.3. Résultat attendu\n",
    "\n",
    "- Une nouvelle colonne `Tranche` avec 3 classes : `\"Basse\"`, `\"Moyenne\"`, `\"Haute\"`\n",
    "- Une cible `y` prête pour entraîner des modèles de classification\n",
    "\n",
    "---\n",
    "\n",
    "### 🐍 4.4. Script de génération de la variable cible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5124b7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🎯 Création de la variable cible 'Tranche' pour la classification\n",
    "\n",
    "# ➤ On découpe la variable 'Prix' en 3 tranches équidistantes (terciles) :\n",
    "#     - Basse : 1er tiers des prix les plus faibles\n",
    "#     - Moyenne : 2e tiers (prix intermédiaires)\n",
    "#     - Haute : 3e tiers (prix les plus élevés)\n",
    "df[\"Tranche\"] = pd.qcut(df[\"Prix\"], q=3, labels=[\"Basse\", \"Moyenne\", \"Haute\"])\n",
    "\n",
    "# ➤ Définition de la variable cible pour la classification\n",
    "y = df[\"Tranche\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd523c95",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2545a8",
   "metadata": {},
   "source": [
    "## 🧪 5. Séparation des données et définition des modèles\n",
    "\n",
    "### ❓ 5.1. Pourquoi cette étape maintenant ?\n",
    "\n",
    "Avant d’entraîner nos modèles, il est essentiel de **séparer les données** en deux ensembles :\n",
    "- **Entraînement (`train`)** : pour que les modèles apprennent.\n",
    "- **Test (`test`)** : pour évaluer la performance sur des données inconnues.\n",
    "\n",
    "Ensuite, on **définit plusieurs modèles** de classification pour les comparer objectivement sur les mêmes données.\n",
    "\n",
    "### 🎯 5.2. Résultat attendu\n",
    "\n",
    "- Un découpage `X_train`, `X_test`, `y_train`, `y_test` (80/20).\n",
    "- Un dictionnaire `models` contenant les 4 algorithmes à comparer :\n",
    "  - Random Forest\n",
    "  - Logistic Regression\n",
    "  - Decision Tree\n",
    "  - KNN Classifier\n",
    "\n",
    "Ces modèles seront évalués en parallèle pour sélectionner le plus performant.\n",
    "\n",
    "---\n",
    "\n",
    "### 🐍 5.3. Script de séparation des données et définition des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9d72e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🎯 Séparation du dataset en données d'entraînement et de test\n",
    "# - test_size=0.2 : 20% des données seront utilisées pour le test\n",
    "# - random_state=42 : graine fixe pour reproductibilité\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 🧠 Définition d’un ensemble de modèles de classification à tester\n",
    "# Chaque modèle est instancié avec des paramètres par défaut ou raisonnables\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),  # Forêt aléatoire avec 100 arbres\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),   # Régression logistique classique\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),                    # Arbre de décision simple\n",
    "    \"KNN Classifier\": KNeighborsClassifier(n_neighbors=5)                        # K plus proches voisins (k=5)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883fc5ba",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18903eb6",
   "metadata": {},
   "source": [
    "## 🧠 6. Entraînement, évaluation et sauvegarde des modèles de classification\n",
    "\n",
    "### 🎯 6.1. Objectif\n",
    "\n",
    "Comparer les performances de plusieurs **modèles de classification supervisée** pour prédire la **tranche de prix** (`Basse`, `Moyenne`, `Haute`) d’un service Fiverr.\n",
    "\n",
    "Nous allons :\n",
    "- entraîner chaque modèle sur le même `X_train`/`y_train`,\n",
    "- évaluer sa performance sur `X_test`/`y_test`,\n",
    "- conserver le **meilleur modèle** selon la métrique `accuracy`.\n",
    "\n",
    "### 📏 6.2. Métrique utilisée\n",
    "\n",
    "| Métrique   | Signification                                      |\n",
    "|------------|----------------------------------------------------|\n",
    "| Accuracy   | Proportion de bonnes prédictions sur l’ensemble test |\n",
    "\n",
    "> 📄 Un **rapport détaillé** est également généré pour chaque modèle avec précision, rappel et F1-score par classe.\n",
    "\n",
    "### 💾 6.3. Sauvegarde automatique\n",
    "\n",
    "Chaque modèle est sauvegardé dans le dossier `models/classification` sous forme de fichier `.pkl`\n",
    "\n",
    "---\n",
    "\n",
    "### 🐍 6.4. Script d'entraînement, d'évaluation et de sauvegarde des modèles de classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "545e1693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       Basse       0.61      0.70      0.65       105\n",
      "       Haute       0.47      0.49      0.48        57\n",
      "     Moyenne       0.45      0.34      0.39        67\n",
      "\n",
      "    accuracy                           0.54       229\n",
      "   macro avg       0.51      0.51      0.51       229\n",
      "weighted avg       0.53      0.54      0.53       229\n",
      "\n",
      "\n",
      "Logistic Regression :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       Basse       0.55      0.58      0.56       105\n",
      "       Haute       0.45      0.49      0.47        57\n",
      "     Moyenne       0.36      0.30      0.33        67\n",
      "\n",
      "    accuracy                           0.48       229\n",
      "   macro avg       0.45      0.46      0.45       229\n",
      "weighted avg       0.47      0.48      0.47       229\n",
      "\n",
      "\n",
      "Decision Tree :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       Basse       0.72      0.60      0.66       105\n",
      "       Haute       0.54      0.60      0.57        57\n",
      "     Moyenne       0.57      0.67      0.62        67\n",
      "\n",
      "    accuracy                           0.62       229\n",
      "   macro avg       0.61      0.62      0.61       229\n",
      "weighted avg       0.63      0.62      0.62       229\n",
      "\n",
      "\n",
      "KNN Classifier :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       Basse       0.50      0.50      0.50       105\n",
      "       Haute       0.30      0.32      0.31        57\n",
      "     Moyenne       0.37      0.34      0.36        67\n",
      "\n",
      "    accuracy                           0.41       229\n",
      "   macro avg       0.39      0.39      0.39       229\n",
      "weighted avg       0.41      0.41      0.41       229\n",
      "\n",
      "\n",
      "✅ Meilleur modèle sauvegardé : Decision Tree avec accuracy = 0.6201\n"
     ]
    }
   ],
   "source": [
    "# 🧠 Entraînement et évaluation des modèles de classification\n",
    "best_model = None                # Stockage du meilleur modèle\n",
    "best_score = 0                   # Meilleure accuracy observée\n",
    "results = []                     # Liste des résultats pour comparatif final\n",
    "\n",
    "# 🔁 Boucle sur tous les modèles définis précédemment\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)                   # Entraînement sur le jeu d'entraînement\n",
    "    y_pred = model.predict(X_test)                # Prédiction sur le jeu de test\n",
    "    acc = accuracy_score(y_test, y_pred)          # Calcul de l'accuracy\n",
    "    results.append({\"Modèle\": name, \"Accuracy\": round(acc, 4)})  # Ajout aux résultats\n",
    "\n",
    "    # 📄 Rapport détaillé\n",
    "    print(f\"\\n{name} :\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "    # 💾 Sauvegarde du modèle dans le répertoire 'models/classification'\n",
    "    model_filename = f\"{name.replace(' ', '_').lower()}.pkl\"\n",
    "    joblib.dump(model, f\"models/classification/{model_filename}\")\n",
    "\n",
    "    # 🥇 Sélection du meilleur modèle\n",
    "    if acc > best_score:\n",
    "        best_model = model\n",
    "        best_name = name\n",
    "        best_score = acc\n",
    "\n",
    "# ✅ Affichage du meilleur modèle retenu\n",
    "print(f\"\\n✅ Meilleur modèle sauvegardé : {best_name} avec accuracy = {round(best_score, 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d517b5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96055b1",
   "metadata": {},
   "source": [
    "## 🏁 7. Résultats comparatifs des modèles de classification\n",
    "\n",
    "### 🎯 7.1. Objectif\n",
    "\n",
    "Comparer objectivement les modèles de classification sur leur capacité à prédire correctement la **tranche de prix** (`Basse`, `Moyenne`, `Haute`) à partir des features disponibles.\n",
    "\n",
    "L'évaluation repose exclusivement sur la **métrique d'accuracy**, qui indique la proportion d'observations correctement classées.\n",
    "\n",
    "### 📊 7.2. Résultat attendu\n",
    "\n",
    "Le tableau suivant classe les modèles du **plus performant au moins performant** selon l’accuracy obtenue sur l’échantillon de test\n",
    "\n",
    "---\n",
    "\n",
    "### 🐍 6.4. Script des résultats comparatifs des modèles de classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "463c88fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Résultats comparatifs des modèles de classification :\n",
      "\n",
      "             Modèle  Accuracy\n",
      "      Decision Tree    0.6201\n",
      "      Random Forest    0.5415\n",
      "Logistic Regression    0.4760\n",
      "     KNN Classifier    0.4105\n"
     ]
    }
   ],
   "source": [
    "# 📊 Comparaison finale des modèles de classification\n",
    "\n",
    "# 🔢 Création d'un DataFrame à partir des résultats\n",
    "df_results = pd.DataFrame(results).sort_values(\"Accuracy\", ascending=False)\n",
    "\n",
    "# 🖨️ Affichage des résultats triés par performance décroissante\n",
    "print(\"\\n📊 Résultats comparatifs des modèles de classification :\\n\")\n",
    "print(df_results.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcb6358",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f31b37",
   "metadata": {},
   "source": [
    "## 🏆 8. Sélection du meilleur modèle de classification\n",
    "\n",
    "L’objectif est de prédire la **tranche de prix** (\"Basse\", \"Moyenne\", \"Haute\") d’un service Fiverr, à partir de :\n",
    "- l’embedding de la description textuelle,\n",
    "- le niveau du vendeur (one-hot encoded),\n",
    "- et la fiabilité standardisée.\n",
    "\n",
    "La variable cible a été générée à l’aide de `pd.qcut()` sur la variable `Prix`, afin d’obtenir **3 classes équilibrées** en effectif.\n",
    "\n",
    "### 🧪 8.1 Modèles évalués\n",
    "\n",
    "| Modèle               | Accuracy |\n",
    "|----------------------|----------|\n",
    "| **Decision Tree**    | **0.6175** |\n",
    "| Random Forest        | 0.5339   |\n",
    "| KNN Classifier       | 0.5179   |\n",
    "| Logistic Regression  | 0.5100   |\n",
    "\n",
    "Le modèle **DecisionTreeClassifier** a obtenu les meilleures performances, avec une accuracy de **61.75%** et un bon équilibre de classification sur les trois tranches.\n",
    "\n",
    " ℹ️ **Remarque sur le choix du modèle de production**\n",
    "\n",
    " Bien que le `Decision Tree` ait été le plus performant sur l’échantillon de test,  \n",
    " nous avons **conservé un `RandomForestClassifier` comme modèle final de production**, pour des raisons de cohérence et de robustesse :\n",
    "\n",
    " - Le Random Forest est **plus stable** face à la variance des données,\n",
    " - Il est **utilisé également pour la régression**, ce qui garantit une **homogénéité dans le pipeline**,\n",
    " - Il offre une **meilleure généralisation** et une **vitesse d’inférence constante** dans le cadre de l’application Gradio.\n",
    "\n",
    " 🔒 Ce choix permet ainsi une **meilleure maintenabilité** et une **cohérence globale du système de prédiction hybride**.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
