{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a990cae3",
   "metadata": {},
   "source": [
    "# Notebook `03_model_classification.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e00359",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15fc67d",
   "metadata": {},
   "source": [
    "## ğŸ“Š Classification des tranches de prix Fiverr\n",
    "\n",
    "Ce notebook a pour objectif de construire et comparer plusieurs **modÃ¨les de classification supervisÃ©e** afin de prÃ©dire la **tranche de prix** (`Basse`, `Moyenne`, `Haute`) dâ€™un service Fiverr Ã  partir de ses caractÃ©ristiques : **description textuelle**, **fiabilitÃ©** et Ã©ventuellement **niveau du vendeur**.\n",
    "\n",
    "## ğŸ¯ Objectifs\n",
    "\n",
    "- ğŸ“¥ Charger les donnÃ©es transformÃ©es et prÃªtes Ã  lâ€™emploi (`fiverr_cleaned_transformed.csv`)\n",
    "- ğŸ”¡ CrÃ©er les features dâ€™entrÃ©e :\n",
    "  - embeddings de la description textuelle,\n",
    "  - indicateur de fiabilitÃ© normalisÃ©,\n",
    "  - encodage possible du niveau du vendeur\n",
    "- ğŸ§  EntraÃ®ner et comparer plusieurs **modÃ¨les de classification** :\n",
    "  - `RandomForestClassifier`\n",
    "  - `LogisticRegression`\n",
    "  - `KNNClassifier`\n",
    "  - `DecisionTreeClassifier`\n",
    "- ğŸ“ Ã‰valuer les performances avec la **Accuracy** et le **rapport de classification**\n",
    "- âœ… SÃ©lectionner et sauvegarder le **meilleur modÃ¨le**\n",
    "- ğŸ’¾ Enregistrer les Ã©lÃ©ments nÃ©cessaires Ã  la prÃ©diction future : modÃ¨le, scaler, colonnes\n",
    "\n",
    "## âœ… CompÃ©tences mobilisÃ©es\n",
    "\n",
    "- **Bloc 3 â€” C1** : Identifier le modÃ¨le de classification le plus adaptÃ© Ã  une variable cible qualitative Ã  3 classes.\n",
    "- **Bloc 3 â€” C2** : Utiliser des techniques de vectorisation (`SentenceTransformer`) pour exploiter les donnÃ©es textuelles dans des modÃ¨les classiques.\n",
    "- **Bloc 3 â€” C3** : Mettre en place un pipeline de classification robuste, avec Ã©valuation, sÃ©lection et sauvegarde.\n",
    "\n",
    "ğŸš€ *Ce notebook permet de complÃ©ter lâ€™approche de modÃ©lisation du projet en fournissant une prÃ©diction catÃ©gorielle utilisable dans lâ€™application finale.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15210945",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd304e0",
   "metadata": {},
   "source": [
    "## ğŸ§­ Sommaire\n",
    "\n",
    "1. [ğŸ“˜ Importation des bibliothÃ¨ques](#ğŸ“˜-1-importation-des-bibliothÃ¨ques)\n",
    "2. [ğŸ“¦ Chargement des donnÃ©es transformÃ©es](#ğŸ“¦-2-chargement-des-donnÃ©es-transformÃ©es)\n",
    "3. [ğŸ§  Construction des variables explicatives (`X`) et de la cible (`y`)](#ğŸ§ -3-construction-des-variables-explicatives-x-et-de-la-cible-y)\n",
    "4. [ğŸ¯ Construction de la variable cible `y` : Tranche de prix](#ğŸ¯-4-construction-de-la-variable-cible-y--tranche-de-prix)\n",
    "5. [ğŸ§ª SÃ©paration des donnÃ©es et dÃ©finition des modÃ¨les](#ğŸ§ª-5-sÃ©paration-des-donnÃ©es-et-dÃ©finition-des-modÃ¨les)\n",
    "6. [ğŸ§  EntraÃ®nement, Ã©valuation et sauvegarde des modÃ¨les de classification](#ğŸ§ -6-entrainement-Ã©valuation-et-sauvegarde-des-modÃ¨les-de-classification)\n",
    "7. [ğŸ RÃ©sultats comparatifs des modÃ¨les de classification](#ğŸ-7-rÃ©sultats-comparatifs-des-modÃ¨les-de-classification)\n",
    "8. [ğŸ† SÃ©lection du meilleur modÃ¨le de classification](#ğŸ†-8-sÃ©lection-du-meilleur-modÃ¨le-de-classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e11b844",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af0eefd",
   "metadata": {},
   "source": [
    "## ğŸ“˜ 1. Importation des bibliothÃ¨ques\n",
    "\n",
    "### â“ 1.1. Pourquoi cette Ã©tape maintenant ?\n",
    "\n",
    "Avant de lancer la phase de modÃ©lisation, il est essentiel dâ€™importer tous les **outils et bibliothÃ¨ques nÃ©cessaires** pour :\n",
    "\n",
    "- manipuler les donnÃ©es (`pandas`, `numpy`)  \n",
    "- charger/sauvegarder les modÃ¨les (`joblib`)  \n",
    "- appliquer les algorithmes de classification (`sklearn`)  \n",
    "- transformer les variables numÃ©riques (`StandardScaler`)  \n",
    "- Ã©valuer les performances (`accuracy_score`, `classification_report`)  \n",
    "- vectoriser les textes (`SentenceTransformer`) Ã  partir de la description du service\n",
    "\n",
    "### ğŸ¯ 1.2. RÃ©sultat attendu\n",
    "\n",
    "- Tous les packages nÃ©cessaires Ã  l'entraÃ®nement et lâ€™Ã©valuation des modÃ¨les sont importÃ©s.\n",
    "- Le notebook est prÃªt Ã  exÃ©cuter la suite du pipeline de classification.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ 1.3. Script d'importation des bibliothÃ¨ques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9329c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“¦ Importation des bibliothÃ¨ques nÃ©cessaires\n",
    "\n",
    "import os  # Gestion des chemins de fichiers\n",
    "import pandas as pd  # Manipulation des donnÃ©es tabulaires\n",
    "import numpy as np  # Calcul numÃ©rique et fonctions mathÃ©matiques\n",
    "import joblib  # Sauvegarde et chargement des modÃ¨les\n",
    "\n",
    "# ğŸ”€ Outils de dÃ©coupage du dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ğŸ§  ModÃ¨les de classification Ã  tester\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# âš™ï¸ PrÃ©traitement\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ğŸ“Š Ã‰valuation des performances\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# ğŸ”¤ ModÃ¨le de transformation des textes en embeddings\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58478c59",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a597db3f",
   "metadata": {},
   "source": [
    "## ğŸ“¦ 2. Chargement des donnÃ©es transformÃ©es\n",
    "\n",
    "### â“ 2.1. Pourquoi cette Ã©tape maintenant ?\n",
    "\n",
    "AprÃ¨s le prÃ©traitement complet du jeu de donnÃ©es brut, nous avons sauvegardÃ© une version transformÃ©e et enrichie (`fiverr_cleaned_transformed.csv`).  \n",
    "Cette Ã©tape consiste Ã  **recharger ce fichier prÃ©parÃ©** pour dÃ©marrer la phase de modÃ©lisation.\n",
    "\n",
    "Ce fichier contient :\n",
    "- Des **colonnes nettoyÃ©es et prÃªtes Ã  lâ€™emploi** : `Description`, `Niveau`, `Prix`, `Fiabilite`, etc.\n",
    "- Les **valeurs manquantes imputÃ©es**\n",
    "- Les descriptions textuelles **nettoyÃ©es des stopwords** et formules types\n",
    "- Des formats unifiÃ©s (`float`, `str`, etc.)\n",
    "\n",
    "### ğŸ¯ 2.2. RÃ©sultat attendu\n",
    "\n",
    "- Les donnÃ©es sont chargÃ©es dans un objet `DataFrame` nommÃ© `df`.\n",
    "- Elles sont prÃªtes Ã  Ãªtre utilisÃ©es pour la phase de modÃ©lisation (rÃ©gression et/ou classification).\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ 2.3. Script de chargement des donnÃ©es transformÃ©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e95465a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ”ï¸ DonnÃ©es chargÃ©es avec succÃ¨s : (1145, 5)\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“¦ Chargement du dataset transformÃ©\n",
    "df = pd.read_csv(\"data/fiverr_cleaned_transformed.csv\")\n",
    "\n",
    "# âœ… VÃ©rification rapide du chargement\n",
    "print(\"âœ”ï¸ DonnÃ©es chargÃ©es avec succÃ¨s :\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fae6e6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69df0ee",
   "metadata": {},
   "source": [
    "## ğŸ§  3. Construction des variables explicatives (`X`) et de la cible (`y`)\n",
    "\n",
    "### â“ 3.1. Pourquoi cette Ã©tape maintenant ?\n",
    "\n",
    "Avant dâ€™entraÃ®ner un modÃ¨le de classification, il est nÃ©cessaire de **prÃ©parer les variables dâ€™entrÃ©e** (`features`) sous forme numÃ©rique.  \n",
    "Dans notre cas, nous utilisons :\n",
    "\n",
    "- ğŸ§¾ Une description textuelle (colonne `Description`) â†’ convertie en vecteurs numÃ©riques via **SentenceTransformer**\n",
    "- ğŸ“Š Un indicateur de fiabilitÃ© (`Fiabilite`) â†’ standardisÃ© pour amÃ©liorer lâ€™apprentissage\n",
    "- (optionnel) ğŸ“ Le niveau de vendeur (`Niveau`) â†’ encodable en one-hot si pertinent\n",
    "\n",
    "### ğŸ”„ 3.2. MÃ©thodes utilisÃ©es\n",
    "\n",
    "| Variable         | Transformation appliquÃ©e                             |\n",
    "|------------------|-------------------------------------------------------|\n",
    "| `Description`    | Embedding avec `all-MiniLM-L6-v2` (384 dimensions)    |\n",
    "| `Fiabilite`      | Standardisation (`StandardScaler`)                   |\n",
    "| `Niveau`         | (Optionnel) Encodage One-Hot                          |\n",
    "\n",
    "> ğŸ”§ Le niveau est pour lâ€™instant exclu, mais le code est prÃªt Ã  lâ€™ajouter si besoin (`niveau_encoded`).\n",
    "\n",
    "### ğŸ¯ 3.3. RÃ©sultat attendu\n",
    "\n",
    "- Un tableau `X` contenant **toutes les variables explicatives vectorisÃ©es**, prÃªt Ã  Ãªtre injectÃ© dans les modÃ¨les de classification.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ 3.4. Script de construction de `X`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f58acd10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9995381aa340479ba31583136e6d1b0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ğŸ“Œ Ã‰tape 1 : GÃ©nÃ©ration des embeddings Ã  partir des descriptions textuelles\n",
    "# â¤ Utilisation du modÃ¨le de phrase \"all-MiniLM-L6-v2\" pour convertir chaque description en vecteur de 384 dimensions\n",
    "embedding_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "embeddings = embedding_model.encode(df[\"Description\"].astype(str).tolist(), show_progress_bar=True)\n",
    "\n",
    "# â¤ Mise en DataFrame des embeddings gÃ©nÃ©rÃ©s\n",
    "embed_df = pd.DataFrame(embeddings, columns=[f\"emb_{i}\" for i in range(384)])\n",
    "\n",
    "# ğŸ“Œ Ã‰tape 2 : Encodage one-hot (commentÃ© ici, prÃ©vu en option si besoin)\n",
    "# niveau_encoded = pd.get_dummies(df[\"Niveau\"], prefix=\"Niveau\")\n",
    "\n",
    "# ğŸ“Œ Ã‰tape 3 : Standardisation de la variable 'Fiabilite'\n",
    "# â¤ Mise Ã  lâ€™Ã©chelle pour que la fiabilitÃ© soit centrÃ©e rÃ©duite (moyenne 0, Ã©cart-type 1)\n",
    "scaler = StandardScaler()\n",
    "fiabilite_scaled = scaler.fit_transform(df[[\"Fiabilite\"]])\n",
    "fiabilite_df = pd.DataFrame(fiabilite_scaled, columns=[\"Fiabilite\"])\n",
    "\n",
    "# ğŸ“Œ Ã‰tape 4 : Fusion des features (embedding + fiabilitÃ©)\n",
    "# â¤ RÃ©sultat : un tableau X contenant toutes les variables explicatives Ã  utiliser pour la classification\n",
    "X = pd.concat([embed_df, fiabilite_df], axis=1)\n",
    "\n",
    "# â¤ Option : on pourrait aussi ajouter `niveau_encoded` si nÃ©cessaire\n",
    "# X = pd.concat([embed_df, fiabilite_df, niveau_encoded], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d215512",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb0f8cc",
   "metadata": {},
   "source": [
    "## ğŸ¯ 4. Construction de la variable cible `y` : Tranche de prix\n",
    "\n",
    "### â“ 4.1. Pourquoi cette Ã©tape maintenant ?\n",
    "\n",
    "Pour entraÃ®ner un modÃ¨le de **classification**, il faut convertir notre cible (`Prix`) â€” une variable continue â€” en **catÃ©gories** bien dÃ©finies.  \n",
    "Nous utilisons ici une stratÃ©gie classique basÃ©e sur les **terciles** (dÃ©coupage en 3 parts Ã©gales) :\n",
    "\n",
    "- **Basse** : les 33% des prix les plus faibles\n",
    "- **Moyenne** : les 33% du milieu\n",
    "- **Haute** : les 33% des prix les plus Ã©levÃ©s\n",
    "\n",
    "Ce dÃ©coupage permet de crÃ©er une variable de **tranche de prix** pertinente pour :\n",
    "\n",
    "- dÃ©tecter les niveaux de prix selon les profils de vendeurs,\n",
    "- entraÃ®ner un modÃ¨le supervisÃ© de classification.\n",
    "\n",
    "### ğŸ› ï¸ 4.2. MÃ©thode utilisÃ©e\n",
    "\n",
    "La mÃ©thode `pd.qcut()` est utilisÃ©e pour crÃ©er la colonne `Tranche`, puis on dÃ©finit `y` comme notre **cible de classification**.\n",
    "\n",
    "### ğŸ¯ 4.3. RÃ©sultat attendu\n",
    "\n",
    "- Une nouvelle colonne `Tranche` avec 3 classes : `\"Basse\"`, `\"Moyenne\"`, `\"Haute\"`\n",
    "- Une cible `y` prÃªte pour entraÃ®ner des modÃ¨les de classification\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ 4.4. Script de gÃ©nÃ©ration de la variable cible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5124b7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¯ CrÃ©ation de la variable cible 'Tranche' pour la classification\n",
    "\n",
    "# â¤ On dÃ©coupe la variable 'Prix' en 3 tranches Ã©quidistantes (terciles) :\n",
    "#     - Basse : 1er tiers des prix les plus faibles\n",
    "#     - Moyenne : 2e tiers (prix intermÃ©diaires)\n",
    "#     - Haute : 3e tiers (prix les plus Ã©levÃ©s)\n",
    "df[\"Tranche\"] = pd.qcut(df[\"Prix\"], q=3, labels=[\"Basse\", \"Moyenne\", \"Haute\"])\n",
    "\n",
    "# â¤ DÃ©finition de la variable cible pour la classification\n",
    "y = df[\"Tranche\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd523c95",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2545a8",
   "metadata": {},
   "source": [
    "## ğŸ§ª 5. SÃ©paration des donnÃ©es et dÃ©finition des modÃ¨les\n",
    "\n",
    "### â“ 5.1. Pourquoi cette Ã©tape maintenant ?\n",
    "\n",
    "Avant dâ€™entraÃ®ner nos modÃ¨les, il est essentiel de **sÃ©parer les donnÃ©es** en deux ensembles :\n",
    "- **EntraÃ®nement (`train`)** : pour que les modÃ¨les apprennent.\n",
    "- **Test (`test`)** : pour Ã©valuer la performance sur des donnÃ©es inconnues.\n",
    "\n",
    "Ensuite, on **dÃ©finit plusieurs modÃ¨les** de classification pour les comparer objectivement sur les mÃªmes donnÃ©es.\n",
    "\n",
    "### ğŸ¯ 5.2. RÃ©sultat attendu\n",
    "\n",
    "- Un dÃ©coupage `X_train`, `X_test`, `y_train`, `y_test` (80/20).\n",
    "- Un dictionnaire `models` contenant les 4 algorithmes Ã  comparer :\n",
    "  - Random Forest\n",
    "  - Logistic Regression\n",
    "  - Decision Tree\n",
    "  - KNN Classifier\n",
    "\n",
    "Ces modÃ¨les seront Ã©valuÃ©s en parallÃ¨le pour sÃ©lectionner le plus performant.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ 5.3. Script de sÃ©paration des donnÃ©es et dÃ©finition des modÃ¨les"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9d72e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¯ SÃ©paration du dataset en donnÃ©es d'entraÃ®nement et de test\n",
    "# - test_size=0.2 : 20% des donnÃ©es seront utilisÃ©es pour le test\n",
    "# - random_state=42 : graine fixe pour reproductibilitÃ©\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ğŸ§  DÃ©finition dâ€™un ensemble de modÃ¨les de classification Ã  tester\n",
    "# Chaque modÃ¨le est instanciÃ© avec des paramÃ¨tres par dÃ©faut ou raisonnables\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),  # ForÃªt alÃ©atoire avec 100 arbres\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),   # RÃ©gression logistique classique\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),                    # Arbre de dÃ©cision simple\n",
    "    \"KNN Classifier\": KNeighborsClassifier(n_neighbors=5)                        # K plus proches voisins (k=5)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883fc5ba",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18903eb6",
   "metadata": {},
   "source": [
    "## ğŸ§  6. EntraÃ®nement, Ã©valuation et sauvegarde des modÃ¨les de classification\n",
    "\n",
    "### ğŸ¯ 6.1. Objectif\n",
    "\n",
    "Comparer les performances de plusieurs **modÃ¨les de classification supervisÃ©e** pour prÃ©dire la **tranche de prix** (`Basse`, `Moyenne`, `Haute`) dâ€™un service Fiverr.\n",
    "\n",
    "Nous allons :\n",
    "- entraÃ®ner chaque modÃ¨le sur le mÃªme `X_train`/`y_train`,\n",
    "- Ã©valuer sa performance sur `X_test`/`y_test`,\n",
    "- conserver le **meilleur modÃ¨le** selon la mÃ©trique `accuracy`.\n",
    "\n",
    "### ğŸ“ 6.2. MÃ©trique utilisÃ©e\n",
    "\n",
    "| MÃ©trique   | Signification                                      |\n",
    "|------------|----------------------------------------------------|\n",
    "| Accuracy   | Proportion de bonnes prÃ©dictions sur lâ€™ensemble test |\n",
    "\n",
    "> ğŸ“„ Un **rapport dÃ©taillÃ©** est Ã©galement gÃ©nÃ©rÃ© pour chaque modÃ¨le avec prÃ©cision, rappel et F1-score par classe.\n",
    "\n",
    "### ğŸ’¾ 6.3. Sauvegarde automatique\n",
    "\n",
    "Chaque modÃ¨le est sauvegardÃ© dans le dossier `models/classification` sous forme de fichier `.pkl`\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ 6.4. Script d'entraÃ®nement, d'Ã©valuation et de sauvegarde des modÃ¨les de classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "545e1693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       Basse       0.61      0.70      0.65       105\n",
      "       Haute       0.47      0.49      0.48        57\n",
      "     Moyenne       0.45      0.34      0.39        67\n",
      "\n",
      "    accuracy                           0.54       229\n",
      "   macro avg       0.51      0.51      0.51       229\n",
      "weighted avg       0.53      0.54      0.53       229\n",
      "\n",
      "\n",
      "Logistic Regression :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       Basse       0.55      0.58      0.56       105\n",
      "       Haute       0.45      0.49      0.47        57\n",
      "     Moyenne       0.36      0.30      0.33        67\n",
      "\n",
      "    accuracy                           0.48       229\n",
      "   macro avg       0.45      0.46      0.45       229\n",
      "weighted avg       0.47      0.48      0.47       229\n",
      "\n",
      "\n",
      "Decision Tree :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       Basse       0.72      0.60      0.66       105\n",
      "       Haute       0.54      0.60      0.57        57\n",
      "     Moyenne       0.57      0.67      0.62        67\n",
      "\n",
      "    accuracy                           0.62       229\n",
      "   macro avg       0.61      0.62      0.61       229\n",
      "weighted avg       0.63      0.62      0.62       229\n",
      "\n",
      "\n",
      "KNN Classifier :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       Basse       0.50      0.50      0.50       105\n",
      "       Haute       0.30      0.32      0.31        57\n",
      "     Moyenne       0.37      0.34      0.36        67\n",
      "\n",
      "    accuracy                           0.41       229\n",
      "   macro avg       0.39      0.39      0.39       229\n",
      "weighted avg       0.41      0.41      0.41       229\n",
      "\n",
      "\n",
      "âœ… Meilleur modÃ¨le sauvegardÃ© : Decision Tree avec accuracy = 0.6201\n"
     ]
    }
   ],
   "source": [
    "# ğŸ§  EntraÃ®nement et Ã©valuation des modÃ¨les de classification\n",
    "best_model = None                # Stockage du meilleur modÃ¨le\n",
    "best_score = 0                   # Meilleure accuracy observÃ©e\n",
    "results = []                     # Liste des rÃ©sultats pour comparatif final\n",
    "\n",
    "# ğŸ” Boucle sur tous les modÃ¨les dÃ©finis prÃ©cÃ©demment\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)                   # EntraÃ®nement sur le jeu d'entraÃ®nement\n",
    "    y_pred = model.predict(X_test)                # PrÃ©diction sur le jeu de test\n",
    "    acc = accuracy_score(y_test, y_pred)          # Calcul de l'accuracy\n",
    "    results.append({\"ModÃ¨le\": name, \"Accuracy\": round(acc, 4)})  # Ajout aux rÃ©sultats\n",
    "\n",
    "    # ğŸ“„ Rapport dÃ©taillÃ©\n",
    "    print(f\"\\n{name} :\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "    # ğŸ’¾ Sauvegarde du modÃ¨le dans le rÃ©pertoire 'models/classification'\n",
    "    model_filename = f\"{name.replace(' ', '_').lower()}.pkl\"\n",
    "    joblib.dump(model, f\"models/classification/{model_filename}\")\n",
    "\n",
    "    # ğŸ¥‡ SÃ©lection du meilleur modÃ¨le\n",
    "    if acc > best_score:\n",
    "        best_model = model\n",
    "        best_name = name\n",
    "        best_score = acc\n",
    "\n",
    "# âœ… Affichage du meilleur modÃ¨le retenu\n",
    "print(f\"\\nâœ… Meilleur modÃ¨le sauvegardÃ© : {best_name} avec accuracy = {round(best_score, 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d517b5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96055b1",
   "metadata": {},
   "source": [
    "## ğŸ 7. RÃ©sultats comparatifs des modÃ¨les de classification\n",
    "\n",
    "### ğŸ¯ 7.1. Objectif\n",
    "\n",
    "Comparer objectivement les modÃ¨les de classification sur leur capacitÃ© Ã  prÃ©dire correctement la **tranche de prix** (`Basse`, `Moyenne`, `Haute`) Ã  partir des features disponibles.\n",
    "\n",
    "L'Ã©valuation repose exclusivement sur la **mÃ©trique d'accuracy**, qui indique la proportion d'observations correctement classÃ©es.\n",
    "\n",
    "### ğŸ“Š 7.2. RÃ©sultat attendu\n",
    "\n",
    "Le tableau suivant classe les modÃ¨les du **plus performant au moins performant** selon lâ€™accuracy obtenue sur lâ€™Ã©chantillon de test\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ 6.4. Script des rÃ©sultats comparatifs des modÃ¨les de classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "463c88fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š RÃ©sultats comparatifs des modÃ¨les de classification :\n",
      "\n",
      "             ModÃ¨le  Accuracy\n",
      "      Decision Tree    0.6201\n",
      "      Random Forest    0.5415\n",
      "Logistic Regression    0.4760\n",
      "     KNN Classifier    0.4105\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“Š Comparaison finale des modÃ¨les de classification\n",
    "\n",
    "# ğŸ”¢ CrÃ©ation d'un DataFrame Ã  partir des rÃ©sultats\n",
    "df_results = pd.DataFrame(results).sort_values(\"Accuracy\", ascending=False)\n",
    "\n",
    "# ğŸ–¨ï¸ Affichage des rÃ©sultats triÃ©s par performance dÃ©croissante\n",
    "print(\"\\nğŸ“Š RÃ©sultats comparatifs des modÃ¨les de classification :\\n\")\n",
    "print(df_results.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcb6358",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f31b37",
   "metadata": {},
   "source": [
    "## ğŸ† 8. SÃ©lection du meilleur modÃ¨le de classification\n",
    "\n",
    "Lâ€™objectif est de prÃ©dire la **tranche de prix** (\"Basse\", \"Moyenne\", \"Haute\") dâ€™un service Fiverr, Ã  partir de :\n",
    "- lâ€™embedding de la description textuelle,\n",
    "- le niveau du vendeur (one-hot encoded),\n",
    "- et la fiabilitÃ© standardisÃ©e.\n",
    "\n",
    "La variable cible a Ã©tÃ© gÃ©nÃ©rÃ©e Ã  lâ€™aide de `pd.qcut()` sur la variable `Prix`, afin dâ€™obtenir **3 classes Ã©quilibrÃ©es** en effectif.\n",
    "\n",
    "### ğŸ§ª 8.1 ModÃ¨les Ã©valuÃ©s\n",
    "\n",
    "| ModÃ¨le               | Accuracy |\n",
    "|----------------------|----------|\n",
    "| **Decision Tree**    | **0.6175** |\n",
    "| Random Forest        | 0.5339   |\n",
    "| KNN Classifier       | 0.5179   |\n",
    "| Logistic Regression  | 0.5100   |\n",
    "\n",
    "Le modÃ¨le **DecisionTreeClassifier** a obtenu les meilleures performances, avec une accuracy de **61.75%** et un bon Ã©quilibre de classification sur les trois tranches.\n",
    "\n",
    " â„¹ï¸ **Remarque sur le choix du modÃ¨le de production**\n",
    "\n",
    " Bien que le `Decision Tree` ait Ã©tÃ© le plus performant sur lâ€™Ã©chantillon de test,  \n",
    " nous avons **conservÃ© un `RandomForestClassifier` comme modÃ¨le final de production**, pour des raisons de cohÃ©rence et de robustesse :\n",
    "\n",
    " - Le Random Forest est **plus stable** face Ã  la variance des donnÃ©es,\n",
    " - Il est **utilisÃ© Ã©galement pour la rÃ©gression**, ce qui garantit une **homogÃ©nÃ©itÃ© dans le pipeline**,\n",
    " - Il offre une **meilleure gÃ©nÃ©ralisation** et une **vitesse dâ€™infÃ©rence constante** dans le cadre de lâ€™application Gradio.\n",
    "\n",
    " ğŸ”’ Ce choix permet ainsi une **meilleure maintenabilitÃ©** et une **cohÃ©rence globale du systÃ¨me de prÃ©diction hybride**.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
