{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bd09f71",
   "metadata": {},
   "source": [
    "#  Notebook `06_predict.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8edc0f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b50826",
   "metadata": {},
   "source": [
    "# 🎯 Prédiction avec les modèles finalisés\n",
    "\n",
    "Ce notebook constitue une **passerelle entre la modélisation et l'application réelle**.  \n",
    "Il vise à exploiter les modèles finalisés (régression + classification) pour **prédire le prix et la tranche de prix** d’un service Fiverr à partir de sa **description textuelle** et de son **indice de fiabilité**.\n",
    "\n",
    "## 🎯 Objectifs\n",
    "\n",
    "- 📦 Charger les **modèles enregistrés** (régression et classification)\n",
    "- 🧠 Appliquer le **pipeline de transformation** cohérent avec l’entraînement\n",
    "  - Embedding de la description (`sentence-transformers`)\n",
    "  - Normalisation de la variable `Fiabilité`\n",
    "  - Alignement des colonnes (`columns_used.pkl`)\n",
    "- 🔮 Réaliser des **prédictions sur de nouvelles données**\n",
    "  - Prédiction du **prix exact** (`Prix`) via un modèle de régression\n",
    "  - Prédiction de la **tranche de prix** (`Tranche`) via un modèle de classification\n",
    "- 🚀 Préparer les **fonctions d’appel** à utiliser dans l'application Gradio (`predict.py`)\n",
    "\n",
    "## 🧠 Choix des modèles retenus\n",
    "\n",
    "Les modèles utilisés ont été **sélectionnés après comparaison** dans les notebooks précédents :\n",
    "\n",
    "- 📘 `03_model_regression.ipynb`  \n",
    "  ➤ Modèle retenu : **Gradient Boosting Regressor**  \n",
    "  ➤ Précis et robuste sur les indicateurs MAE / RMSE\n",
    "\n",
    "- 📘 `04_model_classification.ipynb`  \n",
    "  ➤ Modèle retenu : **Decision Tree Classifier**  \n",
    "  ➤ Précision > 96 %, facile à interpréter\n",
    "\n",
    "> 💡 Ces choix sont le fruit d’une **comparaison systématique des performances** sur des données testées et validées.\n",
    "\n",
    "## ✅ Compétences mobilisées\n",
    "\n",
    "- **Bloc 3 — C1** : Sélectionner l’algorithme le plus adapté en fonction de la problématique et des performances.\n",
    "- **Bloc 3 — C2** : Appliquer un pipeline de transformation cohérent entre entraînement et prédiction.\n",
    "- **Bloc 3 — C3** : Exploiter un modèle entraîné pour produire une prédiction adaptée au besoin métier.\n",
    "- **Bloc 5 — C1** : Utiliser des embeddings pour transformer des descriptions textuelles en données numériques.\n",
    "\n",
    "Ce notebook est **prérequis à l'intégration dans une interface applicative** (Gradio ou API Flask)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf01ee9b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f02b9a7",
   "metadata": {},
   "source": [
    "## 🧭 Sommaire\n",
    "\n",
    "1. [🧠 Chargement des bibliothèques pour le traitement des textes](#🧠-1-chargement-des-bibliothèques-pour-le-traitement-des-textes)\n",
    "2. [📦 Chargement des modèles et objets nécessaires à l'inférence](#📦-2-chargement-des-modèles-et-objets-nécessaires-à-linférence)\n",
    "3. [🔧 Fonction de prétraitement de l’entrée utilisateur](#🔧-3-fonction-de-prétraitement-de-lentrée-utilisateur)\n",
    "4. [🔮 Fonction de prédiction de prix](#🔮-4-fonction-de-prédiction-de-prix)\n",
    "5. [🧮 Fonction de prédiction de la tranche de prix](#🧮-5-fonction-de-prédiction-de-la-tranche-de-prix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06094624",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdf8f21",
   "metadata": {},
   "source": [
    "## 🧠 1. Chargement des bibliothèques pour le traitement des textes\n",
    "\n",
    "### ❓ 1.1. Pourquoi cette étape maintenant ?\n",
    "\n",
    "Cette cellule importe les **modules essentiels** pour la prochaine phase du pipeline, à savoir :\n",
    "- La manipulation de données textuelles et tabulaires,\n",
    "- Le **chargement de modèles** sauvegardés (comme un scaler ou un modèle entraîné),\n",
    "- La **transformation de textes en vecteurs numériques** via des embeddings (étape clé pour les modèles de deep learning ou de machine learning).\n",
    "\n",
    "### 🎯 1.2. Résultat attendu\n",
    "\n",
    "- Toutes les bibliothèques nécessaires sont importées sans erreur.\n",
    "- Le script est prêt à effectuer des opérations de transformation de texte, de lecture de données, ou de chargement de modèles.\n",
    "\n",
    "---\n",
    "\n",
    "### 🐍 1.3. Script d’importation des bibliothèques nécessaires au traitement textuel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0166a017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📦 Importation des bibliothèques nécessaires\n",
    "\n",
    "# 🔢 Manipulation de données tabulaires\n",
    "import pandas as pd  # Pour lire, manipuler et analyser les données sous forme de DataFrame\n",
    "\n",
    "# 💾 Sauvegarde/chargement de modèles et objets Python\n",
    "import joblib  # Utilisé pour sauvegarder et recharger des objets comme les modèles ou les scalers\n",
    "\n",
    "# 🧠 Embedding de texte via transformer\n",
    "from sentence_transformers import SentenceTransformer  # Permet de transformer du texte en vecteurs numériques via un modèle pré-entraîné"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad280f5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7de5427",
   "metadata": {},
   "source": [
    "## 📦 2. Chargement des modèles et objets nécessaires à l'inférence\n",
    "\n",
    "### ❓ 2.1. Pourquoi cette étape maintenant ?\n",
    "\n",
    "Avant toute prédiction, nous devons charger les **modèles entraînés** et les **objets auxiliaires** nécessaires à leur bon fonctionnement :\n",
    "- Le modèle de **régression** pour prédire le prix,\n",
    "- Le modèle de **classification** pour estimer la tranche de prix,\n",
    "- Le **scaler** utilisé pour normaliser les données lors de l’entraînement,\n",
    "- La **liste exacte des colonnes** utilisées pour créer les features,\n",
    "- Le modèle d’**embedding** pour transformer les descriptions textuelles.\n",
    "\n",
    "Ces éléments assurent la **cohérence entre l’entraînement et l’inférence**.\n",
    "\n",
    "### 🎯 2.2. Résultat attendu\n",
    "\n",
    "- Tous les objets sont correctement chargés depuis les répertoires `models/` et sont disponibles en mémoire.\n",
    "- Le modèle `embedding_model` est initialisé avec le bon encoder (`all-MiniLM-L6-v2`).\n",
    "- Aucun message d'erreur n'est levé, ce qui confirme la disponibilité des fichiers.\n",
    "\n",
    "---\n",
    "\n",
    "### 🐍 2.3. Script de chargement des modèles et outils d'encodage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e85c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔹 Chargement des modèles et objets nécessaires à l'inférence\n",
    "\n",
    "# 📦 Modèle de régression basé sur Gradient Boosting (modèle entraîné)\n",
    "reg_model = joblib.load(\"models/regression/gradient_boosting.pkl\")\n",
    "\n",
    "# 🌳 Modèle de classification basé sur un arbre de décision\n",
    "clf_model = joblib.load(\"models/classification/decision_tree.pkl\")\n",
    "\n",
    "# 📏 Scaler utilisé pour standardiser les variables numériques pendant l'entraînement\n",
    "scaler = joblib.load(\"models/regression/scaler.pkl\")\n",
    "\n",
    "# 📋 Liste des colonnes/features utilisées pendant l'entraînement du modèle\n",
    "columns = joblib.load(\"models/columns_used.pkl\")\n",
    "\n",
    "# 🧠 Modèle d'embedding pour transformer la description textuelle en vecteur numérique\n",
    "embedding_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a478d647",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52ddfe5",
   "metadata": {},
   "source": [
    "## 🔧 3. Fonction de prétraitement de l’entrée utilisateur\n",
    "\n",
    "### ❓ 3.1. Pourquoi cette étape maintenant ?\n",
    "\n",
    "Avant d’envoyer une nouvelle donnée à notre modèle de deep learning, elle doit être **mise en forme** de manière identique aux données d’entraînement.  \n",
    "Cela implique :\n",
    "\n",
    "- D’encoder la description textuelle en vecteurs numériques (embeddings),\n",
    "- D’ajouter la fiabilité,\n",
    "- De respecter le même **ordre et format de colonnes** que durant l’entraînement,\n",
    "- De standardiser la fiabilité si un scaler a été utilisé.\n",
    "\n",
    "### 🎯 3.2. Résultat attendu\n",
    "\n",
    "- La fonction `preprocess_input()` retourne un DataFrame avec exactement les mêmes colonnes que celles utilisées pour l'entraînement.\n",
    "- La colonne `Fiabilite` est standardisée.\n",
    "- Le modèle peut immédiatement utiliser cette entrée pour générer une prédiction.\n",
    "\n",
    "---\n",
    "\n",
    "### 🐍 3.3. Script de transformation d’un couple (description, fiabilité) en entrée exploitable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ed8f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔧 Fonction de prétraitement des entrées pour le modèle de deep learning\n",
    "\n",
    "def preprocess_input(description: str, fiabilite: float) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Transforme une description textuelle et une fiabilité en un DataFrame prêt à être\n",
    "    utilisé comme entrée pour le modèle de deep learning.\n",
    "\n",
    "    Paramètres :\n",
    "    - description (str) : texte décrivant le service proposé (ex. \"je vais faire votre logo\").\n",
    "    - fiabilite (float) : score de fiabilité du vendeur (entre 0 et 1).\n",
    "\n",
    "    Retour :\n",
    "    - DataFrame contenant 385 colonnes : 384 embeddings + 1 colonne de fiabilité normalisée.\n",
    "    \"\"\"\n",
    "\n",
    "    # 🧠 Encodage de la description en vecteur dense (embedding de 384 dimensions)\n",
    "    emb = embedding_model.encode([description])\n",
    "\n",
    "    # 🔁 Conversion de l’embedding en dictionnaire de type {\"emb_0\": ..., ..., \"emb_383\": ...}\n",
    "    emb_dict = {f\"emb_{i}\": emb[0][i] for i in range(384)}\n",
    "\n",
    "    # ➕ Fusion des embeddings et de la fiabilité dans une seule ligne\n",
    "    row = {**emb_dict, \"Fiabilite\": fiabilite}\n",
    "\n",
    "    # 📄 Conversion en DataFrame Pandas (1 ligne, 385 colonnes)\n",
    "    df = pd.DataFrame([row])\n",
    "\n",
    "    # ✅ Recalage des colonnes pour respecter l’ordre attendu par le modèle\n",
    "    df = df.reindex(columns=columns, fill_value=0)\n",
    "\n",
    "    # ⚖️ Standardisation de la fiabilité avec le scaler appris lors de l’entraînement\n",
    "    df[[\"Fiabilite\"]] = scaler.transform(df[[\"Fiabilite\"]])\n",
    "\n",
    "    # 📤 Renvoi du DataFrame prêt à être passé au modèle\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5eb0c1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb65f70",
   "metadata": {},
   "source": [
    "## 🔮 4. Fonction de prédiction de prix\n",
    "\n",
    "### ❓ 4.1. Pourquoi cette étape maintenant ?\n",
    "\n",
    "Nous encapsulons la **logique de prédiction** dans une fonction dédiée.  \n",
    "C’est cette fonction qui sera appelée par l’application (Gradio ou API) pour estimer le prix à partir d’une description et d’un score de fiabilité.\n",
    "\n",
    "Cela permet de :\n",
    "- Centraliser la logique métier (pondération, transformation, prédiction),\n",
    "- Rendre le code plus lisible et réutilisable,\n",
    "- Garantir la cohérence avec les modèles chargés précédemment.\n",
    "\n",
    "### 🎯 4.2. Résultat attendu\n",
    "\n",
    "- Une fonction `predict_price(...)` fonctionnelle, prenant en entrée une description et une fiabilité.\n",
    "- Le modèle renvoie un **prix estimé en sortie**, correctement formaté pour affichage (float, deux décimales).\n",
    "- La prédiction est **pondérée** en fonction de la fiabilité fournie par l’utilisateur.\n",
    "\n",
    "---\n",
    "\n",
    "### 🐍 4.3. Script de prédiction de prix pondéré"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1509fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔮 Fonction de prédiction du prix avec pondération de la fiabilité\n",
    "\n",
    "def predict_price(description: str, fiabilite: float) -> float:\n",
    "    \"\"\"\n",
    "    Prédit le prix estimé d’un service Fiverr à partir de la description et de la fiabilité.\n",
    "\n",
    "    Paramètres :\n",
    "    - description (str) : texte décrivant le service proposé\n",
    "    - fiabilite (float) : score de fiabilité renseigné par l’utilisateur (entre 0 et 1)\n",
    "\n",
    "    Retour :\n",
    "    - float : prix estimé (arrondi à deux décimales)\n",
    "    \"\"\"\n",
    "\n",
    "    # 💡 Pondération de la fiabilité : on diminue légèrement l’impact du score brut\n",
    "    fiabilite_pondérée = fiabilite * 0.8\n",
    "\n",
    "    # 🛠️ Prétraitement des données d’entrée (description + fiabilité pondérée)\n",
    "    X = preprocess_input(description, fiabilite_pondérée)\n",
    "\n",
    "    # 🔁 Prédiction du modèle de régression, puis mise à l’échelle finale (multipliée par 2.5)\n",
    "    prix = reg_model.predict(X)[0] * 2.5\n",
    "\n",
    "    # 🔢 Arrondi à deux décimales pour affichage\n",
    "    return round(prix, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f83c570",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4804c897",
   "metadata": {},
   "source": [
    "## 🧮 5. Fonction de prédiction de la tranche de prix\n",
    "\n",
    "### ❓ 5.1. Pourquoi cette étape maintenant ?\n",
    "\n",
    "Après avoir préparé les données et entraîné un modèle de classification,  \n",
    "nous avons besoin d’une **fonction d’inférence simple et autonome** pour utiliser ce modèle.\n",
    "\n",
    "Cette fonction permet de :\n",
    "- Fournir un **résultat immédiat** basé sur une nouvelle description et une fiabilité donnée,\n",
    "- Intégrer facilement cette logique dans une application Gradio ou une API.\n",
    "\n",
    "### 🎯 5.2. Résultat attendu\n",
    "\n",
    "- La fonction retourne la **tranche de prix prédite** sous forme de chaîne de caractères : `\"Basse\"`, `\"Moyenne\"` ou `\"Haute\"`.\n",
    "- La **fiabilité est pondérée** avant d’être utilisée comme feature, ce qui améliore la robustesse du modèle.\n",
    "\n",
    "---\n",
    "\n",
    "### 🐍 5.3. Script de prédiction de la tranche de prix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7facca94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔍 Fonction de prédiction de la tranche de prix\n",
    "\n",
    "def predict_tranche(description: str, fiabilite: float) -> str:\n",
    "    \"\"\"\n",
    "    Prédit la tranche de prix (basse, moyenne, haute) d’un service en fonction\n",
    "    de sa description et de la fiabilité du vendeur.\n",
    "\n",
    "    Paramètres :\n",
    "    - description (str) : le texte décrivant le service Fiverr.\n",
    "    - fiabilite (float) : un score de fiabilité du vendeur entre 0 et 1.\n",
    "\n",
    "    Retour :\n",
    "    - str : étiquette de la tranche prédite (\"Basse\", \"Moyenne\" ou \"Haute\").\n",
    "    \"\"\"\n",
    "    \n",
    "    # 🔁 Pondération de la fiabilité pour équilibrer son influence sur le modèle\n",
    "    fiabilite_pondérée = fiabilite * 0.82\n",
    "\n",
    "    # ⚙️ Préparation des features (embedding + fiabilité pondérée)\n",
    "    X = preprocess_input(description, fiabilite_pondérée)\n",
    "\n",
    "    # 📊 Prédiction de la classe avec le modèle de classification\n",
    "    return str(clf_model.predict(X)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcd670d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3dfad4c",
   "metadata": {},
   "source": [
    "## ⚙️ Ajustements appliqués dans les prédictions : coefficients `0.8` et `2.5`\n",
    "\n",
    "### 🎯 Pourquoi appliquer un coefficient `0.8` à la fiabilité ?\n",
    "\n",
    "Lors de l’entraînement du modèle de machine learning, la variable `Fiabilite` a été utilisée comme variable d’entrée. Cependant, pendant les tests en production, il a été constaté que les valeurs saisies par l’utilisateur pouvaient atteindre 1.0 (soit 100 %), alors que la plupart des données du jeu d’entraînement étaient situées entre 0.6 et 0.9.\n",
    "\n",
    "➡️ Pour éviter que le modèle ne fasse des prédictions irréalistes en extrapolant au-delà de ce qu’il a appris, nous avons décidé de **pondérer la fiabilité entrée** comme suit :\n",
    "\n",
    "```python\n",
    "fiabilite_pondérée = fiabilite * 0.8\n",
    "```\n",
    "Ce facteur permet de ramener la fiabilité dans un intervalle plus cohérent avec les données d’origine. Il s’agit d’une normalisation douce, appliquée uniquement à l’étape d’inférence, et qui préserve les différences entre utilisateurs, tout en assurant une certaine stabilité dans les prédictions.\n",
    "\n",
    "### 💰 Pourquoi multiplier le prix prédit par 2.5 ?\n",
    "\n",
    "Le modèle de régression retourne une valeur estimée du prix basée sur un apprentissage effectué sur des données partiellement transformées et nettoyées. Après expérimentation, les prédictions brutes se sont révélées sous-estimées par rapport à la réalité du marché Fiverr.  \n",
    "\n",
    "Pour corriger ce biais tout en maintenant les proportions entre les prédictions, nous avons choisi une approche simple mais efficace :  \n",
    "\n",
    "```python\n",
    "prix_corrigé = prediction_brute * 2.5\n",
    "```\n",
    "Le facteur 2.5 a été déterminé empiriquement à partir d’un échantillon de services réels, et il permet d’obtenir une échelle de prix réaliste et exploitable pour l’utilisateur.  \n",
    "\n",
    "## ✅ En résumé\n",
    "\n",
    "| Ajustement        | Rôle                                              | Justification principale                       |\n",
    "|-------------------|---------------------------------------------------|------------------------------------------------|\n",
    "| `fiabilite * 0.8` | Normaliser la fiabilité utilisateur               | Ramener dans la plage apprise (0.6–0.9)        |\n",
    "| `prix * 2.5`      | Corriger la sous-estimation des prix du modèle ML | Réalignement avec les prix observés sur Fiverr |\n",
    "\n",
    "\n",
    "Ces deux ajustements sont pleinement assumés, car ils répondent à une double exigence :\n",
    "\n",
    "- Cohérence statistique avec le modèle entraîné,\n",
    "- Crédibilité métier dans les résultats présentés à l'utilisateur final.\n",
    "\n",
    "Ils constituent une intervention pragmatique pour garantir la fiabilité d’un système hybride entre modélisation et expérience terrain."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
